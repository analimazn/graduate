{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "me82Mq_lNBXr"
   },
   "source": [
    "**Deep Autoencoder**\n",
    "\n",
    "Use to encoder and autoencoder images with different sizes.\n",
    "\n",
    "Sequence\n",
    "\n",
    "Create the directories:\n",
    "\n",
    "1. `./data_png`: Load images saved on the `./images` directorie in here\n",
    "2. `./data_npy `: The `.npy` are saved in here\n",
    "3. `./results_png `: The results after processing images are saved in here\n",
    "4. `./metrics_png`: The metricts about lost are saved in here\n",
    "5. `./models_h5`: The models `.h5` are saved in here\n",
    "6. `./models_yml`: The models `.yml` are saved in here, if the models are created\n",
    "7. `./shapes_sizes_json`: The shaped `.json` are saved in here, if the shaped are created\n",
    "8. `./histograms`: The histograms are saved in here\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "9JmR3qeh8ApC"
   },
   "source": [
    "Install libs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "UvxJ2HVk78hR"
   },
   "outputs": [],
   "source": [
    "pip install PyYAML numpy matplotlib tensorflow"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "YFUNFKLQO5cw"
   },
   "source": [
    "Import libs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "GYlaNZAWMwnL"
   },
   "outputs": [],
   "source": [
    "# Numpy Matplot and Cv2 libs\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.image as mpimg\n",
    "from google.colab.patches import cv2_imshow\n",
    "import cv2\n",
    "\n",
    "# OS lib\n",
    "import os\n",
    "import time\n",
    "\n",
    "# Tensorflow and Keras\n",
    "from tensorflow.keras.layers import Dense, Input\n",
    "from tensorflow.keras.models import Model, load_model\n",
    "from tensorflow.keras import backend\n",
    "from tensorflow.keras.utils import plot_model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "OnWzecItTQ9g"
   },
   "source": [
    "Directories"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "bFpUqpOWTRVn"
   },
   "outputs": [],
   "source": [
    "data_png = './data_png'\n",
    "data_npy = './data_npy/'\n",
    "results_png = './results_png/'\n",
    "metrics_png = './metrics_png/'\n",
    "models_h5 = './models_h5/'\n",
    "models_yml = './models_yml/'\n",
    "shapes_sizes_json = './shapes_sizes_json/'\n",
    "histograms = './histograms/'\n",
    "\n",
    "\n",
    "try:\n",
    "    os.mkdir(data_png)\n",
    "    os.mkdir(data_npy)\n",
    "    os.mkdir(results_png)\n",
    "    os.mkdir(metrics_png)\n",
    "    os.mkdir(models_h5)\n",
    "    os.mkdir(models_yml)\n",
    "    os.mkdir(shapes_sizes_json)\n",
    "    os.mkdir(histograms)\n",
    "except OSError:\n",
    "    print (\"Creation of the directory %s failed\" % data_png)\n",
    "    print (\"Creation of the directory %s failed\" % data_npy)\n",
    "    print (\"Creation of the directory %s failed\" % results_png)\n",
    "    print (\"Creation of the directory %s failed\" % metrics_png)\n",
    "    print (\"Creation of the directory %s failed\" % models_h5)\n",
    "    print (\"Creation of the directory %s failed\" % models_yml)\n",
    "    print (\"Creation of the directory %s failed\" % shapes_sizes_json)\n",
    "    print (\"Creation of the directory %s failed\" % histograms)\n",
    "\n",
    "else:\n",
    "    print (\"Successfully created the directory %s \" % data_png)   \n",
    "    print (\"Successfully created the directory %s \" % data_npy)   \n",
    "    print (\"Successfully created the directory %s \" % results_png)   \n",
    "    print (\"Successfully created the directory %s \" % metrics_png)   \n",
    "    print (\"Successfully created the directory %s \" % models_h5)   \n",
    "    print (\"Successfully created the directory %s \" % models_yml)   \n",
    "    print (\"Successfully created the directory %s \" % shapes_sizes_json)\n",
    "    print (\"Successfully created the directory %s \" % histograms)  \n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "lgIB5XwhgiMa"
   },
   "source": [
    "Utils"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "jdGwsxqOglCx"
   },
   "outputs": [],
   "source": [
    "def plot_metrics_history_subplot(history, name):\n",
    "    fig, (ax1, ax2) = plt.subplots(1, 2)\n",
    "\n",
    "    loss = history.history['loss']\n",
    "    val_loss = history.history['val_loss']\n",
    "\n",
    "    # Plot training & validation RMSE values\n",
    "    ax1.plot(rmse)\n",
    "    ax1.plot(val_rmse)\n",
    "    ax1.set_title('RMSE')\n",
    "    ax1.legend(['Train', 'Test'], loc='upper right')\n",
    "\n",
    "    # Plot training & validation loss values\n",
    "    ax2.plot(loss)\n",
    "    ax2.plot(val_loss)\n",
    "    ax2.set_title('Model loss')\n",
    "    ax2.legend(['Train', 'Test'], loc='upper right')\n",
    "\n",
    "    fig.savefig(metrics_png + 'history_subplot_' + name)\n",
    "    \n",
    "def plot_metrics_history(history, name):\n",
    "    fig = plt.figure()\n",
    "    plt.plot(history.history['loss'])\n",
    "    plt.plot(history.history['val_loss'])\n",
    "    plt.title('RMSE')\n",
    "    plt.ylabel('Loss')\n",
    "    plt.xlabel('Epoch')\n",
    "    plt.legend(['Train', 'Test'], loc='upper right')\n",
    "    plt.show()\n",
    "    fig.savefig(metrics_png + 'history_loss_' + name)\n",
    "\n",
    "def plot_all(images):\n",
    "    fig = plt.figure(figsize=(32, 32))\n",
    "    number_rows = int(len(images)/3) + 1\n",
    "    for index in range(len(images)):\n",
    "        a = fig.add_subplot(number_rows, 3, index+1)\n",
    "        plt.imshow(images[index])\n",
    "        plt.title(f'{index}:{images[index].shape}')\n",
    "        a.axis('off')\n",
    "    plt.show()\n",
    "    fig.savefig(results_png + 'compare_all_images.png')\n",
    "\n",
    "def save_image(name, image):        \n",
    "    mpimg.imsave(results_png + name, image)\n",
    "\n",
    "def save_npy(name, image): \n",
    "    name = name[:-4]\n",
    "    np.save(data_npy + name + '.npy', image)\n",
    "\n",
    "def simple_histogram(name, image):\n",
    "    fig = plt.figure()\n",
    "    gray = cv2.cvtColor(image, cv2.COLOR_BGR2GRAY)\n",
    "    plt.title('Histograma Cinza')\n",
    "    plt.ylabel('Pixels')\n",
    "    plt.xlabel('Bins')   \n",
    "    plt.hist(gray.ravel(),256,[0,256])\n",
    "    fig.savefig(histograms + 'simple_histogram_' + name)\n",
    "    plt.show()\n",
    "\n",
    "def color_histogram(name, image):\n",
    "    fig = plt.figure()\n",
    "    color = ('b','g','r')\n",
    "    plt.title('Histograma Colorido')\n",
    "    plt.ylabel('Pixels')\n",
    "    plt.xlabel('Bins')    \n",
    "    for i,col in enumerate(color):\n",
    "        histr = cv2.calcHist([image],[i],None,[256],[0,256])\n",
    "        plt.plot(histr,color = col)\n",
    "        plt.xlim([0,256])\n",
    "    fig.savefig(histograms + 'color_histogram_' + name)\n",
    "    plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "CjFKTa5O4gFj"
   },
   "source": [
    "Class TimingCallback"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "NWb2b_g54f3N"
   },
   "outputs": [],
   "source": [
    "class TimingCallback(Callback):\n",
    "  def __init__(self):\n",
    "    self.times = []\n",
    "  def on_time_begin(self, epoch, logs={}):\n",
    "    self.start_time = time.time()\n",
    "  def on_time_end(self, epoch, logs={}):\n",
    "    self.times.append(time.time() - self.start_time)\n",
    "\n",
    "time_callback = TimingCallback()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "ZSTjBwlIf3qf"
   },
   "source": [
    "Class DeepAutoencoder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "zwkxYHUUf70V"
   },
   "outputs": [],
   "source": [
    "def rmse(y_true, y_pred):\n",
    "\treturn backend.sqrt(backend.mean(backend.square(y_pred - y_true), axis=-1))\n",
    "\n",
    "class DeepAutoencoder(object):\n",
    "    def __init__(self, input_dim, encoded_dim):     \n",
    "\n",
    "        # Dimensions of output and input layers\n",
    "        input_layer = Input(shape=(input_dim,))\n",
    "        hidden_input = Input(shape=(encoded_dim,))\n",
    "        \n",
    "        # Hidden layers to encoder (512, 384, 256, 128)\n",
    "        encoded = Dense(8 * encoded_dim, activation='relu')(input_layer)\n",
    "        encoded = Dense(6 * encoded_dim, activation='relu')(encoded)\n",
    "        encoded = Dense(4 * encoded_dim, activation='relu')(encoded)\n",
    "        encoded = Dense(2 * encoded_dim, activation='relu')(encoded)\n",
    "\n",
    "        # Hidden layer (64)\n",
    "        hidden_layer = Dense(encoded_dim, activation='relu')(encoded)\n",
    "\n",
    "        # Hidden layers to decoder (128, 256, 384, 512)\n",
    "        decoded = Dense(2 * encoded_dim, activation='relu')(hidden_layer)\n",
    "        decoded = Dense(4 * encoded_dim, activation='relu')(decoded)\n",
    "        decoded = Dense(6 * encoded_dim, activation='relu')(decoded)\n",
    "        decoded = Dense(8 * encoded_dim, activation='relu')(decoded)\n",
    "\n",
    "        # Output layer\n",
    "        output_layer = Dense(input_dim, activation='sigmoid')(decoded)\n",
    "        \n",
    "        # Autoencoder and encoder models\n",
    "        self.autoencoder = Model(input_layer, output_layer)\n",
    "        self.encoder = Model(input_layer, hidden_layer)\n",
    "        \n",
    "        # Sequential hidden layers of encoder\n",
    "        layer1 = self.autoencoder.layers[-5]\n",
    "        layer2 = self.autoencoder.layers[-4]\n",
    "        layer3 = self.autoencoder.layers[-3]\n",
    "        layer4 = self.autoencoder.layers[-2]\n",
    "        layer5 = self.autoencoder.layers[-1]\n",
    "        \n",
    "        encoded_layers = layer5(layer4(layer3(layer2(layer1(hidden_input)))))\n",
    "        \n",
    "        # Decoder model\n",
    "        self.decoder = Model(hidden_input, encoded_layers)\n",
    "\n",
    "        # Informations about models (autoencoder, encoder e decoder) \n",
    "        self.autoencoder.summary()\n",
    "        self.encoder.summary()\n",
    "        self.decoder.summary()\n",
    "\n",
    "        # Compiler autoencoder using optimizer function adam\n",
    "        self.autoencoder.compile(optimizer='adam', loss=rmse)\n",
    "\n",
    "    # Methods\n",
    "    # Method train autoencoder\n",
    "    def train(self, input_train, input_test, batch_size, epochs):    \n",
    "        self.autoencoder.fit(input_train, input_train,\n",
    "                            epochs=epochs,\n",
    "                            batch_size=batch_size,\n",
    "                            shuffle=True,\n",
    "                            validation_data=(input_train, input_test))\n",
    "    \n",
    "    # Method to return an encoded image\n",
    "    def get_encoded_image(self, image):\n",
    "        encoded_img = self.encoder.predict(image)\n",
    "        return encoded_img\n",
    "    \n",
    "    # Method to return a decoded image\n",
    "    def get_decoded_image(self, encoded_img):\n",
    "        decoded_img = self.decoder.predict(encoded_img)\n",
    "        return decoded_img\n",
    "\n",
    "    # History informations about train\n",
    "    def get_history_model(self):\n",
    "        autoencoder_history = self.autoencoder.history\n",
    "        return autoencoder_history\n",
    "\n",
    "    # Get evaluate informations about train and test\n",
    "    def get_evaluate_model(self, train, test):\n",
    "        autoencoder_evaluate = self.autoencoder.evaluate(train, test)\n",
    "        return autoencoder_evaluate\n",
    "\n",
    "    # Method to save the models\n",
    "    def save_model(self, name):\n",
    "        name = name[:-4]\n",
    "        self.autoencoder.save(models_h5 + 'autoencoder_' + name + '.h5')\n",
    "        self.encoder.save(models_h5 + 'encoder_' + name + '.h5')\n",
    "        self.decoder.save(models_h5 + 'decoder_' + name + '.h5')\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "iDquENhxjlFg"
   },
   "source": [
    "Class main()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "nltJyhIIjpxj"
   },
   "outputs": [],
   "source": [
    "def main():\n",
    "    images = []\n",
    "\n",
    "    for img in os.listdir(data_png):\n",
    "        try:\n",
    "            # Normalization of training image and test image   \n",
    "            img_train = mpimg.imread((os.path.join(data_png, img)))\n",
    "            train = img_train.reshape((len(img_train), np.prod(img_train.shape[1:])))\n",
    "            \n",
    "            img_test = mpimg.imread((os.path.join(data_png, img)))\n",
    "            test = img_train.reshape((len(img_train), np.prod(img_train.shape[1:])))\n",
    "\n",
    "            print(\"Image: \", img)\n",
    "            print(\"Initial Dimension: \", img_train.ndim)\n",
    "            print(\"Initial Shape:\", img_train.shape)\n",
    "            print(\"Initial Size: \", img_train.size)\n",
    "\n",
    "            print(\"Normalized Dimension: \", train.ndim)\n",
    "            print(\"Normalized shape:\", train.shape)\n",
    "            print(\"Normalized Size: \", train.size)\n",
    "\n",
    "            # Instantiation of class DeepAutoencoder\n",
    "            deep_autoencoder = DeepAutoencoder(train.shape[1], 64)\n",
    "            deep_autoencoder.train(train, test, 64, 10)\n",
    "            \n",
    "            # Start time\n",
    "            start_time = time.time()\n",
    "            \n",
    "            # Get encoded and decoded image\n",
    "            encoded_img = deep_autoencoder.get_encoded_image(test)\n",
    "            decoded_img = deep_autoencoder.get_decoded_image(encoded_img)\n",
    "            \n",
    "            # End time\n",
    "            end_time = time.time()\n",
    "\n",
    "            # Total time\n",
    "            times = (end_time - start_time) * 1000\n",
    "\n",
    "            # Get history and evaluate about training\n",
    "            deep_autoencoder_history = deep_autoencoder.get_history_model()\n",
    "            deep_autoencoder_evaluate = deep_autoencoder.get_evaluate_model(train, test)\n",
    "            \n",
    "            # Save models (autoencoder, encoder and decoder)\n",
    "            deep_autoencoder.save_model(img)\n",
    "            \n",
    "            # Plot images and graphics\n",
    "            # Dimensions of original image\n",
    "            image_shape = img_train.shape\n",
    "            original_img_size = image_shape[0], image_shape[1], image_shape[2]\n",
    "\n",
    "            # Resize original and decoded image\n",
    "            original_result = test.reshape(original_img_size)\n",
    "            decoded_img_result = decoded_img.reshape(original_img_size)\n",
    "\n",
    "            decoded_reshape = decoded_img_result.reshape((len(decoded_img_result), \n",
    "                                                          np.prod(decoded_img_result.shape[1:])))    \n",
    "\n",
    "            # Generate a plot with input, hidden layer and output\n",
    "            images.append(original_result)\n",
    "            images.append(encoded_img)\n",
    "            images.append(decoded_img_result)\n",
    "\n",
    "            # Generate a plot of metrics\n",
    "            plot_metrics_history(deep_autoencoder_history, 'deep_autoencoder' + img)\n",
    "\n",
    "            shape_0 = train.shape[0]\n",
    "\n",
    "            # Calculate the compression to hidden layers (512, 384, 256, 128, 64)\n",
    "            compression_original = ((shape_0 * train.shape[1]) / (shape_0 * train.shape[1])) * 100\n",
    "            compression_512 = ((shape_0 * 512) / (shape_0 * train.shape[1])) * 100\n",
    "            compression_384 = ((shape_0 * 384) / (shape_0 * train.shape[1])) * 100\n",
    "            compression_256 = ((shape_0 * 256) / (shape_0 * train.shape[1])) * 100\n",
    "            compression_128 = ((shape_0 * 128) / (shape_0 * train.shape[1])) * 100\n",
    "            compression_64 = ((shape_0 * 64) / (shape_0 * train.shape[1])) * 100\n",
    "\n",
    "            size_original = (shape_0 * train.shape[1])\n",
    "            size_512 = (shape_0 * 512)\n",
    "            size_384 = (shape_0 * 384)\n",
    "            size_256 = (shape_0 * 256)\n",
    "            size_128 = (shape_0 * 128)\n",
    "            size_64 = (shape_0 * 64)\n",
    "\n",
    "            # Calculate compression ratio\n",
    "            print(\"Image: \", img)\n",
    "            print(\"Encoded Dimension: \", encoded_img.ndim)\n",
    "            print(\"Initial Shape Encoded:\", encoded_img.shape)\n",
    "            print(\"Encoded Size: \", encoded_img.size)\n",
    "            \n",
    "            print('Run time takes %d seconds' % times)\n",
    "            print('Loss: %.2f%%' % ( deep_autoencoder_evaluate * 100 ))\n",
    "\n",
    "            # Get the percentages of compression\n",
    "            print('Original Pixels: %.2f%%\\n' %  compression_original)\n",
    "            print('512 Pixels: %.2f%%\\n' %  compression_512)\n",
    "            print('384 Pixels: %.2f%%\\n' % compression_384)\n",
    "            print('256 Pixels: %.2f%%\\n' % compression_256)\n",
    "            print('128 Pixels: %.2f%%\\n' % compression_128)\n",
    "            print('64 Pixels: %.2f%%\\n' % compression_64)\n",
    "\n",
    "            # Get sizes\n",
    "            print('Original Pixels: %.2d\\n' %  size_original)\n",
    "            print('512 Pixels: %.2d\\n' %  size_512)\n",
    "            print('384 Pixels: %.2d\\n' % size_384)\n",
    "            print('256 Pixels: %.2d\\n' % size_256)\n",
    "            print('128 Pixels: %.2d\\n' % size_128)\n",
    "            print('64 Pixels: %.2d\\n' % size_64)\n",
    "\n",
    "            # Save images\n",
    "            save_image('original_' + img, original_result)\n",
    "            save_image('encoded_' + img, encoded_img)\n",
    "            save_image('decoded_' + img, decoded_img_result)\n",
    "            \n",
    "        except Exception as e:\n",
    "            print(e)\n",
    "            pass\n",
    "\n",
    "    plot_all(images)\n",
    "    return\n",
    "\n",
    "main()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "BETQvSHqnFmB"
   },
   "source": [
    "Generate plot models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "S7d6Z1n0NUQC"
   },
   "outputs": [],
   "source": [
    "def rmse(y_true, y_pred):\n",
    "\treturn backend.sqrt(backend.mean(backend.square(y_pred - y_true), axis=-1))\n",
    "\n",
    "model_autoencoder_save = load_model('./models_h5/autoencoder_GOESR_RET_CH13_BMARBLE_20191009_1400.h5', custom_objects={'rmse':                   \n",
    "rmse})\n",
    "model_decoder_save = load_model('./models_h5/decoder_GOESR_RET_CH13_BMARBLE_20191009_1400.h5', custom_objects={'rmse':                   \n",
    "rmse})\n",
    "model_encoder_save = load_model('./models_h5/encoder_GOESR_RET_CH13_BMARBLE_20191009_1400.h5', custom_objects={'rmse':                   \n",
    "rmse})\n",
    "\n",
    "model_autoencoder_save.compile(optimizer='adam', loss=[rmse])\n",
    "model_decoder_save.compile(optimizer='adam', loss=[rmse])\n",
    "model_encoder_save.compile(optimizer='adam', loss=[rmse])\n",
    "\n",
    "plot_model(model_autoencoder_save, to_file='autoencoder.png', show_shapes=True, show_layer_names=True, expand_nested=True)\n",
    "plot_model(model_decoder_save, to_file='decoder.png', show_shapes=True, show_layer_names=True, expand_nested=True)\n",
    "plot_model(model_encoder_save, to_file='encoder.png', show_shapes=True, show_layer_names=True, expand_nested=True)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "HNILuK4mc1VN"
   },
   "source": [
    "Histograms"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "7JCAj-Y8c05I"
   },
   "outputs": [],
   "source": [
    "# Histograms\n",
    "# Original\n",
    "original_name = 'GOESR_RET_CH13_BMARBLE_20191009_1400'\n",
    "original = mpimg.imread('./data_png/' + original_name + '.png', 0)  \n",
    "simple_histogram('original_gray_' + original_name +'.png', original)\n",
    "color_histogram('original_color_' + original_name + '.png', original)\n",
    "\n",
    "# Histograms\n",
    "# Decoded\n",
    "decoded_name = 'decoded_GOESR_RET_CH13_BMARBLE_20191009_1400'\n",
    "decoded = mpimg.imread('./results_png/' + decoded_name + '.png', 0)  \n",
    "simple_histogram('decoded_gray_' + decoded_name +'.png', decoded)\n",
    "color_histogram('decoded_color_' + decoded_name + '.png', decoded)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "6GWfPtKoPSAt"
   },
   "source": [
    "Get a cropped size of original image and decoded image to compare"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "S3w8XNHtFULF"
   },
   "outputs": [],
   "source": [
    "from matplotlib.patches import Rectangle\n",
    "\n",
    "# Load images\n",
    "original = mpimg.imread(\"./data_png/GOESR_RET_CH13_IRCOL0_20191009_1400.png\")\n",
    "decoded = mpimg.imread(\"./results_png/decoded_GOESR_RET_CH13_IRCOL0_20191009_1400.png\")\n",
    "\n",
    "# Cropped original and decoded images\n",
    "cropped_original = original[2000:3000, 2000:3000]\n",
    "cropped_decoded = decoded[2000:3000, 2000:3000]\n",
    "\n",
    "# Show original and decoded \n",
    "fig = plt.figure(figsize=(56, 56))\n",
    "plt.title(\"Original Image\")\n",
    "plt.imshow(original)\n",
    "\n",
    "# Show original and decoded \n",
    "fig = plt.figure(figsize=(56, 56))\n",
    "plt.title(\"Decoded Image\")\n",
    "plt.imshow(decoded)\n",
    "\n",
    "# Show original and decoded - Grid\n",
    "fig = plt.figure(figsize=(56, 56))\n",
    "plt.title(\"Original Image\")\n",
    "plt.grid(color='black', axis='both', linestyle='-', linewidth=5)\n",
    "plt.gca().add_patch(Rectangle((2000,2000),1000,1000,linewidth=10,edgecolor='red',facecolor='none'))\n",
    "plt.imshow(original)\n",
    "\n",
    "fig = plt.figure(figsize=(56, 56))\n",
    "plt.title(\"Decoded Image\")\n",
    "plt.grid(color='black', axis='both', linestyle='-', linewidth=5)\n",
    "plt.gca().add_patch(Rectangle((2000,2000),1000,1000,linewidth=10,edgecolor='red',facecolor='none'))\n",
    "plt.imshow(decoded)\n",
    "\n",
    "# Show original and decoded croppeds\n",
    "fig = plt.figure(figsize=(56, 56))\n",
    "plt.title(\"Cropped original image {x1: 2000, y1: 2000, x2: 2000, y2: 3000}\")\n",
    "plt.imshow(cropped_original)\n",
    "\n",
    "fig = plt.figure(figsize=(56, 56))\n",
    "plt.title(\"Cropped decoded image {x1: 2000, y1: 2000, x2: 2000, y2: 3000}\")\n",
    "plt.imshow(cropped_decoded)\n",
    "\n",
    "# Show original and decoded croppeds - Grid\n",
    "fig = plt.figure(figsize=(56, 56))\n",
    "plt.title(\"Cropped original image {x1: 2000, y1: 2000, x2: 2000, y2: 3000}\")\n",
    "plt.grid(color='black', linestyle='-', linewidth=5)\n",
    "plt.gca().add_patch(Rectangle((200,200),200,200,linewidth=10,edgecolor='red',facecolor='none'))\n",
    "plt.imshow(cropped_original)\n",
    "\n",
    "fig = plt.figure(figsize=(56, 56))\n",
    "plt.title(\"Cropped decoded image {x1: 2000, y1: 2000, x2: 2000, y2: 3000}\")\n",
    "plt.gca().add_patch(Rectangle((200,200),200,200,linewidth=10,edgecolor='red',facecolor='none'))\n",
    "plt.grid(color='black', linestyle='-', linewidth=5)\n",
    "plt.imshow(cropped_decoded)\n",
    "\n",
    "\n",
    "# Cropped of cropped\n",
    "cropped_original_1 = cropped_original[200:500, 200:500]\n",
    "cropped_decoded_1 = cropped_decoded[200:500, 200:500]\n",
    "\n",
    "# Show original and decoded \n",
    "fig = plt.figure(figsize=(56, 56))\n",
    "plt.title(\"Original Image\")\n",
    "plt.imshow(cropped_original_1)\n",
    "\n",
    "# Show original and decoded \n",
    "fig = plt.figure(figsize=(56, 56))\n",
    "plt.title(\"Decoded Image\")\n",
    "plt.imshow(cropped_decoded_1)\n",
    "\n",
    "# Show original and decoded - Grid\n",
    "fig = plt.figure(figsize=(56, 56))\n",
    "plt.title(\"Original Image\")\n",
    "plt.grid(color='black', axis='both', linestyle='-', linewidth=5)\n",
    "plt.imshow(cropped_original_1)\n",
    "\n",
    "fig = plt.figure(figsize=(56, 56))\n",
    "plt.title(\"Decoded Image\")\n",
    "plt.grid(color='black', axis='both', linestyle='-', linewidth=5)\n",
    "plt.imshow(cropped_decoded_1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "646a45RKjA26"
   },
   "source": [
    "Load model and tests"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "00OeNqb9jAiy"
   },
   "outputs": [],
   "source": [
    "from tensorflow.keras.models import load_model\n",
    "\n",
    "def rmse(y_true, y_pred):\n",
    "\treturn backend.sqrt(backend.mean(backend.square(y_pred - y_true), axis=-1))\n",
    " \n",
    "# Load models using .npy\n",
    "\n",
    "# model_decoder_save = load_model('./models_h5/decoder_GOESR_RET_CH09_WVCOL2_20191009_1320.h5')\n",
    "# #model_decoder_save.compile(loss='mean_squared_error', optimizer='adam', metrics=[rmse])\n",
    "\n",
    "# img_encoded = np.load('./data_npy/GOESR_RET_CH09_WVCOL2_20191009_1320.npy')\n",
    "# img_decoded = model_decoder_save.predict(img_encoded)\n",
    "\n",
    "# with open(\"./shapes_sizes_json/original_GOESR_RET_CH09_WVCOL2_20191009_1320.json\", \"r\") as read_file:\n",
    "#     data = json.load(read_file)\n",
    "\n",
    "# test_encoder_result = img_decoded.reshape(data['rows'], data['columns'], data['channels'])\n",
    "# plt.imshow(test_encoder_result)\n",
    "\n",
    "# Load models using images\n",
    "\n",
    "model_autoencoder_save = load_model('./models_h5/decoder_GOESR_RET_CH09_WVCOL2_20191009_1320.h5')\n",
    "# model_encoder_save = load_model('./models/model_encoder__3_7880292.h5')\n",
    "\n",
    "model_autoencoder_save.compile(optimizer='adam',  loss='mean_squared_error', metrics=['mse'])\n",
    "\n",
    "img_test = mpimg.imread('./data_png/GOESR_RET_CH13_BMARBLE_20191009_1410.png')\n",
    "max_test_value = float(img_test.max())\n",
    "test_autoencoder = img_test.astype('float32') / max_test_value\n",
    "test_autoencoder = test_autoencoder.reshape((len(test_autoencoder), np.prod(test_autoencoder.shape[1:])))\n",
    "\n",
    "model_autoencoder_save.fit(test_autoencoder, test_autoencoder,\n",
    "                        epochs=100,\n",
    "                        batch_size=64,\n",
    "                        shuffle=True,\n",
    "                        validation_data=(test_autoencoder, test_autoencoder))\n",
    "\n",
    "test = model_autoencoder_save.predict(test_autoencoder)\n",
    "model_autoencoder_save.save('./test.h5')\n",
    "\n",
    "to_reshape = img_test.shape\n",
    "\n",
    "# test_encoder = model_encoder_save.predict(test_autoencoder)\n",
    "# test_autoencoder = model_autoencoder_save.predict(test_autoencoder)\n",
    "\n",
    "test_autoencoder_result = test.reshape(to_reshape[0], to_reshape[1], to_reshape[2])     \n",
    "plt.imshow(test_autoencoder_result) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "JBjAf94xlIeg"
   },
   "outputs": [],
   "source": [
    "img_test = mpimg.imread('./data_png/GOESR_RET_CH09_WVCOL2_20191009_1310.png')\n",
    "max_test_value = float(img_test.max())\n",
    "test_autoencoder = img_test.astype('float32') / max_test_value\n",
    "test_autoencoder = test_autoencoder.reshape((len(test_autoencoder), np.prod(test_autoencoder.shape[1:])))\n",
    "\n",
    "autoencoder = DeepAutoencoder(test_autoencoder.shape[1], 64)\n",
    "autoencoder.train(test_autoencoder, test_autoencoder, 64, 100)\n",
    "\n",
    "encoded_img = autoencoder.get_encoded_image(test_autoencoder)\n",
    "decoded_img = autoencoder.get_decoded_image(encoded_img)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "pKvbLvcgt8s9"
   },
   "source": [
    "Test model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "pbn1cQzHt8BL"
   },
   "outputs": [],
   "source": [
    "model_decoder_save = load_model('./models_h5/decoder_GOESR_RET_CH13_BMARBLE_20191009_1400.h5')\n",
    "#model_decoder_save.compile(loss='mean_squared_error', optimizer='adam', metrics=[rmse])\n",
    "\n",
    "img_encoded = np.load('./data_npy/GOESR_RET_CH13_BMARBLE_20191009_1400.npy')\n",
    "img_decoded = model_decoder_save.predict(img_encoded)\n",
    "\n",
    "with open(\"./shapes_sizes_json/original_GOESR_RET_CH13_BMARBLE_20191009_1400.json\", \"r\") as read_file:\n",
    "    data = json.load(read_file)\n",
    "\n",
    "test_encoder_result = img_decoded.reshape(data['rows'], data['columns'], data['channels'])\n",
    "plt.imshow(test_encoder_result)\n",
    "\n",
    "\n",
    "model_decoder_save = load_model('./models_h5/decoder_GOESR_RET_CH09_WVCOL2_20191009_1320.h5')\n",
    "model_decoder_save.compile(loss='mean_squared_error', optimizer='adam', metrics=[rmse])\n",
    "\n",
    "img_test = mpimg.imread('./data_png/GOESR_RET_CH09_WVCOL2_20191009_1310.png')\n",
    "max_test_value = float(img_test.max())\n",
    "test_autoencoder = img_test.astype('float32') / max_test_value\n",
    "test_autoencoder = test_autoencoder.reshape((len(test_autoencoder), np.prod(test_autoencoder.shape[1:])))\n",
    "\n",
    "model_decoder_save = load_model('./models_h5/autoencoder_GOESR_RET_CH09_WVCOL2_20191009_1310.h5')\n",
    "test = model_decoder_save.predict(test_autoencoder)\n",
    "\n",
    "to_reshape = img_test.shape\n",
    "\n",
    "# test_encoder = model_encoder_save.predict(test_autoencoder)\n",
    "# test_autoencoder = model_autoencoder_save.predict(test_autoencoder)\n",
    "\n",
    "test_autoencoder_result = test.reshape(to_reshape[0], to_reshape[1], to_reshape[2])     \n",
    "plt.imshow(test_autoencoder_result) "
   ]
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "collapsed_sections": [],
   "name": "deep_autoencoder_with_decoder.ipynb",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
