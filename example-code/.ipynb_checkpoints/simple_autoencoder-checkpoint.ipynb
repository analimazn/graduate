{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "me82Mq_lNBXr"
   },
   "source": [
    "**Simple Autoencoder**\n",
    "\n",
    "Use to encoder and autoencoder images with different sizes."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Install libs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: PyYAML in /home/analimazn/anaconda3/lib/python3.7/site-packages (5.1.1)\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "pip install PyYAML"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "YFUNFKLQO5cw"
   },
   "source": [
    "Import libs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "GYlaNZAWMwnL"
   },
   "outputs": [],
   "source": [
    "# Numpy and Matplot\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.image as mpimg\n",
    "\n",
    "# Tensorflow and Keras\n",
    "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
    "from tensorflow.keras.layers import Dense, Input, Dropout\n",
    "from tensorflow.keras.models import Model, Sequential, load_model, model_from_yaml, model_from_json\n",
    "from tensorflow.keras.applications.inception_v3 import preprocess_input\n",
    "from tensorflow.keras.callbacks import *\n",
    "#import tensorflow.keras.callbacks.Callback as Callback\n",
    "\n",
    "import os\n",
    "import json\n",
    "import time"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "OnWzecItTQ9g"
   },
   "source": [
    "Directories"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "bFpUqpOWTRVn"
   },
   "outputs": [],
   "source": [
    "data_png = './data_png'\n",
    "data_npy = './data_npy/'\n",
    "results_png = './results_png/'\n",
    "metrics_png = './metrics_png/'\n",
    "models_h5 = './models_h5/'\n",
    "models_yml = './models_yml/'\n",
    "shapes_sizes_json = './shapes_sizes_json/'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Utils"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_metrics_history_subplot(history, name):\n",
    "    fig, (ax1, ax2) = plt.subplots(1, 2)\n",
    "\n",
    "    # Plot training & validation accuracy values\n",
    "    ax1.plot(history.history['acc'])\n",
    "    ax1.plot(history.history['val_acc'])\n",
    "    ax1.set_title('Model accuracy')\n",
    "    ax1.legend(['Train', 'Test'], loc='upper right')\n",
    "\n",
    "    # Plot training & validation loss values\n",
    "    ax2.plot(history.history['loss'])\n",
    "    ax2.plot(history.history['val_loss'])\n",
    "    ax2.set_title('Model loss')\n",
    "    ax2.legend(['Train', 'Test'], loc='upper right')\n",
    "\n",
    "    fig.savefig(metrics_png + 'history_subplot_' + name)\n",
    "\n",
    "def plot_metrics_history(history, name):    \n",
    "    fig = plt.figure()\n",
    "    \n",
    "    # Plot training & validation accuracy values\n",
    "    plt.plot(history.history['acc'])\n",
    "    plt.plot(history.history['val_acc'])\n",
    "    plt.title('Model accuracy')\n",
    "    plt.ylabel('Accuracy')\n",
    "    plt.xlabel('Epoch')\n",
    "    plt.legend(['Train', 'Test'], loc='upper right')\n",
    "    plt.show()\n",
    "    fig.savefig(metrics_png + 'history_acc_' + name)\n",
    "\n",
    "    fig = plt.figure()\n",
    "    # Plot training & validation loss values\n",
    "    plt.plot(history.history['loss'])\n",
    "    plt.plot(history.history['val_loss'])\n",
    "    plt.title('Model loss')\n",
    "    plt.ylabel('Loss')\n",
    "    plt.xlabel('Epoch')\n",
    "    plt.legend(['Train', 'Test'], loc='upper right')\n",
    "    plt.show()\n",
    "    fig.savefig(metrics_png + 'history_loss_' + name)\n",
    "\n",
    "def plot_metrics_evaluate_all(model, name):\n",
    "    fig = plt.figure()\n",
    "\n",
    "    loss = model[0]\n",
    "    accuracy = model[1]\n",
    "\n",
    "    plt.plot([0, 100], [0, loss * 100])\n",
    "    plt.plot([0, 100], [0, accuracy * 100])\n",
    "    plt.title('Loss: %.2f%% | Accuracy: %.2f%%' % ( loss * 100,  accuracy * 100 ))\n",
    "    plt.legend(['Loss', 'Accuracy'], loc='upper right')\n",
    "    plt.show()\n",
    "    \n",
    "    fig.savefig(metrics_png + 'evaluate_loss_accuracy' + name)\n",
    "\n",
    "def plot_metrics_evaluate(model, name):\n",
    "    fig, (ax1, ax2) = plt.subplots(1, 2)\n",
    "    loss = model[0]\n",
    "    accuracy = model[1]\n",
    "\n",
    "    ax1.plot([0, 100], [0, loss * 100])\n",
    "    ax1.set_title('Loss: %.2f%%' % ( loss * 100 ))\n",
    "    ax1.legend(['Loss'], loc='upper right')\n",
    "\n",
    "    ax2.plot([0, 100], [0, accuracy * 100])\n",
    "    ax2.set_title('Accuracy: %.2f%%' % ( accuracy * 100 ))\n",
    "    ax2.legend(['Accuracy'], loc='upper right')\n",
    "    \n",
    "    fig.savefig(metrics_png + 'evaluate_acc_' + name)\n",
    "\n",
    "def plot_all(images):\n",
    "    fig = plt.figure(figsize=(32, 32))\n",
    "    number_rows = int(len(images)/3) + 1\n",
    "    \n",
    "    for index in range(len(images)):\n",
    "        a = fig.add_subplot(number_rows, 3, index+1)\n",
    "        plt.imshow(images[index])\n",
    "        plt.title(f'{index}:{images[index].shape}')\n",
    "        a.axis('off')\n",
    "    \n",
    "    fig.savefig(results_png + 'compare_all_images.png')\n",
    "    plt.show()\n",
    "\n",
    "def save_image(name, image):        \n",
    "    mpimg.imsave(results_png + name, image)\n",
    "\n",
    "def save_npy(name, image): \n",
    "    name = name[:-4]\n",
    "    np.save(data_npy + name + '.npy', image)\n",
    "\n",
    "def save_json(name, shape): \n",
    "    name = name[:-4]\n",
    "\n",
    "    data = {\n",
    "        \"shape_0\": shape[0],\n",
    "        \"shape_1\": shape[1],\n",
    "        \"shape_2\": shape[2]\n",
    "    }\n",
    "\n",
    "    with open(shapes_sizes_json + 'original_' + name + '.json', 'w') as outfile:\n",
    "        json.dump(data, outfile)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Class TimeCallback()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "class TimingCallback(Callback):\n",
    "    def __init__(self):\n",
    "        self.times = []\n",
    "    def on_epoch_begin(self, epoch, logs={}):\n",
    "        self.start_time = time.time()\n",
    "    def on_epoch_end(self, epoch, logs={}):\n",
    "        self.times.append(time.time() - self.start_time)\n",
    "\n",
    "time_callback = TimingCallback()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "ZSTjBwlIf3qf"
   },
   "source": [
    "Class SimpleAutoencder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "zwkxYHUUf70V"
   },
   "outputs": [],
   "source": [
    "class SimpleAutoencoder(object):\n",
    "\n",
    "    def __init__(self, input_dim, encoded_dim):    \n",
    "        input_layer = Input(shape=(input_dim,))\n",
    "        hidden_input = Input(shape=(encoded_dim,))\n",
    "        hidden_layer = Dense(encoded_dim, activation='relu')(input_layer)\n",
    "        output_layer = Dense(input_dim, activation='sigmoid')(hidden_layer)\n",
    "\n",
    "        self.autoencoder = Model(input_layer, output_layer)\n",
    "        self.encoder = Model(input_layer, hidden_layer)\n",
    "        tmp_decoder_layer = self.autoencoder.layers[-1]\n",
    "        self.decoder = Model(hidden_input, tmp_decoder_layer(hidden_input))\n",
    "\n",
    "        self.autoencoder.compile(optimizer='adam', loss='binary_crossentropy', metrics = ['accuracy'])\n",
    "\n",
    "    def train(self, input_train, input_test, batch_size, epochs):    \n",
    "        self.autoencoder.fit(input_train, \n",
    "                                    input_train,\n",
    "                                    epochs=epochs,\n",
    "                                    batch_size=batch_size,\n",
    "                                    shuffle=True,\n",
    "                                    validation_data=(\n",
    "                                            input_test, \n",
    "                                            input_test),\n",
    "                                    callbacks=[time_callback])\n",
    "        \n",
    "    def get_encoded_image(self, image):\n",
    "        encoded_image = self.encoder.predict(image)\n",
    "        return encoded_image\n",
    "    \n",
    "    def get_decoded_image(self, encoded_imgs):\n",
    "        decoded_image = self.decoder.predict(encoded_imgs)\n",
    "        return decoded_image\n",
    "\n",
    "    def get_evaluate_model(self, train, test):\n",
    "        return self.autoencoder.evaluate(train, test)\n",
    "\n",
    "    def get_history_model(self):\n",
    "        return self.autoencoder.history\n",
    "    \n",
    "    def save_model(self, name):\n",
    "        name = name[:-4]\n",
    "        self.autoencoder.save(models_h5 + 'autoencoder_' + name + '.h5')\n",
    "        self.encoder.save(models_h5 + 'encoder_' + name + '.h5')\n",
    "        self.decoder.save(models_h5 + 'decoder_' + name + '.h5')\n",
    "\n",
    "    def save_model_to_yml(self, name):\n",
    "        name = name[:-4]\n",
    "        model_yaml = self.autoencoder.to_yaml()\n",
    "        with open(models_yml + 'autoencoder_' + name + '.yaml', 'w') as yaml_file:\n",
    "            yaml_file.write(model_yaml)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "iDquENhxjlFg"
   },
   "source": [
    "Class main()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "nltJyhIIjpxj"
   },
   "outputs": [],
   "source": [
    "def main():\n",
    "    images = []\n",
    "    historic = []\n",
    "    results = []\n",
    "    \n",
    "    for img in os.listdir(data_png):\n",
    "        try:\n",
    "            # Normalização das imagens   \n",
    "            img_train = mpimg.imread((os.path.join(data_png, img)))  \n",
    "            max_train_value = float(img_train.max())\n",
    "            train = img_train.astype('float32') / max_train_value\n",
    "            train = train.reshape((len(train), np.prod(train.shape[1:])))\n",
    "            \n",
    "            img_test = mpimg.imread((os.path.join(data_png, img)))\n",
    "            max_test_value = float(img_test.max())\n",
    "            test = img_test.astype('float32') / max_test_value\n",
    "            test = test.reshape((len(test), np.prod(test.shape[1:])))\n",
    "\n",
    "            # Envio da imagem para a classe DeepAutoencoder\n",
    "            autoencoder = SimpleAutoencoder(train.shape[1], 64)\n",
    "            autoencoder.train(train, test, 64, 1500)\n",
    "            \n",
    "            encoded_img = autoencoder.get_encoded_image(test)\n",
    "            decoded_img = autoencoder.get_decoded_image(encoded_img)\n",
    "\n",
    "            autoencoder_history = autoencoder.get_history_model()\n",
    "            autoencoder_evaluate = autoencoder.get_evaluate_model(train, test)\n",
    "            \n",
    "            autoencoder.save_model(img)\n",
    "            autoencoder.save_model_to_yml(img)\n",
    "            \n",
    "            plot_metrics_history(autoencoder_history, 'autoencoder' + img)\n",
    "            plot_metrics_history_subplot(autoencoder_history, 'autoencoder' + img)\n",
    "            plot_metrics_evaluate(autoencoder_evaluate, 'autoencoder' + img)\n",
    "            plot_metrics_evaluate_all(autoencoder_evaluate, 'autoencoder' + img)\n",
    "\n",
    "            # Dimensões da imagem original\n",
    "            to_reshape = img_train.shape\n",
    "\n",
    "            # Redimensionamento das imagens obtidas\n",
    "            original_result = test.reshape(to_reshape[0], to_reshape[1], to_reshape[2])\n",
    "            decoded_img_result = decoded_img.reshape(to_reshape[0], to_reshape[1], to_reshape[2])      \n",
    "\n",
    "            images.append(original_result)\n",
    "            images.append(encoded_img)\n",
    "            images.append(decoded_img_result)\n",
    "\n",
    "            save_image('original_' + img, original_result)\n",
    "            save_image('encoded_' + img, encoded_img)\n",
    "            save_image('decoded_' + img, decoded_img_result)\n",
    "            \n",
    "            save_npy(img, encoded_img)\n",
    "            save_json(img, img_train.shape)\n",
    "\n",
    "            results.append(np.average(time_callback.times))\n",
    "            #Print average of the time for each layer\n",
    "            print(np.average(time_callback.times))\n",
    "\n",
    "        except Exception as e:\n",
    "            print(e)\n",
    "            pass\n",
    "    \n",
    "    return images"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "Bu6haEdpfTxG"
   },
   "source": [
    "Iteration about images of Satellite"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "z9c5R134fzJk"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 256 samples, validate on 256 samples\n",
      "Epoch 1/10\n",
      "256/256 [==============================] - 1s 3ms/sample - loss: 0.6854 - accuracy: 0.2375 - val_loss: 0.6676 - val_accuracy: 0.2782\n",
      "Epoch 2/10\n",
      "256/256 [==============================] - 0s 274us/sample - loss: 0.6534 - accuracy: 0.2961 - val_loss: 0.6278 - val_accuracy: 0.3242\n",
      "Epoch 3/10\n",
      "256/256 [==============================] - 0s 285us/sample - loss: 0.6113 - accuracy: 0.3361 - val_loss: 0.5824 - val_accuracy: 0.3525\n",
      "Epoch 4/10\n",
      "256/256 [==============================] - 0s 605us/sample - loss: 0.5667 - accuracy: 0.3602 - val_loss: 0.5426 - val_accuracy: 0.3703\n",
      "Epoch 5/10\n",
      "256/256 [==============================] - 0s 272us/sample - loss: 0.5314 - accuracy: 0.3730 - val_loss: 0.5154 - val_accuracy: 0.3763\n",
      "Epoch 6/10\n",
      "256/256 [==============================] - 0s 294us/sample - loss: 0.5088 - accuracy: 0.3781 - val_loss: 0.4996 - val_accuracy: 0.3811\n",
      "Epoch 7/10\n",
      "256/256 [==============================] - 0s 308us/sample - loss: 0.4961 - accuracy: 0.3808 - val_loss: 0.4901 - val_accuracy: 0.3806\n",
      "Epoch 8/10\n",
      "256/256 [==============================] - 0s 304us/sample - loss: 0.4874 - accuracy: 0.3803 - val_loss: 0.4828 - val_accuracy: 0.3801\n",
      "Epoch 9/10\n",
      "256/256 [==============================] - 0s 289us/sample - loss: 0.4808 - accuracy: 0.3800 - val_loss: 0.4774 - val_accuracy: 0.3805\n",
      "Epoch 10/10\n",
      "256/256 [==============================] - 0s 303us/sample - loss: 0.4759 - accuracy: 0.3803 - val_loss: 0.4725 - val_accuracy: 0.3804\n",
      "256/1 [================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================] - 0s 392us/sample - loss: 0.5063 - accuracy: 0.3804\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "'acc'\n",
      "Train on 256 samples, validate on 256 samples\n",
      "Epoch 1/10\n",
      "256/256 [==============================] - 1s 3ms/sample - loss: 0.6853 - accuracy: 0.1935 - val_loss: 0.6646 - val_accuracy: 0.2325\n",
      "Epoch 2/10\n",
      "256/256 [==============================] - 0s 297us/sample - loss: 0.6498 - accuracy: 0.2435 - val_loss: 0.6219 - val_accuracy: 0.2607\n",
      "Epoch 3/10\n",
      "256/256 [==============================] - 0s 282us/sample - loss: 0.6037 - accuracy: 0.2716 - val_loss: 0.5726 - val_accuracy: 0.2842\n",
      "Epoch 4/10\n",
      "256/256 [==============================] - 0s 257us/sample - loss: 0.5561 - accuracy: 0.2895 - val_loss: 0.5318 - val_accuracy: 0.2962\n",
      "Epoch 5/10\n",
      "256/256 [==============================] - 0s 307us/sample - loss: 0.5221 - accuracy: 0.2978 - val_loss: 0.5090 - val_accuracy: 0.3000\n",
      "Epoch 6/10\n",
      "256/256 [==============================] - 0s 250us/sample - loss: 0.5045 - accuracy: 0.3009 - val_loss: 0.4975 - val_accuracy: 0.3022\n",
      "Epoch 7/10\n",
      "256/256 [==============================] - 0s 290us/sample - loss: 0.4943 - accuracy: 0.3027 - val_loss: 0.4894 - val_accuracy: 0.3039\n",
      "Epoch 8/10\n",
      "256/256 [==============================] - 0s 307us/sample - loss: 0.4875 - accuracy: 0.3042 - val_loss: 0.4827 - val_accuracy: 0.3055\n",
      "Epoch 9/10\n",
      "256/256 [==============================] - 0s 257us/sample - loss: 0.4809 - accuracy: 0.3059 - val_loss: 0.4777 - val_accuracy: 0.3065\n",
      "Epoch 10/10\n",
      "256/256 [==============================] - 0s 248us/sample - loss: 0.4766 - accuracy: 0.3069 - val_loss: 0.4740 - val_accuracy: 0.3074\n",
      "256/1 [================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================] - 0s 422us/sample - loss: 0.4893 - accuracy: 0.3074\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "'acc'\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<Figure size 432x288 with 0 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "<Figure size 432x288 with 0 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "<Figure size 2304x2304 with 0 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "images = main()\n",
    "plot_all(images)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "646a45RKjA26"
   },
   "source": [
    "Load model (Test after models were been created)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "00OeNqb9jAiy"
   },
   "outputs": [],
   "source": [
    "# model_autoencoder_save = load_model('./models/model_autoencoder__3_7880292.h5')\n",
    "# model_encoder_save = load_model('./models/model_encoder__3_7880292.h5')\n",
    "\n",
    "# model_autoencoder_save.compile(loss='binary_crossentropy', optimizer='adam', metrics=['accuracy'])\n",
    "# model_encoder_save.compile(loss='binary_crossentropy', optimizer='adam', metrics=['accuracy'])\n",
    "\n",
    "# img_test = mpimg.imread('./data/_3_7880292.png')\n",
    "# max_test_value = float(img_test.max())\n",
    "# test_autoencoder = img_test.astype('float32') / max_test_value\n",
    "# test_autoencoder = test_autoencoder.reshape((len(test_autoencoder), np.prod(test_autoencoder.shape[1:])))\n",
    "\n",
    "# to_reshape = img_test.shape\n",
    "\n",
    "# test_encoder = model_encoder_save.predict(test_autoencoder)\n",
    "# test_autoencoder = model_autoencoder_save.predict(test_autoencoder)\n",
    "\n",
    "# test_autoencoder_result = test_autoencoder.reshape(to_reshape[0], to_reshape[1], to_reshape[2])      "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# plt.imshow(test_autoencoder_result)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# plt.imshow(test_encoder)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "colab": {
   "collapsed_sections": [],
   "name": "deep-autoencoder.ipynb",
   "provenance": [],
   "toc_visible": true
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
