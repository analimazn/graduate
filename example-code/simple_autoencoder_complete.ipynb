{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"name":"simple_autoencoder_complete.ipynb","provenance":[],"collapsed_sections":[]},"kernelspec":{"name":"python3","display_name":"Python 3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.7.4"},"accelerator":"GPU"},"cells":[{"cell_type":"markdown","metadata":{"id":"2eQ4Xl0Zako4","colab_type":"text"},"source":["Import libs to metrify use of system"]},{"cell_type":"code","metadata":{"id":"-OSJmhDyakYV","colab_type":"code","outputId":"fbe0ed15-ddc3-425a-a9c5-c6ced905c23e","executionInfo":{"status":"ok","timestamp":1574623574593,"user_tz":180,"elapsed":12318,"user":{"displayName":"Ana Lima","photoUrl":"https://lh3.googleusercontent.com/a-/AAuE7mD_rVEqxF9pNV2UmDCr1wJi96KOZtAgLTRMQ_YImw=s64","userId":"16351871197992508535"}},"colab":{"base_uri":"https://localhost:8080/","height":573}},"source":["pip install line_profiler memory_profiler"],"execution_count":0,"outputs":[{"output_type":"stream","text":["Collecting line_profiler\n","\u001b[?25l  Downloading https://files.pythonhosted.org/packages/14/fc/ecf4e238bb601ff829068e5a72cd1bd67b0ee0ae379db172eb6a0779c6b6/line_profiler-2.1.2.tar.gz (83kB)\n","\u001b[K     |████████████████████████████████| 92kB 5.7MB/s \n","\u001b[?25hCollecting memory_profiler\n","\u001b[?25l  Downloading https://files.pythonhosted.org/packages/9f/fe/1fca7273dd111108f204a686b12a12b6422d405fe4614087aa7d5a66ea87/memory_profiler-0.55.0.tar.gz (40kB)\n","\u001b[K     |████████████████████████████████| 40kB 5.2MB/s \n","\u001b[?25hRequirement already satisfied: IPython>=0.13 in /usr/local/lib/python3.6/dist-packages (from line_profiler) (5.5.0)\n","Requirement already satisfied: psutil in /usr/local/lib/python3.6/dist-packages (from memory_profiler) (5.4.8)\n","Requirement already satisfied: pygments in /usr/local/lib/python3.6/dist-packages (from IPython>=0.13->line_profiler) (2.1.3)\n","Requirement already satisfied: setuptools>=18.5 in /usr/local/lib/python3.6/dist-packages (from IPython>=0.13->line_profiler) (41.6.0)\n","Requirement already satisfied: prompt-toolkit<2.0.0,>=1.0.4 in /usr/local/lib/python3.6/dist-packages (from IPython>=0.13->line_profiler) (1.0.18)\n","Requirement already satisfied: pexpect; sys_platform != \"win32\" in /usr/local/lib/python3.6/dist-packages (from IPython>=0.13->line_profiler) (4.7.0)\n","Requirement already satisfied: traitlets>=4.2 in /usr/local/lib/python3.6/dist-packages (from IPython>=0.13->line_profiler) (4.3.3)\n","Requirement already satisfied: simplegeneric>0.8 in /usr/local/lib/python3.6/dist-packages (from IPython>=0.13->line_profiler) (0.8.1)\n","Requirement already satisfied: decorator in /usr/local/lib/python3.6/dist-packages (from IPython>=0.13->line_profiler) (4.4.1)\n","Requirement already satisfied: pickleshare in /usr/local/lib/python3.6/dist-packages (from IPython>=0.13->line_profiler) (0.7.5)\n","Requirement already satisfied: wcwidth in /usr/local/lib/python3.6/dist-packages (from prompt-toolkit<2.0.0,>=1.0.4->IPython>=0.13->line_profiler) (0.1.7)\n","Requirement already satisfied: six>=1.9.0 in /usr/local/lib/python3.6/dist-packages (from prompt-toolkit<2.0.0,>=1.0.4->IPython>=0.13->line_profiler) (1.12.0)\n","Requirement already satisfied: ptyprocess>=0.5 in /usr/local/lib/python3.6/dist-packages (from pexpect; sys_platform != \"win32\"->IPython>=0.13->line_profiler) (0.6.0)\n","Requirement already satisfied: ipython-genutils in /usr/local/lib/python3.6/dist-packages (from traitlets>=4.2->IPython>=0.13->line_profiler) (0.2.0)\n","Building wheels for collected packages: line-profiler, memory-profiler\n","  Building wheel for line-profiler (setup.py) ... \u001b[?25l\u001b[?25hdone\n","  Created wheel for line-profiler: filename=line_profiler-2.1.2-cp36-cp36m-linux_x86_64.whl size=180890 sha256=897d6fdca71810591e6aeaa42b90b465c2f45829457b99321c7e5a468af55dbb\n","  Stored in directory: /root/.cache/pip/wheels/05/7d/9b/aafbe8d78dc2b2c644d2efd2f060ab3258143860142575193a\n","  Building wheel for memory-profiler (setup.py) ... \u001b[?25l\u001b[?25hdone\n","  Created wheel for memory-profiler: filename=memory_profiler-0.55.0-cp36-none-any.whl size=27174 sha256=8c938ffd5f1ad5a593a43570c19510372bc1e97a2e925f64b2fd26c6b5499186\n","  Stored in directory: /root/.cache/pip/wheels/f0/ff/63/fdbff3f1e1b76ad4eae491dd5b190902906b093e93eb86dd5a\n","Successfully built line-profiler memory-profiler\n","Installing collected packages: line-profiler, memory-profiler\n","Successfully installed line-profiler-2.1.2 memory-profiler-0.55.0\n"],"name":"stdout"}]},{"cell_type":"markdown","metadata":{"id":"memMf8xFQNsA","colab_type":"text"},"source":["Get initial informations about memory of system"]},{"cell_type":"code","metadata":{"id":"lUaDytZ6ynbu","colab_type":"code","outputId":"fbd8d26d-e3ea-46a6-e901-553a8d799a7e","executionInfo":{"status":"ok","timestamp":1574623598061,"user_tz":180,"elapsed":35770,"user":{"displayName":"Ana Lima","photoUrl":"https://lh3.googleusercontent.com/a-/AAuE7mD_rVEqxF9pNV2UmDCr1wJi96KOZtAgLTRMQ_YImw=s64","userId":"16351871197992508535"}},"colab":{"base_uri":"https://localhost:8080/","height":1000}},"source":["!lscpu |grep 'Model name'\n","!lscpu | grep 'Socket(s):'\n","!lscpu | grep 'Core(s) per socket:'\n","!lscpu | grep 'Thread(s) per core'\n","!lscpu | grep \"L3 cache\"\n","!lscpu | grep \"MHz\"\n","!cat /proc/meminfo | grep 'MemAvailable'\n","!df -h / | awk '{print $4}'\n","\n","!df -h\n","!cat /proc/cpuinfo\n","!cat /proc/meminfo"],"execution_count":0,"outputs":[{"output_type":"stream","text":["Model name:          Intel(R) Xeon(R) CPU @ 2.30GHz\n","Socket(s):           1\n","Core(s) per socket:  1\n","Thread(s) per core:  2\n","L3 cache:            46080K\n","CPU MHz:             2300.000\n","MemAvailable:   12348224 kB\n","Avail\n","308G\n","Filesystem      Size  Used Avail Use% Mounted on\n","overlay         359G   33G  308G  10% /\n","tmpfs            64M     0   64M   0% /dev\n","tmpfs           6.4G     0  6.4G   0% /sys/fs/cgroup\n","tmpfs           6.4G   12K  6.4G   1% /var/colab\n","/dev/sda1       365G   34G  332G  10% /opt/bin\n","shm             5.9G  4.0K  5.9G   1% /dev/shm\n","tmpfs           6.4G     0  6.4G   0% /proc/acpi\n","tmpfs           6.4G     0  6.4G   0% /proc/scsi\n","tmpfs           6.4G     0  6.4G   0% /sys/firmware\n","processor\t: 0\n","vendor_id\t: GenuineIntel\n","cpu family\t: 6\n","model\t\t: 63\n","model name\t: Intel(R) Xeon(R) CPU @ 2.30GHz\n","stepping\t: 0\n","microcode\t: 0x1\n","cpu MHz\t\t: 2300.000\n","cache size\t: 46080 KB\n","physical id\t: 0\n","siblings\t: 2\n","core id\t\t: 0\n","cpu cores\t: 1\n","apicid\t\t: 0\n","initial apicid\t: 0\n","fpu\t\t: yes\n","fpu_exception\t: yes\n","cpuid level\t: 13\n","wp\t\t: yes\n","flags\t\t: fpu vme de pse tsc msr pae mce cx8 apic sep mtrr pge mca cmov pat pse36 clflush mmx fxsr sse sse2 ss ht syscall nx pdpe1gb rdtscp lm constant_tsc rep_good nopl xtopology nonstop_tsc cpuid tsc_known_freq pni pclmulqdq ssse3 fma cx16 pcid sse4_1 sse4_2 x2apic movbe popcnt aes xsave avx f16c rdrand hypervisor lahf_lm abm invpcid_single ssbd ibrs ibpb stibp fsgsbase tsc_adjust bmi1 avx2 smep bmi2 erms invpcid xsaveopt arat md_clear arch_capabilities\n","bugs\t\t: cpu_meltdown spectre_v1 spectre_v2 spec_store_bypass l1tf mds swapgs\n","bogomips\t: 4600.00\n","clflush size\t: 64\n","cache_alignment\t: 64\n","address sizes\t: 46 bits physical, 48 bits virtual\n","power management:\n","\n","processor\t: 1\n","vendor_id\t: GenuineIntel\n","cpu family\t: 6\n","model\t\t: 63\n","model name\t: Intel(R) Xeon(R) CPU @ 2.30GHz\n","stepping\t: 0\n","microcode\t: 0x1\n","cpu MHz\t\t: 2300.000\n","cache size\t: 46080 KB\n","physical id\t: 0\n","siblings\t: 2\n","core id\t\t: 0\n","cpu cores\t: 1\n","apicid\t\t: 1\n","initial apicid\t: 1\n","fpu\t\t: yes\n","fpu_exception\t: yes\n","cpuid level\t: 13\n","wp\t\t: yes\n","flags\t\t: fpu vme de pse tsc msr pae mce cx8 apic sep mtrr pge mca cmov pat pse36 clflush mmx fxsr sse sse2 ss ht syscall nx pdpe1gb rdtscp lm constant_tsc rep_good nopl xtopology nonstop_tsc cpuid tsc_known_freq pni pclmulqdq ssse3 fma cx16 pcid sse4_1 sse4_2 x2apic movbe popcnt aes xsave avx f16c rdrand hypervisor lahf_lm abm invpcid_single ssbd ibrs ibpb stibp fsgsbase tsc_adjust bmi1 avx2 smep bmi2 erms invpcid xsaveopt arat md_clear arch_capabilities\n","bugs\t\t: cpu_meltdown spectre_v1 spectre_v2 spec_store_bypass l1tf mds swapgs\n","bogomips\t: 4600.00\n","clflush size\t: 64\n","cache_alignment\t: 64\n","address sizes\t: 46 bits physical, 48 bits virtual\n","power management:\n","\n","MemTotal:       13335180 kB\n","MemFree:        10217436 kB\n","MemAvailable:   12352132 kB\n","Buffers:           80616 kB\n","Cached:          2170252 kB\n","SwapCached:            0 kB\n","Active:           883404 kB\n","Inactive:        1941608 kB\n","Active(anon):     518992 kB\n","Inactive(anon):      328 kB\n","Active(file):     364412 kB\n","Inactive(file):  1941280 kB\n","Unevictable:           0 kB\n","Mlocked:               0 kB\n","SwapTotal:             0 kB\n","SwapFree:              0 kB\n","Dirty:              1960 kB\n","Writeback:             0 kB\n","AnonPages:        574016 kB\n","Mapped:           345032 kB\n","Shmem:               896 kB\n","Slab:             174348 kB\n","SReclaimable:     140040 kB\n","SUnreclaim:        34308 kB\n","KernelStack:        3584 kB\n","PageTables:         6884 kB\n","NFS_Unstable:          0 kB\n","Bounce:                0 kB\n","WritebackTmp:          0 kB\n","CommitLimit:     6667588 kB\n","Committed_AS:    2978836 kB\n","VmallocTotal:   34359738367 kB\n","VmallocUsed:           0 kB\n","VmallocChunk:          0 kB\n","AnonHugePages:         0 kB\n","ShmemHugePages:        0 kB\n","ShmemPmdMapped:        0 kB\n","HugePages_Total:       0\n","HugePages_Free:        0\n","HugePages_Rsvd:        0\n","HugePages_Surp:        0\n","Hugepagesize:       2048 kB\n","DirectMap4k:       92148 kB\n","DirectMap2M:     5150720 kB\n","DirectMap1G:    10485760 kB\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"7ylAdrZ_yBGA","colab_type":"code","outputId":"a88357c2-e0c8-4cab-eb62-c0d8276a9059","executionInfo":{"status":"ok","timestamp":1574623598071,"user_tz":180,"elapsed":35747,"user":{"displayName":"Ana Lima","photoUrl":"https://lh3.googleusercontent.com/a-/AAuE7mD_rVEqxF9pNV2UmDCr1wJi96KOZtAgLTRMQ_YImw=s64","userId":"16351871197992508535"}},"colab":{"base_uri":"https://localhost:8080/","height":55}},"source":["from psutil import *\n","\n","cpu_count()\n","cpu_stats()\n","virtual_memory()"],"execution_count":0,"outputs":[{"output_type":"execute_result","data":{"text/plain":["svmem(total=13655224320, available=12651065344, percent=7.4, used=741797888, free=10465120256, active=903770112, inactive=1988222976, buffers=82550784, cached=2365755392, shared=917504, slab=178429952)"]},"metadata":{"tags":[]},"execution_count":10}]},{"cell_type":"markdown","metadata":{"colab_type":"text","id":"me82Mq_lNBXr"},"source":["**Deep Autoencoder**\n","\n","Use to encoder and autoencoder images with different sizes."]},{"cell_type":"markdown","metadata":{"id":"9JmR3qeh8ApC","colab_type":"text"},"source":["Install libs"]},{"cell_type":"code","metadata":{"id":"UvxJ2HVk78hR","colab_type":"code","outputId":"a4703fe5-e838-4283-89a1-1ab7ab2107eb","executionInfo":{"status":"ok","timestamp":1574623602287,"user_tz":180,"elapsed":39952,"user":{"displayName":"Ana Lima","photoUrl":"https://lh3.googleusercontent.com/a-/AAuE7mD_rVEqxF9pNV2UmDCr1wJi96KOZtAgLTRMQ_YImw=s64","userId":"16351871197992508535"}},"colab":{"base_uri":"https://localhost:8080/","height":519}},"source":["pip install PyYAML numpy matplotlib tensorflow"],"execution_count":0,"outputs":[{"output_type":"stream","text":["Requirement already satisfied: PyYAML in /usr/local/lib/python3.6/dist-packages (3.13)\n","Requirement already satisfied: numpy in /usr/local/lib/python3.6/dist-packages (1.17.4)\n","Requirement already satisfied: matplotlib in /usr/local/lib/python3.6/dist-packages (3.1.1)\n","Requirement already satisfied: tensorflow in /usr/local/lib/python3.6/dist-packages (1.15.0)\n","Requirement already satisfied: pyparsing!=2.0.4,!=2.1.2,!=2.1.6,>=2.0.1 in /usr/local/lib/python3.6/dist-packages (from matplotlib) (2.4.5)\n","Requirement already satisfied: cycler>=0.10 in /usr/local/lib/python3.6/dist-packages (from matplotlib) (0.10.0)\n","Requirement already satisfied: kiwisolver>=1.0.1 in /usr/local/lib/python3.6/dist-packages (from matplotlib) (1.1.0)\n","Requirement already satisfied: python-dateutil>=2.1 in /usr/local/lib/python3.6/dist-packages (from matplotlib) (2.6.1)\n","Requirement already satisfied: protobuf>=3.6.1 in /usr/local/lib/python3.6/dist-packages (from tensorflow) (3.10.0)\n","Requirement already satisfied: six>=1.10.0 in /usr/local/lib/python3.6/dist-packages (from tensorflow) (1.12.0)\n","Requirement already satisfied: keras-applications>=1.0.8 in /usr/local/lib/python3.6/dist-packages (from tensorflow) (1.0.8)\n","Requirement already satisfied: opt-einsum>=2.3.2 in /usr/local/lib/python3.6/dist-packages (from tensorflow) (3.1.0)\n","Requirement already satisfied: wheel>=0.26 in /usr/local/lib/python3.6/dist-packages (from tensorflow) (0.33.6)\n","Requirement already satisfied: keras-preprocessing>=1.0.5 in /usr/local/lib/python3.6/dist-packages (from tensorflow) (1.1.0)\n","Requirement already satisfied: termcolor>=1.1.0 in /usr/local/lib/python3.6/dist-packages (from tensorflow) (1.1.0)\n","Requirement already satisfied: google-pasta>=0.1.6 in /usr/local/lib/python3.6/dist-packages (from tensorflow) (0.1.8)\n","Requirement already satisfied: gast==0.2.2 in /usr/local/lib/python3.6/dist-packages (from tensorflow) (0.2.2)\n","Requirement already satisfied: tensorflow-estimator==1.15.1 in /usr/local/lib/python3.6/dist-packages (from tensorflow) (1.15.1)\n","Requirement already satisfied: tensorboard<1.16.0,>=1.15.0 in /usr/local/lib/python3.6/dist-packages (from tensorflow) (1.15.0)\n","Requirement already satisfied: grpcio>=1.8.6 in /usr/local/lib/python3.6/dist-packages (from tensorflow) (1.15.0)\n","Requirement already satisfied: astor>=0.6.0 in /usr/local/lib/python3.6/dist-packages (from tensorflow) (0.8.0)\n","Requirement already satisfied: wrapt>=1.11.1 in /usr/local/lib/python3.6/dist-packages (from tensorflow) (1.11.2)\n","Requirement already satisfied: absl-py>=0.7.0 in /usr/local/lib/python3.6/dist-packages (from tensorflow) (0.8.1)\n","Requirement already satisfied: setuptools in /usr/local/lib/python3.6/dist-packages (from kiwisolver>=1.0.1->matplotlib) (41.6.0)\n","Requirement already satisfied: h5py in /usr/local/lib/python3.6/dist-packages (from keras-applications>=1.0.8->tensorflow) (2.8.0)\n","Requirement already satisfied: werkzeug>=0.11.15 in /usr/local/lib/python3.6/dist-packages (from tensorboard<1.16.0,>=1.15.0->tensorflow) (0.16.0)\n","Requirement already satisfied: markdown>=2.6.8 in /usr/local/lib/python3.6/dist-packages (from tensorboard<1.16.0,>=1.15.0->tensorflow) (3.1.1)\n"],"name":"stdout"}]},{"cell_type":"markdown","metadata":{"colab_type":"text","id":"YFUNFKLQO5cw"},"source":["Import libs"]},{"cell_type":"code","metadata":{"colab_type":"code","id":"GYlaNZAWMwnL","colab":{}},"source":["# Numpy Matplot cv2\n","import numpy as np\n","import matplotlib.pyplot as plt\n","import matplotlib.image as mpimg\n","from google.colab.patches import cv2_imshow\n","import cv2\n","\n","# Tensorflow and Keras\n","from tensorflow.keras.preprocessing.image import ImageDataGenerator\n","from tensorflow.keras.layers import Dense, Input, Dropout\n","from tensorflow.keras.models import Model, Sequential, load_model, model_from_yaml, model_from_json\n","from tensorflow.keras.applications.inception_v3 import preprocess_input\n","from tensorflow.keras.callbacks import *\n","\n","# OS libs\n","import os\n","import json\n","import time\n","import datetime"],"execution_count":0,"outputs":[]},{"cell_type":"markdown","metadata":{"colab_type":"text","id":"OnWzecItTQ9g"},"source":["Directories"]},{"cell_type":"code","metadata":{"colab_type":"code","id":"bFpUqpOWTRVn","colab":{}},"source":["data_png = './data_png'\n","data_npy = './data_npy/'\n","results_png = './results_png/'\n","metrics_png = './metrics_png/'\n","models_h5 = './models_h5/'\n","models_yml = './models_yml/'\n","shapes_sizes_json = './shapes_sizes_json/'\n","# dataset = './dataset'\n","# data = './data'\n"],"execution_count":0,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"qV-YundJj-v4","colab_type":"text"},"source":["Create directores after reset colab notebook"]},{"cell_type":"code","metadata":{"id":"NnOmwrzaj-cE","colab_type":"code","colab":{}},"source":["# try:\n","#     os.mkdir(data_png)\n","#     os.mkdir(data_npy)\n","#     os.mkdir(results_png)\n","#     os.mkdir(metrics_png)\n","#     os.mkdir(models_h5)\n","#     os.mkdir(models_yml)\n","#     os.mkdir(shapes_sizes_json)\n","# except OSError:\n","#     print (\"Creation of the directory %s failed\" % data_png)\n","#     print (\"Creation of the directory %s failed\" % data_npy)\n","#     print (\"Creation of the directory %s failed\" % results_png)\n","#     print (\"Creation of the directory %s failed\" % metrics_png)\n","#     print (\"Creation of the directory %s failed\" % models_h5)\n","#     print (\"Creation of the directory %s failed\" % models_yml)\n","#     print (\"Creation of the directory %s failed\" % shapes_sizes_json)\n","# else:\n","#     print (\"Successfully created the directory %s \" % data_png)   \n","#     print (\"Successfully created the directory %s \" % data_npy)   \n","#     print (\"Successfully created the directory %s \" % results_png)   \n","#     print (\"Successfully created the directory %s \" % metrics_png)   \n","#     print (\"Successfully created the directory %s \" % models_h5)   \n","#     print (\"Successfully created the directory %s \" % models_yml)   \n","#     print (\"Successfully created the directory %s \" % shapes_sizes_json)   "],"execution_count":0,"outputs":[]},{"cell_type":"markdown","metadata":{"colab_type":"text","id":"lgIB5XwhgiMa"},"source":["Utils"]},{"cell_type":"code","metadata":{"colab_type":"code","id":"jdGwsxqOglCx","colab":{}},"source":["def plot_metrics_history_subplot(history, name):\n","    fig, (ax1, ax2) = plt.subplots(1, 2)\n","\n","    # Plot training & validation accuracy values\n","    ax1.plot(history.history['acc'])\n","    ax1.plot(history.history['val_acc'])\n","    ax1.set_title('Model accuracy')\n","    ax1.legend(['Train', 'Test'], loc='upper right')\n","\n","    # Plot training & validation loss values\n","    ax2.plot(history.history['loss'])\n","    ax2.plot(history.history['val_loss'])\n","    ax2.set_title('Model loss')\n","    ax2.legend(['Train', 'Test'], loc='upper right')\n","\n","    fig.savefig(metrics_png + 'history_subplot_' + name)\n","\n","def plot_metrics_history(history, name):    \n","    fig = plt.figure()\n","    \n","    # Plot training & validation accuracy values\n","    plt.plot(history.history['acc'])\n","    plt.plot(history.history['val_acc'])\n","    plt.title('Model accuracy')\n","    plt.ylabel('Accuracy')\n","    plt.xlabel('Epoch')\n","    plt.legend(['Train', 'Test'], loc='upper right')\n","    plt.show()\n","    fig.savefig(metrics_png + 'history_acc_' + name)\n","\n","    fig = plt.figure()\n","\n","    # Plot training & validation loss values\n","    plt.plot(history.history['loss'])\n","    plt.plot(history.history['val_loss'])\n","    plt.title('Model loss')\n","    plt.ylabel('Loss')\n","    plt.xlabel('Epoch')\n","    plt.legend(['Train', 'Test'], loc='upper right')\n","    plt.show()\n","    fig.savefig(metrics_png + 'history_loss_' + name)\n","\n","def plot_metrics_evaluate_all(model, name):\n","    fig = plt.figure()\n","\n","    loss = model[0]\n","    accuracy = model[1]\n","\n","    plt.plot([0, 100], [0, loss * 100])\n","    plt.plot([0, 100], [0, accuracy * 100])\n","    plt.title('Loss: %.2f%% | Accuracy: %.2f%%' % ( loss * 100,  accuracy * 100 ))\n","    plt.legend(['Loss', 'Accuracy'], loc='upper right')\n","    plt.show()\n","    \n","    fig.savefig(metrics_png + 'evaluate_loss_accuracy' + name)\n","\n","def plot_metrics_evaluate(model, name):\n","    fig, (ax1, ax2) = plt.subplots(1, 2)\n","    loss = model[0]\n","    accuracy = model[1]\n","\n","    ax1.plot([0, 100], [0, loss * 100])\n","    ax1.set_title('Loss: %.2f%%' % ( loss * 100 ))\n","    ax1.legend(['Loss'], loc='upper right')\n","\n","    ax2.plot([0, 100], [0, accuracy * 100])\n","    ax2.set_title('Accuracy: %.2f%%' % ( accuracy * 100 ))\n","    ax2.legend(['Accuracy'], loc='upper right')\n","    \n","    fig.savefig(metrics_png + 'evaluate_acc_' + name)\n","\n","def plot_all(images):\n","    fig = plt.figure(figsize=(32, 32))\n","    number_rows = int(len(images)/3) + 1\n","    \n","    for index in range(len(images)):\n","        a = fig.add_subplot(number_rows, 3, index+1)\n","        plt.imshow(images[index])\n","        plt.title(f'{index}:{images[index].shape}')\n","        a.axis('off')\n","    \n","    fig.savefig(results_png + 'compare_all_images.png')\n","    plt.show()\n","\n","def save_image(name, image):        \n","    mpimg.imsave(results_png + name, image)\n","\n","def save_npy(name, image): \n","    name = name[:-4]\n","    np.save(data_npy + name + '.npy', image)\n","\n","def save_json(name, shape, size): \n","    name = name[:-4]\n","\n","    data = {\n","        \"rows\": shape[0],\n","        \"columns\": shape[1],\n","        \"channels\": shape[2],\n","        \"size\": size,\n","        \"shape\": shape\n","    }\n","\n","    with open(shapes_sizes_json + 'original_' + name + '.json', 'w') as outfile:\n","        json.dump(data, outfile)\n","\n","# def resized_images():\n","#     file = os.listdir(data)\n","#     size = sum(1 for img in file)\n","\n","#     train_datagen = ImageDataGenerator(preprocessing_function = preprocess_input)\n","\n","#     train_generator = train_datagen.flow_from_directory(\n","#         data,\n","#         target_size=(256, 256),\n","#         save_to_dir=dataset,\n","#         batch_size=64,\n","#         class_mode='input',\n","#         color_mode='rgba')\n","\n","#     index = 0\n","#     for batch in train_generator:\n","#         index += 1\n","#         if index <= size:\n","#             break"],"execution_count":0,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"CjFKTa5O4gFj","colab_type":"text"},"source":["Class TimeHistory"]},{"cell_type":"code","metadata":{"id":"NWb2b_g54f3N","colab_type":"code","colab":{}},"source":["class TimingCallback(Callback):\n","  def __init__(self):\n","    self.times = []\n","  def on_epoch_begin(self, epoch, logs={}):\n","    self.start_time = time.time()\n","  def on_epoch_end(self, epoch, logs={}):\n","    self.times.append(time.time() - self.start_time)\n","\n","time_callback = TimingCallback()"],"execution_count":0,"outputs":[]},{"cell_type":"markdown","metadata":{"colab_type":"text","id":"ZSTjBwlIf3qf"},"source":["Class DeepAutoencoder"]},{"cell_type":"code","metadata":{"colab_type":"code","id":"zwkxYHUUf70V","colab":{}},"source":["class SimpleAutoencoder(object):\n","\n","    def __init__(self, input_dim, encoded_dim):    \n","        input_layer = Input(shape=(input_dim,))\n","        hidden_input = Input(shape=(encoded_dim,))\n","        hidden_layer = Dense(encoded_dim, activation='relu')(input_layer)\n","        output_layer = Dense(input_dim, activation='sigmoid')(hidden_layer)\n","\n","        self.autoencoder = Model(input_layer, output_layer)\n","        self.encoder = Model(input_layer, hidden_layer)\n","        tmp_decoder_layer = self.autoencoder.layers[-1]\n","        self.decoder = Model(hidden_input, tmp_decoder_layer(hidden_input))\n","\n","        self.autoencoder.compile(optimizer='adam', loss='binary_crossentropy', metrics = ['accuracy'])\n","\n","    def train(self, input_train, input_test, batch_size, epochs):    \n","        self.autoencoder.fit(input_train, \n","                                    input_train,\n","                                    epochs=epochs,\n","                                    batch_size=batch_size,\n","                                    shuffle=True,\n","                                    validation_data=(\n","                                            input_test, \n","                                            input_test),\n","                                    callbacks=[time_callback])\n","        \n","    def get_encoded_image(self, image):\n","        encoded_image = self.encoder.predict(image)\n","        return encoded_image\n","    \n","    def get_decoded_image(self, encoded_imgs):\n","        decoded_image = self.decoder.predict(encoded_imgs)\n","        return decoded_image\n","\n","    def get_evaluate_model(self, train, test):\n","        return self.autoencoder.evaluate(train, test)\n","\n","    def get_history_model(self):\n","        return self.autoencoder.history\n","    \n","    def save_model(self, name):\n","        name = name[:-4]\n","        self.autoencoder.save(models_h5 + 'autoencoder_' + name + '.h5')\n","        self.encoder.save(models_h5 + 'encoder_' + name + '.h5')\n","        self.decoder.save(models_h5 + 'decoder_' + name + '.h5')\n","\n","    def save_model_to_yml(self, name):\n","        name = name[:-4]\n","        model_yaml = self.autoencoder.to_yaml()\n","        with open(models_yml + 'autoencoder_' + name + '.yaml', 'w') as yaml_file:\n","            yaml_file.write(model_yaml)"],"execution_count":0,"outputs":[]},{"cell_type":"markdown","metadata":{"colab_type":"text","id":"iDquENhxjlFg"},"source":["Class main()"]},{"cell_type":"code","metadata":{"colab_type":"code","id":"nltJyhIIjpxj","colab":{}},"source":["def main():\n","    images = []\n","    historic = []\n","    results = []\n","    \n","    for img in os.listdir(data_png):\n","        try:\n","            # Normalização das imagens   \n","            img_train = mpimg.imread((os.path.join(data_png, img)))  \n","            max_train_value = float(img_train.max())\n","            train = img_train.astype('float32') / max_train_value\n","            train = train.reshape((len(train), np.prod(train.shape[1:])))\n","            \n","            img_test = mpimg.imread((os.path.join(data_png, img)))\n","            max_test_value = float(img_test.max())\n","            test = img_test.astype('float32') / max_test_value\n","            test = test.reshape((len(test), np.prod(test.shape[1:])))\n","\n","            # Envio da imagem para a classe DeepAutoencoder\n","            autoencoder = SimpleAutoencoder(train.shape[1], 64)\n","            autoencoder.train(train, test, 64, 1500)\n","            \n","            encoded_img = autoencoder.get_encoded_image(test)\n","            decoded_img = autoencoder.get_decoded_image(encoded_img)\n","\n","            autoencoder_history = autoencoder.get_history_model()\n","            autoencoder_evaluate = autoencoder.get_evaluate_model(train, test)\n","            \n","            autoencoder.save_model(img)\n","            autoencoder.save_model_to_yml(img)\n","            \n","            plot_metrics_history(autoencoder_history, 'autoencoder' + img)\n","            plot_metrics_history_subplot(autoencoder_history, 'autoencoder' + img)\n","            plot_metrics_evaluate(autoencoder_evaluate, 'autoencoder' + img)\n","            plot_metrics_evaluate_all(autoencoder_evaluate, 'autoencoder' + img)\n","\n","            # Dimensões da imagem original\n","            image_shape = img_test.shape\n","            size_image = img_test.size\n","\n","            # Redimensionamento das imagens obtidas\n","            original_result = test.reshape(image_shape[0], image_shape[1], image_shape[2])\n","            decoded_img_result = decoded_img.reshape(image_shape[0], image_shape[1], image_shape[2])      \n","\n","            images.append(original_result)\n","            images.append(encoded_img)\n","            images.append(decoded_img_result)\n","\n","            save_image('original_' + img, original_result)\n","            save_image('encoded_' + img, encoded_img)\n","            save_image('decoded_' + img, decoded_img_result)\n","            \n","            save_npy(img, encoded_img)\n","            save_json(img, image_shape, size_image)\n","            \n","            #Print average of the time for each layer\n","            results.append(np.average(time_callback.times))\n","            seconds = np.average(time_callback.times)\n","            result_time = str(datetime.timedelta(seconds=seconds))\n","            print(\"Medium time:\", result_time)\t\n","\n","        except Exception as e:\n","            print(e)\n","            pass\n","\n","    plot_all(images)\n","    return"],"execution_count":0,"outputs":[]},{"cell_type":"markdown","metadata":{"colab_type":"text","id":"Bu6haEdpfTxG"},"source":["Reload files to get time of use and memory"]},{"cell_type":"code","metadata":{"id":"2mqOojzop09v","colab_type":"code","colab":{}},"source":["%reload_ext line_profiler\n","%reload_ext memory_profiler"],"execution_count":0,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"lGHtcUjql3k3","colab_type":"text"},"source":["Get time of processing"]},{"cell_type":"code","metadata":{"id":"4CojNHL1O_G2","colab_type":"code","colab":{}},"source":["# Get time process\n","\n","# %lprun -f main main()"],"execution_count":0,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"N9hFwbTFl6dC","colab_type":"text"},"source":["Get use of memory of processing"]},{"cell_type":"code","metadata":{"colab_type":"code","id":"z9c5R134fzJk","outputId":"e59fab62-d0b3-4ba7-b72d-87af3d915d23","colab":{"base_uri":"https://localhost:8080/","height":1000}},"source":["# Get memory process\n","\n","from deep_autoencoder import main\n","%mprun -f main main()"],"execution_count":0,"outputs":[{"output_type":"stream","text":["WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/tensorflow_core/python/ops/resource_variable_ops.py:1630: calling BaseResourceVariable.__init__ (from tensorflow.python.ops.resource_variable_ops) with constraint is deprecated and will be removed in a future version.\n","Instructions for updating:\n","If using Keras pass *_constraint arguments to layers.\n","Model: \"model\"\n","_________________________________________________________________\n","Layer (type)                 Output Shape              Param #   \n","=================================================================\n","input_1 (InputLayer)         [(None, 24004)]           0         \n","_________________________________________________________________\n","dense (Dense)                (None, 512)               12290560  \n","_________________________________________________________________\n","dense_1 (Dense)              (None, 384)               196992    \n","_________________________________________________________________\n","dense_2 (Dense)              (None, 256)               98560     \n","_________________________________________________________________\n","dense_3 (Dense)              (None, 128)               32896     \n","_________________________________________________________________\n","dense_4 (Dense)              (None, 64)                8256      \n","_________________________________________________________________\n","dense_5 (Dense)              (None, 128)               8320      \n","_________________________________________________________________\n","dense_6 (Dense)              (None, 256)               33024     \n","_________________________________________________________________\n","dense_7 (Dense)              (None, 384)               98688     \n","_________________________________________________________________\n","dense_8 (Dense)              (None, 512)               197120    \n","_________________________________________________________________\n","dense_9 (Dense)              (None, 24004)             12314052  \n","=================================================================\n","Total params: 25,278,468\n","Trainable params: 25,278,468\n","Non-trainable params: 0\n","_________________________________________________________________\n","Model: \"model_1\"\n","_________________________________________________________________\n","Layer (type)                 Output Shape              Param #   \n","=================================================================\n","input_1 (InputLayer)         [(None, 24004)]           0         \n","_________________________________________________________________\n","dense (Dense)                (None, 512)               12290560  \n","_________________________________________________________________\n","dense_1 (Dense)              (None, 384)               196992    \n","_________________________________________________________________\n","dense_2 (Dense)              (None, 256)               98560     \n","_________________________________________________________________\n","dense_3 (Dense)              (None, 128)               32896     \n","_________________________________________________________________\n","dense_4 (Dense)              (None, 64)                8256      \n","=================================================================\n","Total params: 12,627,264\n","Trainable params: 12,627,264\n","Non-trainable params: 0\n","_________________________________________________________________\n","Model: \"model_2\"\n","_________________________________________________________________\n","Layer (type)                 Output Shape              Param #   \n","=================================================================\n","input_2 (InputLayer)         [(None, 64)]              0         \n","_________________________________________________________________\n","dense_5 (Dense)              (None, 128)               8320      \n","_________________________________________________________________\n","dense_6 (Dense)              (None, 256)               33024     \n","_________________________________________________________________\n","dense_7 (Dense)              (None, 384)               98688     \n","_________________________________________________________________\n","dense_8 (Dense)              (None, 512)               197120    \n","_________________________________________________________________\n","dense_9 (Dense)              (None, 24004)             12314052  \n","=================================================================\n","Total params: 12,651,204\n","Trainable params: 12,651,204\n","Non-trainable params: 0\n","_________________________________________________________________\n","WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/tensorflow_core/python/ops/nn_impl.py:183: where (from tensorflow.python.ops.array_ops) is deprecated and will be removed in a future version.\n","Instructions for updating:\n","Use tf.where in 2.0, which has the same broadcast rule as np.where\n","Train on 5501 samples, validate on 5501 samples\n","Epoch 1/1500\n","5501/5501 [==============================] - 5s 861us/sample - loss: 0.4767 - acc: 0.3719 - val_loss: 0.4469 - val_acc: 0.3832\n","Epoch 2/1500\n","5501/5501 [==============================] - 4s 655us/sample - loss: 0.4370 - acc: 0.3844 - val_loss: 0.4245 - val_acc: 0.3858\n","Epoch 3/1500\n","5501/5501 [==============================] - 4s 660us/sample - loss: 0.4141 - acc: 0.3858 - val_loss: 0.4045 - val_acc: 0.3867\n","Epoch 4/1500\n","5501/5501 [==============================] - 4s 668us/sample - loss: 0.4005 - acc: 0.3867 - val_loss: 0.3964 - val_acc: 0.3872\n","Epoch 5/1500\n","5501/5501 [==============================] - 4s 665us/sample - loss: 0.3965 - acc: 0.3872 - val_loss: 0.3941 - val_acc: 0.3877\n","Epoch 6/1500\n","5501/5501 [==============================] - 4s 656us/sample - loss: 0.3910 - acc: 0.3876 - val_loss: 0.3891 - val_acc: 0.3879\n","Epoch 7/1500\n","5501/5501 [==============================] - 4s 660us/sample - loss: 0.3890 - acc: 0.3879 - val_loss: 0.3872 - val_acc: 0.3882\n","Epoch 8/1500\n","5501/5501 [==============================] - 4s 664us/sample - loss: 0.3873 - acc: 0.3881 - val_loss: 0.3866 - val_acc: 0.3882\n","Epoch 9/1500\n","5501/5501 [==============================] - 4s 659us/sample - loss: 0.3877 - acc: 0.3881 - val_loss: 0.3873 - val_acc: 0.3883\n","Epoch 10/1500\n","5501/5501 [==============================] - 4s 657us/sample - loss: 0.3846 - acc: 0.3883 - val_loss: 0.3833 - val_acc: 0.3886\n","Epoch 11/1500\n","5501/5501 [==============================] - 4s 656us/sample - loss: 0.3840 - acc: 0.3884 - val_loss: 0.3835 - val_acc: 0.3885\n","Epoch 12/1500\n","5501/5501 [==============================] - 4s 656us/sample - loss: 0.3831 - acc: 0.3885 - val_loss: 0.3821 - val_acc: 0.3887\n","Epoch 13/1500\n","5501/5501 [==============================] - 4s 660us/sample - loss: 0.3818 - acc: 0.3886 - val_loss: 0.3813 - val_acc: 0.3887\n","Epoch 14/1500\n","5501/5501 [==============================] - 4s 659us/sample - loss: 0.3813 - acc: 0.3887 - val_loss: 0.3814 - val_acc: 0.3888\n","Epoch 15/1500\n","5501/5501 [==============================] - 4s 665us/sample - loss: 0.3811 - acc: 0.3887 - val_loss: 0.3809 - val_acc: 0.3887\n","Epoch 16/1500\n","5501/5501 [==============================] - 4s 658us/sample - loss: 0.3814 - acc: 0.3887 - val_loss: 0.3795 - val_acc: 0.3889\n","Epoch 17/1500\n","5501/5501 [==============================] - 4s 661us/sample - loss: 0.3796 - acc: 0.3888 - val_loss: 0.3787 - val_acc: 0.3889\n","Epoch 18/1500\n","5501/5501 [==============================] - 4s 661us/sample - loss: 0.3787 - acc: 0.3889 - val_loss: 0.3781 - val_acc: 0.3890\n","Epoch 19/1500\n","5501/5501 [==============================] - 4s 665us/sample - loss: 0.3795 - acc: 0.3889 - val_loss: 0.3790 - val_acc: 0.3889\n","Epoch 20/1500\n","5501/5501 [==============================] - 4s 661us/sample - loss: 0.3807 - acc: 0.3888 - val_loss: 0.3805 - val_acc: 0.3888\n","Epoch 21/1500\n","5501/5501 [==============================] - 4s 661us/sample - loss: 0.3805 - acc: 0.3888 - val_loss: 0.3777 - val_acc: 0.3890\n","Epoch 22/1500\n","5501/5501 [==============================] - 4s 666us/sample - loss: 0.3787 - acc: 0.3889 - val_loss: 0.3777 - val_acc: 0.3890\n","Epoch 23/1500\n","5501/5501 [==============================] - 4s 667us/sample - loss: 0.3773 - acc: 0.3890 - val_loss: 0.3767 - val_acc: 0.3891\n","Epoch 24/1500\n","5501/5501 [==============================] - 4s 669us/sample - loss: 0.3768 - acc: 0.3891 - val_loss: 0.3768 - val_acc: 0.3891\n","Epoch 25/1500\n","5501/5501 [==============================] - 4s 659us/sample - loss: 0.3772 - acc: 0.3891 - val_loss: 0.3764 - val_acc: 0.3892\n","Epoch 26/1500\n","5501/5501 [==============================] - 4s 663us/sample - loss: 0.3765 - acc: 0.3891 - val_loss: 0.3759 - val_acc: 0.3893\n","Epoch 27/1500\n","5501/5501 [==============================] - 4s 660us/sample - loss: 0.3762 - acc: 0.3892 - val_loss: 0.3758 - val_acc: 0.3892\n","Epoch 28/1500\n","5501/5501 [==============================] - 4s 655us/sample - loss: 0.3766 - acc: 0.3891 - val_loss: 0.3764 - val_acc: 0.3892\n","Epoch 29/1500\n","5501/5501 [==============================] - 4s 658us/sample - loss: 0.3768 - acc: 0.3891 - val_loss: 0.3764 - val_acc: 0.3893\n","Epoch 30/1500\n","5501/5501 [==============================] - 4s 661us/sample - loss: 0.3765 - acc: 0.3892 - val_loss: 0.3756 - val_acc: 0.3893\n","Epoch 31/1500\n","5501/5501 [==============================] - 4s 657us/sample - loss: 0.3755 - acc: 0.3893 - val_loss: 0.3746 - val_acc: 0.3894\n","Epoch 32/1500\n","5501/5501 [==============================] - 4s 662us/sample - loss: 0.3753 - acc: 0.3893 - val_loss: 0.3752 - val_acc: 0.3893\n","Epoch 33/1500\n","5501/5501 [==============================] - 4s 668us/sample - loss: 0.3758 - acc: 0.3892 - val_loss: 0.3761 - val_acc: 0.3893\n","Epoch 34/1500\n","5501/5501 [==============================] - 4s 662us/sample - loss: 0.3763 - acc: 0.3892 - val_loss: 0.3763 - val_acc: 0.3892\n","Epoch 35/1500\n","5501/5501 [==============================] - 4s 654us/sample - loss: 0.3758 - acc: 0.3892 - val_loss: 0.3754 - val_acc: 0.3893\n","Epoch 36/1500\n","5501/5501 [==============================] - 4s 667us/sample - loss: 0.3752 - acc: 0.3893 - val_loss: 0.3746 - val_acc: 0.3894\n","Epoch 37/1500\n","5501/5501 [==============================] - 4s 661us/sample - loss: 0.3747 - acc: 0.3893 - val_loss: 0.3744 - val_acc: 0.3894\n","Epoch 38/1500\n","5501/5501 [==============================] - 4s 656us/sample - loss: 0.3744 - acc: 0.3894 - val_loss: 0.3757 - val_acc: 0.3893\n","Epoch 39/1500\n","5501/5501 [==============================] - 4s 673us/sample - loss: 0.3783 - acc: 0.3890 - val_loss: 0.3876 - val_acc: 0.3884\n","Epoch 40/1500\n","5501/5501 [==============================] - 4s 674us/sample - loss: 0.3846 - acc: 0.3884 - val_loss: 0.3768 - val_acc: 0.3892\n","Epoch 41/1500\n","5501/5501 [==============================] - 4s 667us/sample - loss: 0.3751 - acc: 0.3893 - val_loss: 0.3743 - val_acc: 0.3894\n","Epoch 42/1500\n","5501/5501 [==============================] - 4s 649us/sample - loss: 0.3741 - acc: 0.3894 - val_loss: 0.3733 - val_acc: 0.3895\n","Epoch 43/1500\n","5501/5501 [==============================] - 4s 656us/sample - loss: 0.3736 - acc: 0.3894 - val_loss: 0.3734 - val_acc: 0.3895\n","Epoch 44/1500\n","5501/5501 [==============================] - 4s 653us/sample - loss: 0.3737 - acc: 0.3894 - val_loss: 0.3732 - val_acc: 0.3895\n","Epoch 45/1500\n","5501/5501 [==============================] - 4s 654us/sample - loss: 0.3733 - acc: 0.3895 - val_loss: 0.3726 - val_acc: 0.3896\n","Epoch 46/1500\n","5501/5501 [==============================] - 4s 659us/sample - loss: 0.3730 - acc: 0.3895 - val_loss: 0.3726 - val_acc: 0.3896\n","Epoch 47/1500\n","5501/5501 [==============================] - 4s 661us/sample - loss: 0.3729 - acc: 0.3895 - val_loss: 0.3727 - val_acc: 0.3896\n","Epoch 48/1500\n","5501/5501 [==============================] - 4s 660us/sample - loss: 0.3734 - acc: 0.3895 - val_loss: 0.3736 - val_acc: 0.3895\n","Epoch 49/1500\n","5501/5501 [==============================] - 4s 659us/sample - loss: 0.3741 - acc: 0.3894 - val_loss: 0.3742 - val_acc: 0.3894\n","Epoch 50/1500\n","5501/5501 [==============================] - 4s 657us/sample - loss: 0.3741 - acc: 0.3894 - val_loss: 0.3730 - val_acc: 0.3895\n","Epoch 51/1500\n","5501/5501 [==============================] - 4s 657us/sample - loss: 0.3729 - acc: 0.3895 - val_loss: 0.3722 - val_acc: 0.3896\n","Epoch 52/1500\n","5501/5501 [==============================] - 4s 658us/sample - loss: 0.3728 - acc: 0.3895 - val_loss: 0.3726 - val_acc: 0.3896\n","Epoch 53/1500\n","5501/5501 [==============================] - 4s 657us/sample - loss: 0.3731 - acc: 0.3895 - val_loss: 0.3728 - val_acc: 0.3896\n","Epoch 54/1500\n","5501/5501 [==============================] - 4s 657us/sample - loss: 0.3740 - acc: 0.3894 - val_loss: 0.3733 - val_acc: 0.3895\n","Epoch 55/1500\n","5501/5501 [==============================] - 4s 656us/sample - loss: 0.3734 - acc: 0.3895 - val_loss: 0.3723 - val_acc: 0.3896\n","Epoch 56/1500\n","5501/5501 [==============================] - 4s 656us/sample - loss: 0.3728 - acc: 0.3895 - val_loss: 0.3721 - val_acc: 0.3896\n","Epoch 57/1500\n","5501/5501 [==============================] - 4s 659us/sample - loss: 0.3726 - acc: 0.3896 - val_loss: 0.3719 - val_acc: 0.3897\n","Epoch 58/1500\n","5501/5501 [==============================] - 4s 651us/sample - loss: 0.3725 - acc: 0.3896 - val_loss: 0.3718 - val_acc: 0.3897\n","Epoch 59/1500\n","5501/5501 [==============================] - 4s 663us/sample - loss: 0.3731 - acc: 0.3895 - val_loss: 0.3749 - val_acc: 0.3894\n","Epoch 60/1500\n","5501/5501 [==============================] - 4s 652us/sample - loss: 0.3735 - acc: 0.3895 - val_loss: 0.3728 - val_acc: 0.3896\n","Epoch 61/1500\n","5501/5501 [==============================] - 4s 654us/sample - loss: 0.3740 - acc: 0.3894 - val_loss: 0.3739 - val_acc: 0.3895\n","Epoch 62/1500\n","5501/5501 [==============================] - 4s 663us/sample - loss: 0.3727 - acc: 0.3896 - val_loss: 0.3716 - val_acc: 0.3897\n","Epoch 63/1500\n","5501/5501 [==============================] - 4s 652us/sample - loss: 0.3718 - acc: 0.3896 - val_loss: 0.3713 - val_acc: 0.3897\n","Epoch 64/1500\n","5501/5501 [==============================] - 4s 659us/sample - loss: 0.3718 - acc: 0.3896 - val_loss: 0.3721 - val_acc: 0.3896\n","Epoch 65/1500\n","5501/5501 [==============================] - 4s 658us/sample - loss: 0.3728 - acc: 0.3896 - val_loss: 0.3729 - val_acc: 0.3896\n","Epoch 66/1500\n","5501/5501 [==============================] - 4s 658us/sample - loss: 0.3729 - acc: 0.3895 - val_loss: 0.3716 - val_acc: 0.3897\n","Epoch 67/1500\n","5501/5501 [==============================] - 4s 655us/sample - loss: 0.3726 - acc: 0.3896 - val_loss: 0.3722 - val_acc: 0.3896\n","Epoch 68/1500\n","5501/5501 [==============================] - 4s 658us/sample - loss: 0.3721 - acc: 0.3896 - val_loss: 0.3715 - val_acc: 0.3897\n","Epoch 69/1500\n","5501/5501 [==============================] - 4s 654us/sample - loss: 0.3721 - acc: 0.3896 - val_loss: 0.3717 - val_acc: 0.3897\n","Epoch 70/1500\n","5501/5501 [==============================] - 4s 653us/sample - loss: 0.3716 - acc: 0.3897 - val_loss: 0.3713 - val_acc: 0.3897\n","Epoch 71/1500\n","5501/5501 [==============================] - 4s 651us/sample - loss: 0.3718 - acc: 0.3896 - val_loss: 0.3720 - val_acc: 0.3897\n","Epoch 72/1500\n","5501/5501 [==============================] - 4s 642us/sample - loss: 0.3725 - acc: 0.3896 - val_loss: 0.3718 - val_acc: 0.3897\n","Epoch 73/1500\n","5501/5501 [==============================] - 4s 654us/sample - loss: 0.3718 - acc: 0.3896 - val_loss: 0.3712 - val_acc: 0.3897\n","Epoch 74/1500\n","5501/5501 [==============================] - 4s 644us/sample - loss: 0.3714 - acc: 0.3897 - val_loss: 0.3711 - val_acc: 0.3897\n","Epoch 75/1500\n","5501/5501 [==============================] - 4s 648us/sample - loss: 0.3716 - acc: 0.3897 - val_loss: 0.3714 - val_acc: 0.3897\n","Epoch 76/1500\n","5501/5501 [==============================] - 4s 655us/sample - loss: 0.3716 - acc: 0.3897 - val_loss: 0.3718 - val_acc: 0.3897\n","Epoch 77/1500\n","5501/5501 [==============================] - 4s 648us/sample - loss: 0.3716 - acc: 0.3897 - val_loss: 0.3715 - val_acc: 0.3897\n","Epoch 78/1500\n","5501/5501 [==============================] - 4s 652us/sample - loss: 0.3716 - acc: 0.3897 - val_loss: 0.3715 - val_acc: 0.3897\n","Epoch 79/1500\n","5501/5501 [==============================] - 4s 651us/sample - loss: 0.3719 - acc: 0.3896 - val_loss: 0.3716 - val_acc: 0.3897\n","Epoch 80/1500\n","5501/5501 [==============================] - 4s 652us/sample - loss: 0.3723 - acc: 0.3896 - val_loss: 0.3714 - val_acc: 0.3897\n","Epoch 81/1500\n","5501/5501 [==============================] - 4s 646us/sample - loss: 0.3714 - acc: 0.3897 - val_loss: 0.3708 - val_acc: 0.3898\n","Epoch 82/1500\n","5501/5501 [==============================] - 4s 658us/sample - loss: 0.3710 - acc: 0.3897 - val_loss: 0.3721 - val_acc: 0.3897\n","Epoch 83/1500\n","5501/5501 [==============================] - 4s 653us/sample - loss: 0.3717 - acc: 0.3897 - val_loss: 0.3718 - val_acc: 0.3897\n","Epoch 84/1500\n","5501/5501 [==============================] - 4s 655us/sample - loss: 0.3726 - acc: 0.3896 - val_loss: 0.3723 - val_acc: 0.3896\n","Epoch 85/1500\n","5501/5501 [==============================] - 4s 653us/sample - loss: 0.3725 - acc: 0.3896 - val_loss: 0.3709 - val_acc: 0.3898\n","Epoch 86/1500\n","5501/5501 [==============================] - 4s 652us/sample - loss: 0.3711 - acc: 0.3897 - val_loss: 0.3706 - val_acc: 0.3898\n","Epoch 87/1500\n","5501/5501 [==============================] - 4s 657us/sample - loss: 0.3709 - acc: 0.3897 - val_loss: 0.3708 - val_acc: 0.3898\n","Epoch 88/1500\n","5501/5501 [==============================] - 4s 651us/sample - loss: 0.3714 - acc: 0.3897 - val_loss: 0.3714 - val_acc: 0.3897\n","Epoch 89/1500\n","5501/5501 [==============================] - 4s 660us/sample - loss: 0.3709 - acc: 0.3897 - val_loss: 0.3712 - val_acc: 0.3897\n","Epoch 90/1500\n","5501/5501 [==============================] - 4s 653us/sample - loss: 0.3716 - acc: 0.3897 - val_loss: 0.3706 - val_acc: 0.3898\n","Epoch 91/1500\n","5501/5501 [==============================] - 4s 648us/sample - loss: 0.3711 - acc: 0.3897 - val_loss: 0.3709 - val_acc: 0.3897\n","Epoch 92/1500\n","5501/5501 [==============================] - 4s 650us/sample - loss: 0.3709 - acc: 0.3897 - val_loss: 0.3702 - val_acc: 0.3898\n","Epoch 93/1500\n","5501/5501 [==============================] - 4s 651us/sample - loss: 0.3708 - acc: 0.3897 - val_loss: 0.3707 - val_acc: 0.3898\n","Epoch 94/1500\n","5501/5501 [==============================] - 4s 650us/sample - loss: 0.3718 - acc: 0.3897 - val_loss: 0.3727 - val_acc: 0.3896\n","Epoch 95/1500\n","5501/5501 [==============================] - 4s 654us/sample - loss: 0.3716 - acc: 0.3897 - val_loss: 0.3703 - val_acc: 0.3898\n","Epoch 96/1500\n","5501/5501 [==============================] - 4s 652us/sample - loss: 0.3708 - acc: 0.3897 - val_loss: 0.3707 - val_acc: 0.3898\n","Epoch 97/1500\n","5501/5501 [==============================] - 4s 654us/sample - loss: 0.3707 - acc: 0.3897 - val_loss: 0.3701 - val_acc: 0.3898\n","Epoch 98/1500\n","5501/5501 [==============================] - 4s 650us/sample - loss: 0.3704 - acc: 0.3898 - val_loss: 0.3702 - val_acc: 0.3898\n","Epoch 99/1500\n","5501/5501 [==============================] - 4s 657us/sample - loss: 0.3806 - acc: 0.3889 - val_loss: 0.3918 - val_acc: 0.3881\n","Epoch 100/1500\n","5501/5501 [==============================] - 4s 654us/sample - loss: 0.3809 - acc: 0.3889 - val_loss: 0.3733 - val_acc: 0.3896\n","Epoch 101/1500\n","5501/5501 [==============================] - 4s 652us/sample - loss: 0.3722 - acc: 0.3896 - val_loss: 0.3710 - val_acc: 0.3897\n","Epoch 102/1500\n","5501/5501 [==============================] - 4s 651us/sample - loss: 0.3710 - acc: 0.3897 - val_loss: 0.3706 - val_acc: 0.3898\n","Epoch 103/1500\n","5501/5501 [==============================] - 4s 650us/sample - loss: 0.3708 - acc: 0.3897 - val_loss: 0.3705 - val_acc: 0.3898\n","Epoch 104/1500\n","5501/5501 [==============================] - 4s 650us/sample - loss: 0.3706 - acc: 0.3897 - val_loss: 0.3705 - val_acc: 0.3898\n","Epoch 105/1500\n","5501/5501 [==============================] - 4s 651us/sample - loss: 0.3711 - acc: 0.3897 - val_loss: 0.3708 - val_acc: 0.3897\n","Epoch 106/1500\n","5501/5501 [==============================] - 4s 664us/sample - loss: 0.3709 - acc: 0.3897 - val_loss: 0.3703 - val_acc: 0.3898\n","Epoch 107/1500\n","5501/5501 [==============================] - 4s 667us/sample - loss: 0.3704 - acc: 0.3898 - val_loss: 0.3702 - val_acc: 0.3898\n","Epoch 108/1500\n","5501/5501 [==============================] - 4s 651us/sample - loss: 0.3702 - acc: 0.3898 - val_loss: 0.3699 - val_acc: 0.3898\n","Epoch 109/1500\n","5501/5501 [==============================] - 4s 655us/sample - loss: 0.3705 - acc: 0.3897 - val_loss: 0.3704 - val_acc: 0.3898\n","Epoch 110/1500\n","5501/5501 [==============================] - 4s 652us/sample - loss: 0.3706 - acc: 0.3897 - val_loss: 0.3708 - val_acc: 0.3898\n","Epoch 111/1500\n","5501/5501 [==============================] - 4s 652us/sample - loss: 0.3705 - acc: 0.3898 - val_loss: 0.3701 - val_acc: 0.3898\n","Epoch 112/1500\n","5501/5501 [==============================] - 4s 654us/sample - loss: 0.3705 - acc: 0.3898 - val_loss: 0.3700 - val_acc: 0.3898\n","Epoch 113/1500\n","5501/5501 [==============================] - 4s 656us/sample - loss: 0.3710 - acc: 0.3897 - val_loss: 0.3712 - val_acc: 0.3897\n","Epoch 114/1500\n","5501/5501 [==============================] - 4s 650us/sample - loss: 0.3704 - acc: 0.3898 - val_loss: 0.3697 - val_acc: 0.3898\n","Epoch 115/1500\n","5501/5501 [==============================] - 4s 657us/sample - loss: 0.3701 - acc: 0.3898 - val_loss: 0.3700 - val_acc: 0.3898\n","Epoch 116/1500\n","5501/5501 [==============================] - 4s 656us/sample - loss: 0.3700 - acc: 0.3898 - val_loss: 0.3698 - val_acc: 0.3898\n","Epoch 117/1500\n","5501/5501 [==============================] - 4s 656us/sample - loss: 0.3701 - acc: 0.3898 - val_loss: 0.3697 - val_acc: 0.3898\n","Epoch 118/1500\n","5501/5501 [==============================] - 4s 655us/sample - loss: 0.3702 - acc: 0.3898 - val_loss: 0.3699 - val_acc: 0.3898\n","Epoch 119/1500\n","5501/5501 [==============================] - 4s 659us/sample - loss: 0.3717 - acc: 0.3896 - val_loss: 0.3733 - val_acc: 0.3895\n","Epoch 120/1500\n","5501/5501 [==============================] - 4s 658us/sample - loss: 0.3717 - acc: 0.3897 - val_loss: 0.3702 - val_acc: 0.3898\n","Epoch 121/1500\n","5501/5501 [==============================] - 4s 653us/sample - loss: 0.3704 - acc: 0.3898 - val_loss: 0.3697 - val_acc: 0.3898\n","Epoch 122/1500\n","5501/5501 [==============================] - 4s 658us/sample - loss: 0.3701 - acc: 0.3898 - val_loss: 0.3702 - val_acc: 0.3898\n","Epoch 123/1500\n","5501/5501 [==============================] - 4s 656us/sample - loss: 0.3701 - acc: 0.3898 - val_loss: 0.3695 - val_acc: 0.3899\n","Epoch 124/1500\n","5501/5501 [==============================] - 4s 656us/sample - loss: 0.3699 - acc: 0.3898 - val_loss: 0.3696 - val_acc: 0.3899\n","Epoch 125/1500\n","5501/5501 [==============================] - 4s 664us/sample - loss: 0.3705 - acc: 0.3898 - val_loss: 0.3702 - val_acc: 0.3898\n","Epoch 126/1500\n","5501/5501 [==============================] - 4s 675us/sample - loss: 0.3703 - acc: 0.3898 - val_loss: 0.3696 - val_acc: 0.3899\n","Epoch 127/1500\n","5501/5501 [==============================] - 4s 657us/sample - loss: 0.3702 - acc: 0.3898 - val_loss: 0.3699 - val_acc: 0.3898\n","Epoch 128/1500\n","5501/5501 [==============================] - 4s 660us/sample - loss: 0.3700 - acc: 0.3898 - val_loss: 0.3696 - val_acc: 0.3899\n","Epoch 129/1500\n","5501/5501 [==============================] - 4s 655us/sample - loss: 0.3702 - acc: 0.3898 - val_loss: 0.3699 - val_acc: 0.3898\n","Epoch 130/1500\n","5501/5501 [==============================] - 4s 650us/sample - loss: 0.3698 - acc: 0.3898 - val_loss: 0.3694 - val_acc: 0.3899\n","Epoch 131/1500\n","5501/5501 [==============================] - 4s 654us/sample - loss: 0.3700 - acc: 0.3898 - val_loss: 0.3698 - val_acc: 0.3898\n","Epoch 132/1500\n","5501/5501 [==============================] - 4s 657us/sample - loss: 0.3700 - acc: 0.3898 - val_loss: 0.3694 - val_acc: 0.3899\n","Epoch 133/1500\n","5501/5501 [==============================] - 4s 648us/sample - loss: 0.3697 - acc: 0.3898 - val_loss: 0.3694 - val_acc: 0.3899\n","Epoch 134/1500\n","5501/5501 [==============================] - 4s 653us/sample - loss: 0.3698 - acc: 0.3898 - val_loss: 0.3704 - val_acc: 0.3898\n","Epoch 135/1500\n","5501/5501 [==============================] - 4s 659us/sample - loss: 0.3708 - acc: 0.3897 - val_loss: 0.3705 - val_acc: 0.3898\n","Epoch 136/1500\n","5501/5501 [==============================] - 4s 660us/sample - loss: 0.3708 - acc: 0.3897 - val_loss: 0.3701 - val_acc: 0.3898\n","Epoch 137/1500\n","5501/5501 [==============================] - 4s 660us/sample - loss: 0.3703 - acc: 0.3898 - val_loss: 0.3702 - val_acc: 0.3898\n","Epoch 138/1500\n","5501/5501 [==============================] - 4s 657us/sample - loss: 0.3706 - acc: 0.3897 - val_loss: 0.3702 - val_acc: 0.3898\n","Epoch 139/1500\n","5501/5501 [==============================] - 4s 651us/sample - loss: 0.3708 - acc: 0.3897 - val_loss: 0.3709 - val_acc: 0.3898\n","Epoch 140/1500\n","5501/5501 [==============================] - 4s 655us/sample - loss: 0.3706 - acc: 0.3898 - val_loss: 0.3695 - val_acc: 0.3899\n","Epoch 141/1500\n","5501/5501 [==============================] - 4s 652us/sample - loss: 0.3700 - acc: 0.3898 - val_loss: 0.3697 - val_acc: 0.3899\n","Epoch 142/1500\n","5501/5501 [==============================] - 4s 656us/sample - loss: 0.3701 - acc: 0.3898 - val_loss: 0.3694 - val_acc: 0.3899\n","Epoch 143/1500\n","5501/5501 [==============================] - 4s 664us/sample - loss: 0.3697 - acc: 0.3898 - val_loss: 0.3694 - val_acc: 0.3899\n","Epoch 144/1500\n","5501/5501 [==============================] - 4s 659us/sample - loss: 0.3695 - acc: 0.3898 - val_loss: 0.3691 - val_acc: 0.3899\n","Epoch 145/1500\n","5501/5501 [==============================] - 4s 661us/sample - loss: 0.3695 - acc: 0.3898 - val_loss: 0.3692 - val_acc: 0.3899\n","Epoch 146/1500\n","5501/5501 [==============================] - 4s 668us/sample - loss: 0.3696 - acc: 0.3898 - val_loss: 0.3690 - val_acc: 0.3899\n","Epoch 147/1500\n","5501/5501 [==============================] - 4s 664us/sample - loss: 0.3695 - acc: 0.3898 - val_loss: 0.3694 - val_acc: 0.3899\n","Epoch 148/1500\n","5501/5501 [==============================] - 4s 659us/sample - loss: 0.3702 - acc: 0.3898 - val_loss: 0.3706 - val_acc: 0.3898\n","Epoch 149/1500\n","5501/5501 [==============================] - 4s 663us/sample - loss: 0.3707 - acc: 0.3897 - val_loss: 0.3698 - val_acc: 0.3898\n","Epoch 150/1500\n","5501/5501 [==============================] - 4s 655us/sample - loss: 0.3702 - acc: 0.3898 - val_loss: 0.3697 - val_acc: 0.3899\n","Epoch 151/1500\n","5501/5501 [==============================] - 4s 657us/sample - loss: 0.3697 - acc: 0.3898 - val_loss: 0.3694 - val_acc: 0.3899\n","Epoch 152/1500\n","5501/5501 [==============================] - 4s 660us/sample - loss: 0.3701 - acc: 0.3898 - val_loss: 0.3708 - val_acc: 0.3898\n","Epoch 153/1500\n","5501/5501 [==============================] - 4s 656us/sample - loss: 0.3826 - acc: 0.3887 - val_loss: 0.3817 - val_acc: 0.3888\n","Epoch 154/1500\n","5501/5501 [==============================] - 4s 658us/sample - loss: 0.3768 - acc: 0.3892 - val_loss: 0.3709 - val_acc: 0.3898\n","Epoch 155/1500\n","5501/5501 [==============================] - 4s 657us/sample - loss: 0.3702 - acc: 0.3898 - val_loss: 0.3694 - val_acc: 0.3899\n","Epoch 156/1500\n","5501/5501 [==============================] - 4s 658us/sample - loss: 0.3695 - acc: 0.3898 - val_loss: 0.3692 - val_acc: 0.3899\n","Epoch 157/1500\n","5501/5501 [==============================] - 4s 659us/sample - loss: 0.3694 - acc: 0.3898 - val_loss: 0.3689 - val_acc: 0.3899\n","Epoch 158/1500\n","5501/5501 [==============================] - 4s 655us/sample - loss: 0.3692 - acc: 0.3899 - val_loss: 0.3689 - val_acc: 0.3899\n","Epoch 159/1500\n","5501/5501 [==============================] - 4s 657us/sample - loss: 0.3691 - acc: 0.3899 - val_loss: 0.3688 - val_acc: 0.3899\n","Epoch 160/1500\n","5501/5501 [==============================] - 4s 660us/sample - loss: 0.3691 - acc: 0.3899 - val_loss: 0.3687 - val_acc: 0.3899\n","Epoch 161/1500\n","5501/5501 [==============================] - 4s 657us/sample - loss: 0.3692 - acc: 0.3899 - val_loss: 0.3689 - val_acc: 0.3899\n","Epoch 162/1500\n","5501/5501 [==============================] - 4s 657us/sample - loss: 0.3692 - acc: 0.3899 - val_loss: 0.3688 - val_acc: 0.3899\n","Epoch 163/1500\n","5501/5501 [==============================] - 4s 654us/sample - loss: 0.3693 - acc: 0.3899 - val_loss: 0.3692 - val_acc: 0.3899\n","Epoch 164/1500\n","5501/5501 [==============================] - 4s 657us/sample - loss: 0.3697 - acc: 0.3898 - val_loss: 0.3694 - val_acc: 0.3899\n","Epoch 165/1500\n","5501/5501 [==============================] - 4s 659us/sample - loss: 0.3697 - acc: 0.3898 - val_loss: 0.3691 - val_acc: 0.3899\n","Epoch 166/1500\n","5501/5501 [==============================] - 4s 655us/sample - loss: 0.3694 - acc: 0.3899 - val_loss: 0.3690 - val_acc: 0.3899\n","Epoch 167/1500\n","5501/5501 [==============================] - 4s 666us/sample - loss: 0.3693 - acc: 0.3899 - val_loss: 0.3691 - val_acc: 0.3899\n","Epoch 168/1500\n","5501/5501 [==============================] - 4s 648us/sample - loss: 0.3693 - acc: 0.3899 - val_loss: 0.3688 - val_acc: 0.3899\n","Epoch 169/1500\n","5501/5501 [==============================] - 4s 656us/sample - loss: 0.3692 - acc: 0.3899 - val_loss: 0.3689 - val_acc: 0.3899\n","Epoch 170/1500\n","5501/5501 [==============================] - 4s 666us/sample - loss: 0.3692 - acc: 0.3899 - val_loss: 0.3692 - val_acc: 0.3899\n","Epoch 171/1500\n","5501/5501 [==============================] - 4s 663us/sample - loss: 0.3694 - acc: 0.3899 - val_loss: 0.3689 - val_acc: 0.3899\n","Epoch 172/1500\n","5501/5501 [==============================] - 4s 665us/sample - loss: 0.3693 - acc: 0.3899 - val_loss: 0.3689 - val_acc: 0.3899\n","Epoch 173/1500\n","5501/5501 [==============================] - 4s 657us/sample - loss: 0.3693 - acc: 0.3899 - val_loss: 0.3694 - val_acc: 0.3899\n","Epoch 174/1500\n","5501/5501 [==============================] - 4s 655us/sample - loss: 0.3699 - acc: 0.3898 - val_loss: 0.3703 - val_acc: 0.3898\n","Epoch 175/1500\n","5501/5501 [==============================] - 4s 655us/sample - loss: 0.3716 - acc: 0.3897 - val_loss: 0.3699 - val_acc: 0.3898\n","Epoch 176/1500\n","5501/5501 [==============================] - 4s 654us/sample - loss: 0.3696 - acc: 0.3898 - val_loss: 0.3689 - val_acc: 0.3899\n","Epoch 177/1500\n","5501/5501 [==============================] - 4s 656us/sample - loss: 0.3691 - acc: 0.3899 - val_loss: 0.3688 - val_acc: 0.3899\n","Epoch 178/1500\n","5501/5501 [==============================] - 4s 657us/sample - loss: 0.3691 - acc: 0.3899 - val_loss: 0.3688 - val_acc: 0.3899\n","Epoch 179/1500\n","5501/5501 [==============================] - 4s 649us/sample - loss: 0.3692 - acc: 0.3899 - val_loss: 0.3694 - val_acc: 0.3899\n","Epoch 180/1500\n","5501/5501 [==============================] - 4s 651us/sample - loss: 0.3696 - acc: 0.3898 - val_loss: 0.3691 - val_acc: 0.3899\n","Epoch 181/1500\n","5501/5501 [==============================] - 4s 656us/sample - loss: 0.3693 - acc: 0.3899 - val_loss: 0.3689 - val_acc: 0.3899\n","Epoch 182/1500\n","5501/5501 [==============================] - 4s 655us/sample - loss: 0.3691 - acc: 0.3899 - val_loss: 0.3686 - val_acc: 0.3899\n","Epoch 183/1500\n","5501/5501 [==============================] - 4s 657us/sample - loss: 0.3691 - acc: 0.3899 - val_loss: 0.3688 - val_acc: 0.3899\n","Epoch 184/1500\n","5501/5501 [==============================] - 4s 653us/sample - loss: 0.3694 - acc: 0.3898 - val_loss: 0.3690 - val_acc: 0.3899\n","Epoch 185/1500\n","5501/5501 [==============================] - 4s 653us/sample - loss: 0.3696 - acc: 0.3898 - val_loss: 0.3694 - val_acc: 0.3899\n","Epoch 186/1500\n","5501/5501 [==============================] - 4s 653us/sample - loss: 0.3701 - acc: 0.3898 - val_loss: 0.3690 - val_acc: 0.3899\n","Epoch 187/1500\n","5501/5501 [==============================] - 4s 650us/sample - loss: 0.3695 - acc: 0.3898 - val_loss: 0.3692 - val_acc: 0.3899\n","Epoch 188/1500\n","5501/5501 [==============================] - 4s 651us/sample - loss: 0.3692 - acc: 0.3899 - val_loss: 0.3687 - val_acc: 0.3899\n","Epoch 189/1500\n","5501/5501 [==============================] - 4s 659us/sample - loss: 0.3694 - acc: 0.3898 - val_loss: 0.3690 - val_acc: 0.3899\n","Epoch 190/1500\n","5501/5501 [==============================] - 4s 652us/sample - loss: 0.3691 - acc: 0.3899 - val_loss: 0.3687 - val_acc: 0.3899\n","Epoch 191/1500\n","5501/5501 [==============================] - 4s 666us/sample - loss: 0.3692 - acc: 0.3899 - val_loss: 0.3689 - val_acc: 0.3899\n","Epoch 192/1500\n","5501/5501 [==============================] - 4s 657us/sample - loss: 0.3692 - acc: 0.3899 - val_loss: 0.3689 - val_acc: 0.3899\n","Epoch 193/1500\n","5501/5501 [==============================] - 4s 653us/sample - loss: 0.3692 - acc: 0.3899 - val_loss: 0.3687 - val_acc: 0.3899\n","Epoch 194/1500\n","5501/5501 [==============================] - 4s 654us/sample - loss: 0.3691 - acc: 0.3899 - val_loss: 0.3688 - val_acc: 0.3899\n","Epoch 195/1500\n","5501/5501 [==============================] - 4s 658us/sample - loss: 0.3690 - acc: 0.3899 - val_loss: 0.3688 - val_acc: 0.3899\n","Epoch 196/1500\n","5501/5501 [==============================] - 4s 661us/sample - loss: 0.3692 - acc: 0.3899 - val_loss: 0.3690 - val_acc: 0.3899\n","Epoch 197/1500\n","5501/5501 [==============================] - 4s 653us/sample - loss: 0.3695 - acc: 0.3898 - val_loss: 0.3692 - val_acc: 0.3899\n","Epoch 198/1500\n","5501/5501 [==============================] - 4s 649us/sample - loss: 0.3696 - acc: 0.3898 - val_loss: 0.3692 - val_acc: 0.3899\n","Epoch 199/1500\n","5501/5501 [==============================] - 4s 658us/sample - loss: 0.3694 - acc: 0.3898 - val_loss: 0.3689 - val_acc: 0.3899\n","Epoch 200/1500\n","5501/5501 [==============================] - 4s 655us/sample - loss: 0.3692 - acc: 0.3899 - val_loss: 0.3688 - val_acc: 0.3899\n","Epoch 201/1500\n","5501/5501 [==============================] - 4s 655us/sample - loss: 0.3691 - acc: 0.3899 - val_loss: 0.3688 - val_acc: 0.3899\n","Epoch 202/1500\n","5501/5501 [==============================] - 4s 655us/sample - loss: 0.3692 - acc: 0.3899 - val_loss: 0.3689 - val_acc: 0.3899\n","Epoch 203/1500\n","5501/5501 [==============================] - 4s 660us/sample - loss: 0.3690 - acc: 0.3899 - val_loss: 0.3689 - val_acc: 0.3899\n","Epoch 204/1500\n","5501/5501 [==============================] - 4s 652us/sample - loss: 0.3695 - acc: 0.3898 - val_loss: 0.3701 - val_acc: 0.3898\n","Epoch 205/1500\n","5501/5501 [==============================] - 4s 653us/sample - loss: 0.3702 - acc: 0.3898 - val_loss: 0.3697 - val_acc: 0.3899\n","Epoch 206/1500\n","5501/5501 [==============================] - 4s 650us/sample - loss: 0.3696 - acc: 0.3898 - val_loss: 0.3687 - val_acc: 0.3899\n","Epoch 207/1500\n","5501/5501 [==============================] - 4s 648us/sample - loss: 0.3688 - acc: 0.3899 - val_loss: 0.3685 - val_acc: 0.3899\n","Epoch 208/1500\n","5501/5501 [==============================] - 4s 654us/sample - loss: 0.3687 - acc: 0.3899 - val_loss: 0.3684 - val_acc: 0.3899\n","Epoch 209/1500\n","5501/5501 [==============================] - 4s 649us/sample - loss: 0.3689 - acc: 0.3899 - val_loss: 0.3687 - val_acc: 0.3899\n","Epoch 210/1500\n","5501/5501 [==============================] - 4s 657us/sample - loss: 0.3689 - acc: 0.3899 - val_loss: 0.3686 - val_acc: 0.3899\n","Epoch 211/1500\n","5501/5501 [==============================] - 4s 669us/sample - loss: 0.3690 - acc: 0.3899 - val_loss: 0.3687 - val_acc: 0.3899\n","Epoch 212/1500\n","5501/5501 [==============================] - 4s 669us/sample - loss: 0.3690 - acc: 0.3899 - val_loss: 0.3686 - val_acc: 0.3899\n","Epoch 213/1500\n","5501/5501 [==============================] - 4s 655us/sample - loss: 0.3693 - acc: 0.3899 - val_loss: 0.3693 - val_acc: 0.3899\n","Epoch 214/1500\n","5501/5501 [==============================] - 4s 654us/sample - loss: 0.3702 - acc: 0.3898 - val_loss: 0.3693 - val_acc: 0.3899\n","Epoch 215/1500\n","5501/5501 [==============================] - 4s 653us/sample - loss: 0.3691 - acc: 0.3899 - val_loss: 0.3686 - val_acc: 0.3899\n","Epoch 216/1500\n","5501/5501 [==============================] - 4s 651us/sample - loss: 0.3689 - acc: 0.3899 - val_loss: 0.3688 - val_acc: 0.3899\n","Epoch 217/1500\n","5501/5501 [==============================] - 4s 651us/sample - loss: 0.3690 - acc: 0.3899 - val_loss: 0.3690 - val_acc: 0.3899\n","Epoch 218/1500\n","5501/5501 [==============================] - 4s 653us/sample - loss: 0.3691 - acc: 0.3899 - val_loss: 0.3688 - val_acc: 0.3899\n","Epoch 219/1500\n","5501/5501 [==============================] - 4s 651us/sample - loss: 0.3691 - acc: 0.3899 - val_loss: 0.3685 - val_acc: 0.3899\n","Epoch 220/1500\n","5501/5501 [==============================] - 4s 653us/sample - loss: 0.3688 - acc: 0.3899 - val_loss: 0.3684 - val_acc: 0.3899\n","Epoch 221/1500\n","5501/5501 [==============================] - 4s 655us/sample - loss: 0.3687 - acc: 0.3899 - val_loss: 0.3683 - val_acc: 0.3899\n","Epoch 222/1500\n","5501/5501 [==============================] - 4s 648us/sample - loss: 0.3686 - acc: 0.3899 - val_loss: 0.3683 - val_acc: 0.3900\n","Epoch 223/1500\n","5501/5501 [==============================] - 4s 657us/sample - loss: 0.3687 - acc: 0.3899 - val_loss: 0.3685 - val_acc: 0.3899\n","Epoch 224/1500\n","5501/5501 [==============================] - 4s 647us/sample - loss: 0.3688 - acc: 0.3899 - val_loss: 0.3686 - val_acc: 0.3899\n","Epoch 225/1500\n","5501/5501 [==============================] - 4s 658us/sample - loss: 0.3688 - acc: 0.3899 - val_loss: 0.3685 - val_acc: 0.3899\n","Epoch 226/1500\n","5501/5501 [==============================] - 4s 651us/sample - loss: 0.3691 - acc: 0.3899 - val_loss: 0.3695 - val_acc: 0.3898\n","Epoch 227/1500\n","5501/5501 [==============================] - 4s 654us/sample - loss: 0.3803 - acc: 0.3888 - val_loss: 0.4023 - val_acc: 0.3865\n","Epoch 228/1500\n","5501/5501 [==============================] - 4s 651us/sample - loss: 0.3826 - acc: 0.3887 - val_loss: 0.3723 - val_acc: 0.3896\n","Epoch 229/1500\n","5501/5501 [==============================] - 4s 650us/sample - loss: 0.3708 - acc: 0.3897 - val_loss: 0.3695 - val_acc: 0.3899\n","Epoch 230/1500\n","5501/5501 [==============================] - 4s 654us/sample - loss: 0.3695 - acc: 0.3898 - val_loss: 0.3689 - val_acc: 0.3899\n","Epoch 231/1500\n","5501/5501 [==============================] - 4s 654us/sample - loss: 0.3690 - acc: 0.3899 - val_loss: 0.3686 - val_acc: 0.3899\n","Epoch 232/1500\n","5501/5501 [==============================] - 4s 647us/sample - loss: 0.3688 - acc: 0.3899 - val_loss: 0.3684 - val_acc: 0.3899\n","Epoch 233/1500\n","5501/5501 [==============================] - 4s 654us/sample - loss: 0.3688 - acc: 0.3899 - val_loss: 0.3685 - val_acc: 0.3899\n","Epoch 234/1500\n","5501/5501 [==============================] - 4s 653us/sample - loss: 0.3687 - acc: 0.3899 - val_loss: 0.3684 - val_acc: 0.3899\n","Epoch 235/1500\n","5501/5501 [==============================] - 4s 648us/sample - loss: 0.3686 - acc: 0.3899 - val_loss: 0.3683 - val_acc: 0.3900\n","Epoch 236/1500\n","5501/5501 [==============================] - 4s 649us/sample - loss: 0.3686 - acc: 0.3899 - val_loss: 0.3683 - val_acc: 0.3900\n","Epoch 237/1500\n","5501/5501 [==============================] - 4s 652us/sample - loss: 0.3687 - acc: 0.3899 - val_loss: 0.3683 - val_acc: 0.3900\n","Epoch 238/1500\n","5501/5501 [==============================] - 4s 652us/sample - loss: 0.3686 - acc: 0.3899 - val_loss: 0.3682 - val_acc: 0.3900\n","Epoch 239/1500\n","5501/5501 [==============================] - 4s 648us/sample - loss: 0.3686 - acc: 0.3899 - val_loss: 0.3682 - val_acc: 0.3899\n","Epoch 240/1500\n","5501/5501 [==============================] - 4s 652us/sample - loss: 0.3686 - acc: 0.3899 - val_loss: 0.3683 - val_acc: 0.3899\n","Epoch 241/1500\n","5501/5501 [==============================] - 4s 652us/sample - loss: 0.3687 - acc: 0.3899 - val_loss: 0.3684 - val_acc: 0.3899\n","Epoch 242/1500\n","5501/5501 [==============================] - 4s 651us/sample - loss: 0.3685 - acc: 0.3899 - val_loss: 0.3684 - val_acc: 0.3899\n","Epoch 243/1500\n","5501/5501 [==============================] - 4s 652us/sample - loss: 0.3687 - acc: 0.3899 - val_loss: 0.3684 - val_acc: 0.3899\n","Epoch 244/1500\n","5501/5501 [==============================] - 4s 645us/sample - loss: 0.3686 - acc: 0.3899 - val_loss: 0.3682 - val_acc: 0.3900\n","Epoch 245/1500\n","5501/5501 [==============================] - 4s 655us/sample - loss: 0.3687 - acc: 0.3899 - val_loss: 0.3685 - val_acc: 0.3899\n","Epoch 246/1500\n","5501/5501 [==============================] - 4s 651us/sample - loss: 0.3686 - acc: 0.3899 - val_loss: 0.3683 - val_acc: 0.3899\n","Epoch 247/1500\n","5501/5501 [==============================] - 4s 653us/sample - loss: 0.3685 - acc: 0.3899 - val_loss: 0.3683 - val_acc: 0.3899\n","Epoch 248/1500\n","5501/5501 [==============================] - 4s 650us/sample - loss: 0.3689 - acc: 0.3899 - val_loss: 0.3688 - val_acc: 0.3899\n","Epoch 249/1500\n","5501/5501 [==============================] - 4s 657us/sample - loss: 0.3691 - acc: 0.3899 - val_loss: 0.3689 - val_acc: 0.3899\n","Epoch 250/1500\n","5501/5501 [==============================] - 4s 648us/sample - loss: 0.3690 - acc: 0.3899 - val_loss: 0.3685 - val_acc: 0.3899\n","Epoch 251/1500\n","5501/5501 [==============================] - 4s 646us/sample - loss: 0.3688 - acc: 0.3899 - val_loss: 0.3684 - val_acc: 0.3900\n","Epoch 252/1500\n","5501/5501 [==============================] - 4s 651us/sample - loss: 0.3685 - acc: 0.3899 - val_loss: 0.3683 - val_acc: 0.3900\n","Epoch 253/1500\n","5501/5501 [==============================] - 4s 650us/sample - loss: 0.3686 - acc: 0.3899 - val_loss: 0.3683 - val_acc: 0.3899\n","Epoch 254/1500\n","5501/5501 [==============================] - 4s 653us/sample - loss: 0.3686 - acc: 0.3899 - val_loss: 0.3682 - val_acc: 0.3899\n","Epoch 255/1500\n","5501/5501 [==============================] - 4s 649us/sample - loss: 0.3685 - acc: 0.3899 - val_loss: 0.3682 - val_acc: 0.3900\n","Epoch 256/1500\n","5501/5501 [==============================] - 4s 647us/sample - loss: 0.3686 - acc: 0.3899 - val_loss: 0.3683 - val_acc: 0.3899\n","Epoch 257/1500\n","5501/5501 [==============================] - 4s 651us/sample - loss: 0.3687 - acc: 0.3899 - val_loss: 0.3684 - val_acc: 0.3899\n","Epoch 258/1500\n","5501/5501 [==============================] - 4s 643us/sample - loss: 0.3689 - acc: 0.3899 - val_loss: 0.3693 - val_acc: 0.3899\n","Epoch 259/1500\n","5501/5501 [==============================] - 4s 651us/sample - loss: 0.3694 - acc: 0.3898 - val_loss: 0.3691 - val_acc: 0.3899\n","Epoch 260/1500\n","5501/5501 [==============================] - 4s 653us/sample - loss: 0.3690 - acc: 0.3899 - val_loss: 0.3685 - val_acc: 0.3899\n","Epoch 261/1500\n","5501/5501 [==============================] - 4s 656us/sample - loss: 0.3687 - acc: 0.3899 - val_loss: 0.3686 - val_acc: 0.3899\n","Epoch 262/1500\n","5501/5501 [==============================] - 4s 651us/sample - loss: 0.3685 - acc: 0.3899 - val_loss: 0.3681 - val_acc: 0.3900\n","Epoch 263/1500\n","5501/5501 [==============================] - 4s 648us/sample - loss: 0.3684 - acc: 0.3899 - val_loss: 0.3682 - val_acc: 0.3900\n","Epoch 264/1500\n","5501/5501 [==============================] - 4s 652us/sample - loss: 0.3684 - acc: 0.3899 - val_loss: 0.3679 - val_acc: 0.3900\n","Epoch 265/1500\n","5501/5501 [==============================] - 4s 653us/sample - loss: 0.3683 - acc: 0.3899 - val_loss: 0.3685 - val_acc: 0.3899\n","Epoch 266/1500\n","5501/5501 [==============================] - 4s 652us/sample - loss: 0.3689 - acc: 0.3899 - val_loss: 0.3683 - val_acc: 0.3899\n","Epoch 267/1500\n","5501/5501 [==============================] - 4s 653us/sample - loss: 0.3687 - acc: 0.3899 - val_loss: 0.3684 - val_acc: 0.3899\n","Epoch 268/1500\n","5501/5501 [==============================] - 4s 647us/sample - loss: 0.3688 - acc: 0.3899 - val_loss: 0.3685 - val_acc: 0.3899\n","Epoch 269/1500\n","5501/5501 [==============================] - 4s 648us/sample - loss: 0.3686 - acc: 0.3899 - val_loss: 0.3681 - val_acc: 0.3900\n","Epoch 270/1500\n","5501/5501 [==============================] - 4s 648us/sample - loss: 0.3684 - acc: 0.3899 - val_loss: 0.3682 - val_acc: 0.3900\n","Epoch 271/1500\n","5501/5501 [==============================] - 4s 651us/sample - loss: 0.3685 - acc: 0.3899 - val_loss: 0.3681 - val_acc: 0.3900\n","Epoch 272/1500\n","5501/5501 [==============================] - 4s 647us/sample - loss: 0.3684 - acc: 0.3899 - val_loss: 0.3682 - val_acc: 0.3900\n","Epoch 273/1500\n","5501/5501 [==============================] - 4s 645us/sample - loss: 0.3687 - acc: 0.3899 - val_loss: 0.3684 - val_acc: 0.3900\n","Epoch 274/1500\n","5501/5501 [==============================] - 4s 652us/sample - loss: 0.3685 - acc: 0.3899 - val_loss: 0.3681 - val_acc: 0.3900\n","Epoch 275/1500\n","5501/5501 [==============================] - 4s 655us/sample - loss: 0.3684 - acc: 0.3899 - val_loss: 0.3681 - val_acc: 0.3900\n","Epoch 276/1500\n","5501/5501 [==============================] - 4s 665us/sample - loss: 0.3685 - acc: 0.3899 - val_loss: 0.3684 - val_acc: 0.3899\n","Epoch 277/1500\n","5501/5501 [==============================] - 4s 657us/sample - loss: 0.3688 - acc: 0.3899 - val_loss: 0.3686 - val_acc: 0.3899\n","Epoch 278/1500\n","5501/5501 [==============================] - 4s 645us/sample - loss: 0.3690 - acc: 0.3899 - val_loss: 0.3689 - val_acc: 0.3899\n","Epoch 279/1500\n","5501/5501 [==============================] - 4s 650us/sample - loss: 0.3689 - acc: 0.3899 - val_loss: 0.3685 - val_acc: 0.3899\n","Epoch 280/1500\n","5501/5501 [==============================] - 4s 657us/sample - loss: 0.3684 - acc: 0.3899 - val_loss: 0.3680 - val_acc: 0.3900\n","Epoch 281/1500\n","5501/5501 [==============================] - 4s 646us/sample - loss: 0.3683 - acc: 0.3899 - val_loss: 0.3680 - val_acc: 0.3900\n","Epoch 282/1500\n","5501/5501 [==============================] - 4s 651us/sample - loss: 0.3685 - acc: 0.3899 - val_loss: 0.3686 - val_acc: 0.3899\n","Epoch 283/1500\n","5501/5501 [==============================] - 4s 647us/sample - loss: 0.3685 - acc: 0.3899 - val_loss: 0.3680 - val_acc: 0.3900\n","Epoch 284/1500\n","5501/5501 [==============================] - 4s 653us/sample - loss: 0.3683 - acc: 0.3899 - val_loss: 0.3683 - val_acc: 0.3900\n","Epoch 285/1500\n","5501/5501 [==============================] - 4s 652us/sample - loss: 0.3715 - acc: 0.3897 - val_loss: 0.4207 - val_acc: 0.3841\n","Epoch 286/1500\n","5501/5501 [==============================] - 4s 652us/sample - loss: 0.3922 - acc: 0.3877 - val_loss: 0.3774 - val_acc: 0.3892\n","Epoch 287/1500\n","5501/5501 [==============================] - 4s 652us/sample - loss: 0.3726 - acc: 0.3896 - val_loss: 0.3698 - val_acc: 0.3898\n","Epoch 288/1500\n","5501/5501 [==============================] - 4s 649us/sample - loss: 0.3694 - acc: 0.3898 - val_loss: 0.3687 - val_acc: 0.3899\n","Epoch 289/1500\n","5501/5501 [==============================] - 4s 648us/sample - loss: 0.3687 - acc: 0.3899 - val_loss: 0.3683 - val_acc: 0.3900\n","Epoch 290/1500\n","5501/5501 [==============================] - 4s 651us/sample - loss: 0.3685 - acc: 0.3899 - val_loss: 0.3681 - val_acc: 0.3900\n","Epoch 291/1500\n","5501/5501 [==============================] - 4s 648us/sample - loss: 0.3684 - acc: 0.3899 - val_loss: 0.3680 - val_acc: 0.3900\n","Epoch 292/1500\n","5501/5501 [==============================] - 4s 646us/sample - loss: 0.3683 - acc: 0.3899 - val_loss: 0.3679 - val_acc: 0.3900\n","Epoch 293/1500\n","5501/5501 [==============================] - 4s 640us/sample - loss: 0.3682 - acc: 0.3899 - val_loss: 0.3679 - val_acc: 0.3900\n","Epoch 294/1500\n","5501/5501 [==============================] - 4s 643us/sample - loss: 0.3682 - acc: 0.3899 - val_loss: 0.3679 - val_acc: 0.3900\n","Epoch 295/1500\n","5501/5501 [==============================] - 4s 647us/sample - loss: 0.3681 - acc: 0.3899 - val_loss: 0.3679 - val_acc: 0.3900\n","Epoch 296/1500\n","5501/5501 [==============================] - 4s 646us/sample - loss: 0.3684 - acc: 0.3899 - val_loss: 0.3684 - val_acc: 0.3899\n","Epoch 297/1500\n","5501/5501 [==============================] - 4s 658us/sample - loss: 0.3685 - acc: 0.3899 - val_loss: 0.3681 - val_acc: 0.3900\n","Epoch 298/1500\n","5501/5501 [==============================] - 4s 663us/sample - loss: 0.3683 - acc: 0.3899 - val_loss: 0.3680 - val_acc: 0.3900\n","Epoch 299/1500\n","5501/5501 [==============================] - 4s 660us/sample - loss: 0.3684 - acc: 0.3899 - val_loss: 0.3680 - val_acc: 0.3900\n","Epoch 300/1500\n","5501/5501 [==============================] - 4s 649us/sample - loss: 0.3683 - acc: 0.3899 - val_loss: 0.3680 - val_acc: 0.3900\n","Epoch 301/1500\n","5501/5501 [==============================] - 4s 647us/sample - loss: 0.3682 - acc: 0.3899 - val_loss: 0.3680 - val_acc: 0.3900\n","Epoch 302/1500\n","5501/5501 [==============================] - 4s 649us/sample - loss: 0.3682 - acc: 0.3899 - val_loss: 0.3679 - val_acc: 0.3900\n","Epoch 303/1500\n","5501/5501 [==============================] - 4s 649us/sample - loss: 0.3683 - acc: 0.3899 - val_loss: 0.3681 - val_acc: 0.3900\n","Epoch 304/1500\n","5501/5501 [==============================] - 4s 651us/sample - loss: 0.3684 - acc: 0.3899 - val_loss: 0.3680 - val_acc: 0.3900\n","Epoch 305/1500\n","5501/5501 [==============================] - 4s 651us/sample - loss: 0.3683 - acc: 0.3899 - val_loss: 0.3682 - val_acc: 0.3900\n","Epoch 306/1500\n","5501/5501 [==============================] - 4s 659us/sample - loss: 0.3684 - acc: 0.3899 - val_loss: 0.3681 - val_acc: 0.3900\n","Epoch 307/1500\n","5501/5501 [==============================] - 4s 656us/sample - loss: 0.3685 - acc: 0.3899 - val_loss: 0.3682 - val_acc: 0.3900\n","Epoch 308/1500\n","5501/5501 [==============================] - 4s 653us/sample - loss: 0.3684 - acc: 0.3899 - val_loss: 0.3679 - val_acc: 0.3900\n","Epoch 309/1500\n","5501/5501 [==============================] - 4s 654us/sample - loss: 0.3681 - acc: 0.3899 - val_loss: 0.3678 - val_acc: 0.3900\n","Epoch 310/1500\n","5501/5501 [==============================] - 4s 657us/sample - loss: 0.3682 - acc: 0.3899 - val_loss: 0.3680 - val_acc: 0.3900\n","Epoch 311/1500\n","5501/5501 [==============================] - 4s 650us/sample - loss: 0.3686 - acc: 0.3899 - val_loss: 0.3682 - val_acc: 0.3900\n","Epoch 312/1500\n","5501/5501 [==============================] - 4s 657us/sample - loss: 0.3684 - acc: 0.3899 - val_loss: 0.3680 - val_acc: 0.3900\n","Epoch 313/1500\n","5501/5501 [==============================] - 4s 654us/sample - loss: 0.3681 - acc: 0.3899 - val_loss: 0.3679 - val_acc: 0.3900\n","Epoch 314/1500\n","5501/5501 [==============================] - 4s 650us/sample - loss: 0.3684 - acc: 0.3899 - val_loss: 0.3679 - val_acc: 0.3900\n","Epoch 315/1500\n","5501/5501 [==============================] - 4s 649us/sample - loss: 0.3683 - acc: 0.3899 - val_loss: 0.3679 - val_acc: 0.3900\n","Epoch 316/1500\n","5501/5501 [==============================] - 4s 652us/sample - loss: 0.3681 - acc: 0.3899 - val_loss: 0.3680 - val_acc: 0.3900\n","Epoch 317/1500\n","5501/5501 [==============================] - 4s 647us/sample - loss: 0.3686 - acc: 0.3899 - val_loss: 0.3684 - val_acc: 0.3899\n","Epoch 318/1500\n","5501/5501 [==============================] - 4s 650us/sample - loss: 0.3685 - acc: 0.3899 - val_loss: 0.3685 - val_acc: 0.3899\n","Epoch 319/1500\n","5501/5501 [==============================] - 4s 655us/sample - loss: 0.3684 - acc: 0.3899 - val_loss: 0.3679 - val_acc: 0.3900\n","Epoch 320/1500\n","5501/5501 [==============================] - 4s 652us/sample - loss: 0.3681 - acc: 0.3899 - val_loss: 0.3677 - val_acc: 0.3900\n","Epoch 321/1500\n","5501/5501 [==============================] - 4s 647us/sample - loss: 0.3680 - acc: 0.3900 - val_loss: 0.3677 - val_acc: 0.3900\n","Epoch 322/1500\n","5501/5501 [==============================] - 4s 655us/sample - loss: 0.3679 - acc: 0.3900 - val_loss: 0.3678 - val_acc: 0.3900\n","Epoch 323/1500\n","5501/5501 [==============================] - 4s 647us/sample - loss: 0.3680 - acc: 0.3900 - val_loss: 0.3678 - val_acc: 0.3900\n","Epoch 324/1500\n","5501/5501 [==============================] - 4s 653us/sample - loss: 0.3682 - acc: 0.3899 - val_loss: 0.3680 - val_acc: 0.3900\n","Epoch 325/1500\n","5501/5501 [==============================] - 4s 655us/sample - loss: 0.3684 - acc: 0.3899 - val_loss: 0.3680 - val_acc: 0.3900\n","Epoch 326/1500\n","5501/5501 [==============================] - 4s 648us/sample - loss: 0.3682 - acc: 0.3899 - val_loss: 0.3679 - val_acc: 0.3900\n","Epoch 327/1500\n","5501/5501 [==============================] - 4s 648us/sample - loss: 0.3682 - acc: 0.3899 - val_loss: 0.3680 - val_acc: 0.3900\n","Epoch 328/1500\n","5501/5501 [==============================] - 4s 652us/sample - loss: 0.3686 - acc: 0.3899 - val_loss: 0.3684 - val_acc: 0.3899\n","Epoch 329/1500\n","5501/5501 [==============================] - 4s 655us/sample - loss: 0.3686 - acc: 0.3899 - val_loss: 0.3685 - val_acc: 0.3899\n","Epoch 330/1500\n","5501/5501 [==============================] - 4s 661us/sample - loss: 0.3699 - acc: 0.3898 - val_loss: 0.3738 - val_acc: 0.3895\n","Epoch 331/1500\n","5501/5501 [==============================] - 4s 655us/sample - loss: 0.3891 - acc: 0.3880 - val_loss: 0.3786 - val_acc: 0.3890\n","Epoch 332/1500\n","5501/5501 [==============================] - 4s 649us/sample - loss: 0.3742 - acc: 0.3894 - val_loss: 0.3699 - val_acc: 0.3898\n","Epoch 333/1500\n","5501/5501 [==============================] - 4s 656us/sample - loss: 0.3691 - acc: 0.3899 - val_loss: 0.3683 - val_acc: 0.3900\n","Epoch 334/1500\n","5501/5501 [==============================] - 4s 655us/sample - loss: 0.3683 - acc: 0.3899 - val_loss: 0.3679 - val_acc: 0.3900\n","Epoch 335/1500\n","5501/5501 [==============================] - 4s 646us/sample - loss: 0.3680 - acc: 0.3900 - val_loss: 0.3677 - val_acc: 0.3900\n","Epoch 336/1500\n","5501/5501 [==============================] - 4s 655us/sample - loss: 0.3679 - acc: 0.3900 - val_loss: 0.3676 - val_acc: 0.3900\n","Epoch 337/1500\n","5501/5501 [==============================] - 4s 650us/sample - loss: 0.3678 - acc: 0.3900 - val_loss: 0.3675 - val_acc: 0.3900\n","Epoch 338/1500\n","5501/5501 [==============================] - 4s 648us/sample - loss: 0.3678 - acc: 0.3900 - val_loss: 0.3675 - val_acc: 0.3900\n","Epoch 339/1500\n","5501/5501 [==============================] - 4s 651us/sample - loss: 0.3677 - acc: 0.3900 - val_loss: 0.3674 - val_acc: 0.3900\n","Epoch 340/1500\n","5501/5501 [==============================] - 4s 649us/sample - loss: 0.3677 - acc: 0.3900 - val_loss: 0.3674 - val_acc: 0.3900\n","Epoch 341/1500\n","5501/5501 [==============================] - 4s 648us/sample - loss: 0.3677 - acc: 0.3900 - val_loss: 0.3674 - val_acc: 0.3900\n","Epoch 342/1500\n","5501/5501 [==============================] - 4s 651us/sample - loss: 0.3677 - acc: 0.3900 - val_loss: 0.3675 - val_acc: 0.3900\n","Epoch 343/1500\n","5501/5501 [==============================] - 4s 645us/sample - loss: 0.3678 - acc: 0.3900 - val_loss: 0.3676 - val_acc: 0.3900\n","Epoch 344/1500\n","5501/5501 [==============================] - 4s 651us/sample - loss: 0.3678 - acc: 0.3900 - val_loss: 0.3676 - val_acc: 0.3900\n","Epoch 345/1500\n","5501/5501 [==============================] - 4s 652us/sample - loss: 0.3679 - acc: 0.3900 - val_loss: 0.3676 - val_acc: 0.3900\n","Epoch 346/1500\n","5501/5501 [==============================] - 4s 651us/sample - loss: 0.3678 - acc: 0.3900 - val_loss: 0.3674 - val_acc: 0.3900\n","Epoch 347/1500\n","5501/5501 [==============================] - 4s 654us/sample - loss: 0.3678 - acc: 0.3900 - val_loss: 0.3675 - val_acc: 0.3900\n","Epoch 348/1500\n","5501/5501 [==============================] - 4s 655us/sample - loss: 0.3678 - acc: 0.3900 - val_loss: 0.3675 - val_acc: 0.3900\n","Epoch 349/1500\n","5501/5501 [==============================] - 4s 655us/sample - loss: 0.3678 - acc: 0.3900 - val_loss: 0.3676 - val_acc: 0.3900\n","Epoch 350/1500\n","5501/5501 [==============================] - 4s 648us/sample - loss: 0.3681 - acc: 0.3899 - val_loss: 0.3679 - val_acc: 0.3900\n","Epoch 351/1500\n","5501/5501 [==============================] - 4s 657us/sample - loss: 0.3681 - acc: 0.3899 - val_loss: 0.3678 - val_acc: 0.3900\n","Epoch 352/1500\n","5501/5501 [==============================] - 4s 651us/sample - loss: 0.3683 - acc: 0.3899 - val_loss: 0.3683 - val_acc: 0.3899\n","Epoch 353/1500\n","5501/5501 [==============================] - 4s 649us/sample - loss: 0.3681 - acc: 0.3899 - val_loss: 0.3676 - val_acc: 0.3900\n","Epoch 354/1500\n","5501/5501 [==============================] - 4s 649us/sample - loss: 0.3679 - acc: 0.3900 - val_loss: 0.3676 - val_acc: 0.3900\n","Epoch 355/1500\n","5501/5501 [==============================] - 4s 657us/sample - loss: 0.3679 - acc: 0.3900 - val_loss: 0.3676 - val_acc: 0.3900\n","Epoch 356/1500\n","5501/5501 [==============================] - 4s 648us/sample - loss: 0.3680 - acc: 0.3900 - val_loss: 0.3680 - val_acc: 0.3900\n","Epoch 357/1500\n","5501/5501 [==============================] - 4s 650us/sample - loss: 0.3680 - acc: 0.3900 - val_loss: 0.3677 - val_acc: 0.3900\n","Epoch 358/1500\n","5501/5501 [==============================] - 4s 655us/sample - loss: 0.3681 - acc: 0.3899 - val_loss: 0.3680 - val_acc: 0.3900\n","Epoch 359/1500\n","5501/5501 [==============================] - 4s 651us/sample - loss: 0.3681 - acc: 0.3899 - val_loss: 0.3678 - val_acc: 0.3900\n","Epoch 360/1500\n","5501/5501 [==============================] - 4s 649us/sample - loss: 0.3680 - acc: 0.3900 - val_loss: 0.3675 - val_acc: 0.3900\n","Epoch 361/1500\n","5501/5501 [==============================] - 4s 665us/sample - loss: 0.3678 - acc: 0.3900 - val_loss: 0.3677 - val_acc: 0.3900\n","Epoch 362/1500\n","5501/5501 [==============================] - 4s 660us/sample - loss: 0.3682 - acc: 0.3899 - val_loss: 0.3681 - val_acc: 0.3900\n","Epoch 363/1500\n","5501/5501 [==============================] - 4s 647us/sample - loss: 0.3683 - acc: 0.3899 - val_loss: 0.3679 - val_acc: 0.3900\n","Epoch 364/1500\n","5501/5501 [==============================] - 4s 655us/sample - loss: 0.3680 - acc: 0.3899 - val_loss: 0.3681 - val_acc: 0.3900\n","Epoch 365/1500\n","5501/5501 [==============================] - 4s 656us/sample - loss: 0.3682 - acc: 0.3899 - val_loss: 0.3679 - val_acc: 0.3900\n","Epoch 366/1500\n","5501/5501 [==============================] - 4s 648us/sample - loss: 0.3681 - acc: 0.3899 - val_loss: 0.3680 - val_acc: 0.3900\n","Epoch 367/1500\n","5501/5501 [==============================] - 4s 650us/sample - loss: 0.3679 - acc: 0.3900 - val_loss: 0.3675 - val_acc: 0.3900\n","Epoch 368/1500\n","5501/5501 [==============================] - 4s 655us/sample - loss: 0.3678 - acc: 0.3900 - val_loss: 0.3674 - val_acc: 0.3900\n","Epoch 369/1500\n","5501/5501 [==============================] - 4s 654us/sample - loss: 0.3678 - acc: 0.3900 - val_loss: 0.3676 - val_acc: 0.3900\n","Epoch 370/1500\n","5501/5501 [==============================] - 4s 656us/sample - loss: 0.3678 - acc: 0.3900 - val_loss: 0.3675 - val_acc: 0.3900\n","Epoch 371/1500\n","5501/5501 [==============================] - 4s 654us/sample - loss: 0.3681 - acc: 0.3899 - val_loss: 0.3684 - val_acc: 0.3899\n","Epoch 372/1500\n","5501/5501 [==============================] - 4s 646us/sample - loss: 0.3687 - acc: 0.3899 - val_loss: 0.3684 - val_acc: 0.3899\n","Epoch 373/1500\n","5501/5501 [==============================] - 4s 653us/sample - loss: 0.3682 - acc: 0.3899 - val_loss: 0.3678 - val_acc: 0.3900\n","Epoch 374/1500\n","5501/5501 [==============================] - 4s 647us/sample - loss: 0.3681 - acc: 0.3899 - val_loss: 0.3678 - val_acc: 0.3900\n","Epoch 375/1500\n","5501/5501 [==============================] - 4s 648us/sample - loss: 0.3680 - acc: 0.3900 - val_loss: 0.3675 - val_acc: 0.3900\n","Epoch 376/1500\n","5501/5501 [==============================] - 4s 648us/sample - loss: 0.3676 - acc: 0.3900 - val_loss: 0.3673 - val_acc: 0.3900\n","Epoch 377/1500\n","5501/5501 [==============================] - 4s 650us/sample - loss: 0.3676 - acc: 0.3900 - val_loss: 0.3675 - val_acc: 0.3900\n","Epoch 378/1500\n","5501/5501 [==============================] - 4s 650us/sample - loss: 0.3676 - acc: 0.3900 - val_loss: 0.3674 - val_acc: 0.3900\n","Epoch 379/1500\n","5501/5501 [==============================] - 4s 647us/sample - loss: 0.3676 - acc: 0.3900 - val_loss: 0.3675 - val_acc: 0.3900\n","Epoch 380/1500\n","5501/5501 [==============================] - 4s 650us/sample - loss: 0.3678 - acc: 0.3900 - val_loss: 0.3676 - val_acc: 0.3900\n","Epoch 381/1500\n","5501/5501 [==============================] - 4s 653us/sample - loss: 0.3680 - acc: 0.3900 - val_loss: 0.3676 - val_acc: 0.3900\n","Epoch 382/1500\n","5501/5501 [==============================] - 4s 652us/sample - loss: 0.3681 - acc: 0.3899 - val_loss: 0.3677 - val_acc: 0.3900\n","Epoch 383/1500\n","5501/5501 [==============================] - 4s 657us/sample - loss: 0.3681 - acc: 0.3899 - val_loss: 0.3680 - val_acc: 0.3900\n","Epoch 384/1500\n","5501/5501 [==============================] - 4s 667us/sample - loss: 0.3679 - acc: 0.3900 - val_loss: 0.3677 - val_acc: 0.3900\n","Epoch 385/1500\n","5501/5501 [==============================] - 4s 663us/sample - loss: 0.3679 - acc: 0.3900 - val_loss: 0.3676 - val_acc: 0.3900\n","Epoch 386/1500\n","5501/5501 [==============================] - 4s 655us/sample - loss: 0.3680 - acc: 0.3899 - val_loss: 0.3684 - val_acc: 0.3899\n","Epoch 387/1500\n","5501/5501 [==============================] - 4s 648us/sample - loss: 0.3683 - acc: 0.3899 - val_loss: 0.3683 - val_acc: 0.3899\n","Epoch 388/1500\n","5501/5501 [==============================] - 4s 647us/sample - loss: 0.3681 - acc: 0.3899 - val_loss: 0.3676 - val_acc: 0.3900\n","Epoch 389/1500\n","5501/5501 [==============================] - 4s 648us/sample - loss: 0.3681 - acc: 0.3899 - val_loss: 0.3678 - val_acc: 0.3900\n","Epoch 390/1500\n","5501/5501 [==============================] - 4s 646us/sample - loss: 0.3679 - acc: 0.3900 - val_loss: 0.3678 - val_acc: 0.3900\n","Epoch 391/1500\n","5501/5501 [==============================] - 4s 658us/sample - loss: 0.3679 - acc: 0.3900 - val_loss: 0.3676 - val_acc: 0.3900\n","Epoch 392/1500\n","5501/5501 [==============================] - 4s 653us/sample - loss: 0.3677 - acc: 0.3900 - val_loss: 0.3675 - val_acc: 0.3900\n","Epoch 393/1500\n","5501/5501 [==============================] - 4s 652us/sample - loss: 0.3678 - acc: 0.3900 - val_loss: 0.3674 - val_acc: 0.3900\n","Epoch 394/1500\n","5501/5501 [==============================] - 4s 652us/sample - loss: 0.3677 - acc: 0.3900 - val_loss: 0.3673 - val_acc: 0.3900\n","Epoch 395/1500\n","5501/5501 [==============================] - 4s 654us/sample - loss: 0.3676 - acc: 0.3900 - val_loss: 0.3674 - val_acc: 0.3900\n","Epoch 396/1500\n","5501/5501 [==============================] - 4s 651us/sample - loss: 0.3676 - acc: 0.3900 - val_loss: 0.3674 - val_acc: 0.3900\n","Epoch 397/1500\n","5501/5501 [==============================] - 4s 652us/sample - loss: 0.3677 - acc: 0.3900 - val_loss: 0.3674 - val_acc: 0.3900\n","Epoch 398/1500\n","5501/5501 [==============================] - 4s 648us/sample - loss: 0.3679 - acc: 0.3900 - val_loss: 0.3679 - val_acc: 0.3900\n","Epoch 399/1500\n","5501/5501 [==============================] - 4s 653us/sample - loss: 0.3757 - acc: 0.3893 - val_loss: 0.3937 - val_acc: 0.3876\n","Epoch 400/1500\n","5501/5501 [==============================] - 4s 650us/sample - loss: 0.3796 - acc: 0.3889 - val_loss: 0.3728 - val_acc: 0.3895\n","Epoch 401/1500\n","5501/5501 [==============================] - 4s 652us/sample - loss: 0.3697 - acc: 0.3898 - val_loss: 0.3681 - val_acc: 0.3900\n","Epoch 402/1500\n","5501/5501 [==============================] - 4s 649us/sample - loss: 0.3680 - acc: 0.3899 - val_loss: 0.3676 - val_acc: 0.3900\n","Epoch 403/1500\n","5501/5501 [==============================] - 4s 653us/sample - loss: 0.3677 - acc: 0.3900 - val_loss: 0.3674 - val_acc: 0.3900\n","Epoch 404/1500\n","5501/5501 [==============================] - 4s 651us/sample - loss: 0.3675 - acc: 0.3900 - val_loss: 0.3672 - val_acc: 0.3900\n","Epoch 405/1500\n","5501/5501 [==============================] - 4s 653us/sample - loss: 0.3674 - acc: 0.3900 - val_loss: 0.3671 - val_acc: 0.3900\n","Epoch 406/1500\n","5501/5501 [==============================] - 4s 652us/sample - loss: 0.3674 - acc: 0.3900 - val_loss: 0.3671 - val_acc: 0.3900\n","Epoch 407/1500\n","5501/5501 [==============================] - 4s 646us/sample - loss: 0.3674 - acc: 0.3900 - val_loss: 0.3671 - val_acc: 0.3900\n","Epoch 408/1500\n","5501/5501 [==============================] - 4s 653us/sample - loss: 0.3673 - acc: 0.3900 - val_loss: 0.3671 - val_acc: 0.3900\n","Epoch 409/1500\n","5501/5501 [==============================] - 4s 650us/sample - loss: 0.3674 - acc: 0.3900 - val_loss: 0.3671 - val_acc: 0.3900\n","Epoch 410/1500\n","5501/5501 [==============================] - 4s 647us/sample - loss: 0.3674 - acc: 0.3900 - val_loss: 0.3672 - val_acc: 0.3900\n","Epoch 411/1500\n","5501/5501 [==============================] - 4s 647us/sample - loss: 0.3674 - acc: 0.3900 - val_loss: 0.3671 - val_acc: 0.3900\n","Epoch 412/1500\n","5501/5501 [==============================] - 4s 646us/sample - loss: 0.3674 - acc: 0.3900 - val_loss: 0.3672 - val_acc: 0.3900\n","Epoch 413/1500\n","5501/5501 [==============================] - 4s 647us/sample - loss: 0.3675 - acc: 0.3900 - val_loss: 0.3672 - val_acc: 0.3900\n","Epoch 414/1500\n","5501/5501 [==============================] - 4s 653us/sample - loss: 0.3674 - acc: 0.3900 - val_loss: 0.3672 - val_acc: 0.3900\n","Epoch 415/1500\n","5501/5501 [==============================] - 4s 653us/sample - loss: 0.3674 - acc: 0.3900 - val_loss: 0.3672 - val_acc: 0.3900\n","Epoch 416/1500\n","5501/5501 [==============================] - 4s 650us/sample - loss: 0.3676 - acc: 0.3900 - val_loss: 0.3673 - val_acc: 0.3900\n","Epoch 417/1500\n","5501/5501 [==============================] - 4s 654us/sample - loss: 0.3676 - acc: 0.3900 - val_loss: 0.3675 - val_acc: 0.3900\n","Epoch 418/1500\n","5501/5501 [==============================] - 4s 648us/sample - loss: 0.3677 - acc: 0.3900 - val_loss: 0.3674 - val_acc: 0.3900\n","Epoch 419/1500\n","5501/5501 [==============================] - 4s 656us/sample - loss: 0.3676 - acc: 0.3900 - val_loss: 0.3673 - val_acc: 0.3900\n","Epoch 420/1500\n","5501/5501 [==============================] - 4s 660us/sample - loss: 0.3677 - acc: 0.3900 - val_loss: 0.3676 - val_acc: 0.3900\n","Epoch 421/1500\n","5501/5501 [==============================] - 4s 647us/sample - loss: 0.3679 - acc: 0.3900 - val_loss: 0.3676 - val_acc: 0.3900\n","Epoch 422/1500\n","5501/5501 [==============================] - 4s 654us/sample - loss: 0.3678 - acc: 0.3900 - val_loss: 0.3675 - val_acc: 0.3900\n","Epoch 423/1500\n","5501/5501 [==============================] - 4s 645us/sample - loss: 0.3677 - acc: 0.3900 - val_loss: 0.3675 - val_acc: 0.3900\n","Epoch 424/1500\n","5501/5501 [==============================] - 4s 653us/sample - loss: 0.3679 - acc: 0.3900 - val_loss: 0.3676 - val_acc: 0.3900\n","Epoch 425/1500\n","5501/5501 [==============================] - 4s 653us/sample - loss: 0.3678 - acc: 0.3900 - val_loss: 0.3676 - val_acc: 0.3900\n","Epoch 426/1500\n","5501/5501 [==============================] - 4s 649us/sample - loss: 0.3678 - acc: 0.3900 - val_loss: 0.3674 - val_acc: 0.3900\n","Epoch 427/1500\n","5501/5501 [==============================] - 4s 648us/sample - loss: 0.3678 - acc: 0.3900 - val_loss: 0.3681 - val_acc: 0.3900\n","Epoch 428/1500\n","5501/5501 [==============================] - 4s 653us/sample - loss: 0.3679 - acc: 0.3900 - val_loss: 0.3674 - val_acc: 0.3900\n","Epoch 429/1500\n","5501/5501 [==============================] - 4s 648us/sample - loss: 0.3677 - acc: 0.3900 - val_loss: 0.3674 - val_acc: 0.3900\n","Epoch 430/1500\n","5501/5501 [==============================] - 4s 648us/sample - loss: 0.3677 - acc: 0.3900 - val_loss: 0.3675 - val_acc: 0.3900\n","Epoch 431/1500\n","5501/5501 [==============================] - 4s 646us/sample - loss: 0.3675 - acc: 0.3900 - val_loss: 0.3671 - val_acc: 0.3900\n","Epoch 432/1500\n","5501/5501 [==============================] - 4s 645us/sample - loss: 0.3675 - acc: 0.3900 - val_loss: 0.3673 - val_acc: 0.3900\n","Epoch 433/1500\n","5501/5501 [==============================] - 4s 648us/sample - loss: 0.3676 - acc: 0.3900 - val_loss: 0.3676 - val_acc: 0.3900\n","Epoch 434/1500\n","5501/5501 [==============================] - 4s 644us/sample - loss: 0.3677 - acc: 0.3900 - val_loss: 0.3674 - val_acc: 0.3900\n","Epoch 435/1500\n","5501/5501 [==============================] - 4s 650us/sample - loss: 0.3676 - acc: 0.3900 - val_loss: 0.3672 - val_acc: 0.3900\n","Epoch 436/1500\n","5501/5501 [==============================] - 4s 649us/sample - loss: 0.3674 - acc: 0.3900 - val_loss: 0.3673 - val_acc: 0.3900\n","Epoch 437/1500\n","5501/5501 [==============================] - 4s 648us/sample - loss: 0.3679 - acc: 0.3900 - val_loss: 0.3679 - val_acc: 0.3900\n","Epoch 438/1500\n","5501/5501 [==============================] - 4s 648us/sample - loss: 0.3697 - acc: 0.3898 - val_loss: 0.3711 - val_acc: 0.3897\n","Epoch 439/1500\n","5501/5501 [==============================] - 4s 649us/sample - loss: 0.3764 - acc: 0.3892 - val_loss: 0.3904 - val_acc: 0.3870\n","Epoch 440/1500\n","5501/5501 [==============================] - 4s 648us/sample - loss: 0.3782 - acc: 0.3890 - val_loss: 0.3697 - val_acc: 0.3898\n","Epoch 441/1500\n","5501/5501 [==============================] - 4s 650us/sample - loss: 0.3686 - acc: 0.3899 - val_loss: 0.3677 - val_acc: 0.3900\n","Epoch 442/1500\n","5501/5501 [==============================] - 4s 650us/sample - loss: 0.3678 - acc: 0.3900 - val_loss: 0.3674 - val_acc: 0.3900\n","Epoch 443/1500\n","5501/5501 [==============================] - 4s 644us/sample - loss: 0.3675 - acc: 0.3900 - val_loss: 0.3672 - val_acc: 0.3900\n","Epoch 444/1500\n","5501/5501 [==============================] - 4s 646us/sample - loss: 0.3674 - acc: 0.3900 - val_loss: 0.3671 - val_acc: 0.3900\n","Epoch 445/1500\n","5501/5501 [==============================] - 4s 653us/sample - loss: 0.3673 - acc: 0.3900 - val_loss: 0.3670 - val_acc: 0.3900\n","Epoch 446/1500\n","5501/5501 [==============================] - 4s 662us/sample - loss: 0.3673 - acc: 0.3900 - val_loss: 0.3670 - val_acc: 0.3900\n","Epoch 447/1500\n","5501/5501 [==============================] - 4s 650us/sample - loss: 0.3673 - acc: 0.3900 - val_loss: 0.3670 - val_acc: 0.3900\n","Epoch 448/1500\n","5501/5501 [==============================] - 4s 651us/sample - loss: 0.3673 - acc: 0.3900 - val_loss: 0.3670 - val_acc: 0.3900\n","Epoch 449/1500\n","5501/5501 [==============================] - 4s 645us/sample - loss: 0.3673 - acc: 0.3900 - val_loss: 0.3670 - val_acc: 0.3900\n","Epoch 450/1500\n","5501/5501 [==============================] - 4s 643us/sample - loss: 0.3673 - acc: 0.3900 - val_loss: 0.3671 - val_acc: 0.3900\n","Epoch 451/1500\n","5501/5501 [==============================] - 4s 653us/sample - loss: 0.3673 - acc: 0.3900 - val_loss: 0.3670 - val_acc: 0.3900\n","Epoch 452/1500\n","5501/5501 [==============================] - 4s 640us/sample - loss: 0.3673 - acc: 0.3900 - val_loss: 0.3670 - val_acc: 0.3900\n","Epoch 453/1500\n","5501/5501 [==============================] - 4s 640us/sample - loss: 0.3673 - acc: 0.3900 - val_loss: 0.3670 - val_acc: 0.3900\n","Epoch 454/1500\n","5501/5501 [==============================] - 4s 640us/sample - loss: 0.3672 - acc: 0.3900 - val_loss: 0.3670 - val_acc: 0.3900\n","Epoch 455/1500\n","5501/5501 [==============================] - 4s 637us/sample - loss: 0.3673 - acc: 0.3900 - val_loss: 0.3670 - val_acc: 0.3900\n","Epoch 456/1500\n","5501/5501 [==============================] - 4s 649us/sample - loss: 0.3673 - acc: 0.3900 - val_loss: 0.3672 - val_acc: 0.3900\n","Epoch 457/1500\n","5501/5501 [==============================] - 4s 644us/sample - loss: 0.3674 - acc: 0.3900 - val_loss: 0.3671 - val_acc: 0.3900\n","Epoch 458/1500\n","5501/5501 [==============================] - 4s 644us/sample - loss: 0.3675 - acc: 0.3900 - val_loss: 0.3674 - val_acc: 0.3900\n","Epoch 459/1500\n","5501/5501 [==============================] - 4s 638us/sample - loss: 0.3676 - acc: 0.3900 - val_loss: 0.3673 - val_acc: 0.3900\n","Epoch 460/1500\n","5501/5501 [==============================] - 4s 644us/sample - loss: 0.3675 - acc: 0.3900 - val_loss: 0.3672 - val_acc: 0.3900\n","Epoch 461/1500\n","5501/5501 [==============================] - 4s 644us/sample - loss: 0.3674 - acc: 0.3900 - val_loss: 0.3672 - val_acc: 0.3900\n","Epoch 462/1500\n","5501/5501 [==============================] - 4s 645us/sample - loss: 0.3674 - acc: 0.3900 - val_loss: 0.3671 - val_acc: 0.3900\n","Epoch 463/1500\n","5501/5501 [==============================] - 4s 643us/sample - loss: 0.3676 - acc: 0.3900 - val_loss: 0.3677 - val_acc: 0.3900\n","Epoch 464/1500\n","5501/5501 [==============================] - 4s 641us/sample - loss: 0.3678 - acc: 0.3900 - val_loss: 0.3676 - val_acc: 0.3900\n","Epoch 465/1500\n","5501/5501 [==============================] - 4s 649us/sample - loss: 0.3680 - acc: 0.3899 - val_loss: 0.3674 - val_acc: 0.3900\n","Epoch 466/1500\n","5501/5501 [==============================] - 4s 646us/sample - loss: 0.3676 - acc: 0.3900 - val_loss: 0.3673 - val_acc: 0.3900\n","Epoch 467/1500\n","5501/5501 [==============================] - 4s 648us/sample - loss: 0.3675 - acc: 0.3900 - val_loss: 0.3672 - val_acc: 0.3900\n","Epoch 468/1500\n","5501/5501 [==============================] - 4s 650us/sample - loss: 0.3675 - acc: 0.3900 - val_loss: 0.3673 - val_acc: 0.3900\n","Epoch 469/1500\n","5501/5501 [==============================] - 4s 642us/sample - loss: 0.3675 - acc: 0.3900 - val_loss: 0.3671 - val_acc: 0.3900\n","Epoch 470/1500\n","5501/5501 [==============================] - 4s 658us/sample - loss: 0.3673 - acc: 0.3900 - val_loss: 0.3671 - val_acc: 0.3900\n","Epoch 471/1500\n","5501/5501 [==============================] - 4s 653us/sample - loss: 0.3676 - acc: 0.3900 - val_loss: 0.3676 - val_acc: 0.3900\n","Epoch 472/1500\n","5501/5501 [==============================] - 4s 659us/sample - loss: 0.3676 - acc: 0.3900 - val_loss: 0.3673 - val_acc: 0.3900\n","Epoch 473/1500\n","5501/5501 [==============================] - 4s 645us/sample - loss: 0.3674 - acc: 0.3900 - val_loss: 0.3673 - val_acc: 0.3900\n","Epoch 474/1500\n","5501/5501 [==============================] - 4s 647us/sample - loss: 0.3675 - acc: 0.3900 - val_loss: 0.3672 - val_acc: 0.3900\n","Epoch 475/1500\n","5501/5501 [==============================] - 4s 649us/sample - loss: 0.3675 - acc: 0.3900 - val_loss: 0.3673 - val_acc: 0.3900\n","Epoch 476/1500\n","5501/5501 [==============================] - 4s 645us/sample - loss: 0.3675 - acc: 0.3900 - val_loss: 0.3672 - val_acc: 0.3900\n","Epoch 477/1500\n","5501/5501 [==============================] - 4s 648us/sample - loss: 0.3677 - acc: 0.3900 - val_loss: 0.3678 - val_acc: 0.3900\n","Epoch 478/1500\n","5501/5501 [==============================] - 4s 644us/sample - loss: 0.3792 - acc: 0.3889 - val_loss: 0.3821 - val_acc: 0.3885\n","Epoch 479/1500\n","5501/5501 [==============================] - 4s 645us/sample - loss: 0.3725 - acc: 0.3896 - val_loss: 0.3684 - val_acc: 0.3899\n","Epoch 480/1500\n","5501/5501 [==============================] - 4s 646us/sample - loss: 0.3680 - acc: 0.3900 - val_loss: 0.3674 - val_acc: 0.3900\n","Epoch 481/1500\n","5501/5501 [==============================] - 4s 647us/sample - loss: 0.3675 - acc: 0.3900 - val_loss: 0.3671 - val_acc: 0.3900\n","Epoch 482/1500\n","5501/5501 [==============================] - 4s 649us/sample - loss: 0.3673 - acc: 0.3900 - val_loss: 0.3670 - val_acc: 0.3900\n","Epoch 483/1500\n","5501/5501 [==============================] - 4s 648us/sample - loss: 0.3672 - acc: 0.3900 - val_loss: 0.3670 - val_acc: 0.3900\n","Epoch 484/1500\n","5501/5501 [==============================] - 4s 645us/sample - loss: 0.3672 - acc: 0.3900 - val_loss: 0.3669 - val_acc: 0.3901\n","Epoch 485/1500\n","5501/5501 [==============================] - 4s 649us/sample - loss: 0.3671 - acc: 0.3900 - val_loss: 0.3669 - val_acc: 0.3901\n","Epoch 486/1500\n","5501/5501 [==============================] - 4s 651us/sample - loss: 0.3672 - acc: 0.3900 - val_loss: 0.3669 - val_acc: 0.3900\n","Epoch 487/1500\n","5501/5501 [==============================] - 4s 647us/sample - loss: 0.3672 - acc: 0.3900 - val_loss: 0.3669 - val_acc: 0.3901\n","Epoch 488/1500\n","5501/5501 [==============================] - 4s 649us/sample - loss: 0.3671 - acc: 0.3900 - val_loss: 0.3669 - val_acc: 0.3901\n","Epoch 489/1500\n","5501/5501 [==============================] - 4s 654us/sample - loss: 0.3672 - acc: 0.3900 - val_loss: 0.3670 - val_acc: 0.3900\n","Epoch 490/1500\n","5501/5501 [==============================] - 4s 653us/sample - loss: 0.3672 - acc: 0.3900 - val_loss: 0.3670 - val_acc: 0.3900\n","Epoch 491/1500\n","5501/5501 [==============================] - 4s 650us/sample - loss: 0.3673 - acc: 0.3900 - val_loss: 0.3671 - val_acc: 0.3900\n","Epoch 492/1500\n","5501/5501 [==============================] - 4s 658us/sample - loss: 0.3674 - acc: 0.3900 - val_loss: 0.3671 - val_acc: 0.3900\n","Epoch 493/1500\n","5501/5501 [==============================] - 4s 651us/sample - loss: 0.3673 - acc: 0.3900 - val_loss: 0.3671 - val_acc: 0.3900\n","Epoch 494/1500\n","5501/5501 [==============================] - 4s 650us/sample - loss: 0.3674 - acc: 0.3900 - val_loss: 0.3671 - val_acc: 0.3900\n","Epoch 495/1500\n","5501/5501 [==============================] - 4s 654us/sample - loss: 0.3674 - acc: 0.3900 - val_loss: 0.3672 - val_acc: 0.3900\n","Epoch 496/1500\n","5501/5501 [==============================] - 4s 648us/sample - loss: 0.3674 - acc: 0.3900 - val_loss: 0.3672 - val_acc: 0.3900\n","Epoch 497/1500\n","5501/5501 [==============================] - 4s 647us/sample - loss: 0.3673 - acc: 0.3900 - val_loss: 0.3670 - val_acc: 0.3900\n","Epoch 498/1500\n","5501/5501 [==============================] - 4s 652us/sample - loss: 0.3674 - acc: 0.3900 - val_loss: 0.3672 - val_acc: 0.3900\n","Epoch 499/1500\n","5501/5501 [==============================] - 4s 659us/sample - loss: 0.3674 - acc: 0.3900 - val_loss: 0.3672 - val_acc: 0.3900\n","Epoch 500/1500\n","5501/5501 [==============================] - 4s 650us/sample - loss: 0.3675 - acc: 0.3900 - val_loss: 0.3673 - val_acc: 0.3900\n","Epoch 501/1500\n","5501/5501 [==============================] - 4s 652us/sample - loss: 0.3673 - acc: 0.3900 - val_loss: 0.3670 - val_acc: 0.3900\n","Epoch 502/1500\n","5501/5501 [==============================] - 4s 649us/sample - loss: 0.3673 - acc: 0.3900 - val_loss: 0.3671 - val_acc: 0.3900\n","Epoch 503/1500\n","5501/5501 [==============================] - 4s 651us/sample - loss: 0.3673 - acc: 0.3900 - val_loss: 0.3670 - val_acc: 0.3900\n","Epoch 504/1500\n","5501/5501 [==============================] - 4s 654us/sample - loss: 0.3674 - acc: 0.3900 - val_loss: 0.3675 - val_acc: 0.3900\n","Epoch 505/1500\n","5501/5501 [==============================] - 4s 643us/sample - loss: 0.3682 - acc: 0.3899 - val_loss: 0.3682 - val_acc: 0.3899\n","Epoch 506/1500\n","5501/5501 [==============================] - 4s 651us/sample - loss: 0.3681 - acc: 0.3899 - val_loss: 0.3675 - val_acc: 0.3900\n","Epoch 507/1500\n","5501/5501 [==============================] - 4s 650us/sample - loss: 0.3675 - acc: 0.3900 - val_loss: 0.3672 - val_acc: 0.3900\n","Epoch 508/1500\n","5501/5501 [==============================] - 4s 653us/sample - loss: 0.3675 - acc: 0.3900 - val_loss: 0.3672 - val_acc: 0.3900\n","Epoch 509/1500\n","5501/5501 [==============================] - 4s 649us/sample - loss: 0.3674 - acc: 0.3900 - val_loss: 0.3674 - val_acc: 0.3900\n","Epoch 510/1500\n","5501/5501 [==============================] - 4s 656us/sample - loss: 0.3675 - acc: 0.3900 - val_loss: 0.3674 - val_acc: 0.3900\n","Epoch 511/1500\n","5501/5501 [==============================] - 4s 650us/sample - loss: 0.3675 - acc: 0.3900 - val_loss: 0.3673 - val_acc: 0.3900\n","Epoch 512/1500\n","5501/5501 [==============================] - 4s 647us/sample - loss: 0.3674 - acc: 0.3900 - val_loss: 0.3671 - val_acc: 0.3900\n","Epoch 513/1500\n","5501/5501 [==============================] - 4s 654us/sample - loss: 0.3674 - acc: 0.3900 - val_loss: 0.3674 - val_acc: 0.3900\n","Epoch 514/1500\n","5501/5501 [==============================] - 4s 651us/sample - loss: 0.3676 - acc: 0.3900 - val_loss: 0.3672 - val_acc: 0.3900\n","Epoch 515/1500\n","5501/5501 [==============================] - 4s 655us/sample - loss: 0.3674 - acc: 0.3900 - val_loss: 0.3671 - val_acc: 0.3900\n","Epoch 516/1500\n","5501/5501 [==============================] - 4s 651us/sample - loss: 0.3673 - acc: 0.3900 - val_loss: 0.3670 - val_acc: 0.3900\n","Epoch 517/1500\n","5501/5501 [==============================] - 4s 651us/sample - loss: 0.3674 - acc: 0.3900 - val_loss: 0.3673 - val_acc: 0.3900\n","Epoch 518/1500\n","5501/5501 [==============================] - 4s 647us/sample - loss: 0.3675 - acc: 0.3900 - val_loss: 0.3672 - val_acc: 0.3900\n","Epoch 519/1500\n","5501/5501 [==============================] - 4s 654us/sample - loss: 0.3673 - acc: 0.3900 - val_loss: 0.3672 - val_acc: 0.3900\n","Epoch 520/1500\n","5501/5501 [==============================] - 4s 644us/sample - loss: 0.3673 - acc: 0.3900 - val_loss: 0.3671 - val_acc: 0.3900\n","Epoch 521/1500\n","5501/5501 [==============================] - 4s 649us/sample - loss: 0.3673 - acc: 0.3900 - val_loss: 0.3670 - val_acc: 0.3900\n","Epoch 522/1500\n","5501/5501 [==============================] - 4s 650us/sample - loss: 0.3680 - acc: 0.3899 - val_loss: 0.3690 - val_acc: 0.3899\n","Epoch 523/1500\n","5501/5501 [==============================] - 4s 648us/sample - loss: 0.3708 - acc: 0.3897 - val_loss: 0.3728 - val_acc: 0.3896\n","Epoch 524/1500\n","5501/5501 [==============================] - 4s 649us/sample - loss: 0.3758 - acc: 0.3892 - val_loss: 0.3731 - val_acc: 0.3895\n","Epoch 525/1500\n","5501/5501 [==============================] - 4s 648us/sample - loss: 0.3696 - acc: 0.3898 - val_loss: 0.3677 - val_acc: 0.3900\n","Epoch 526/1500\n","5501/5501 [==============================] - 4s 648us/sample - loss: 0.3675 - acc: 0.3900 - val_loss: 0.3670 - val_acc: 0.3900\n","Epoch 527/1500\n","5501/5501 [==============================] - 4s 646us/sample - loss: 0.3671 - acc: 0.3900 - val_loss: 0.3669 - val_acc: 0.3901\n","Epoch 528/1500\n","5501/5501 [==============================] - 4s 657us/sample - loss: 0.3671 - acc: 0.3900 - val_loss: 0.3668 - val_acc: 0.3901\n","Epoch 529/1500\n","5501/5501 [==============================] - 4s 649us/sample - loss: 0.3670 - acc: 0.3900 - val_loss: 0.3668 - val_acc: 0.3901\n","Epoch 530/1500\n","5501/5501 [==============================] - 4s 656us/sample - loss: 0.3670 - acc: 0.3900 - val_loss: 0.3667 - val_acc: 0.3901\n","Epoch 531/1500\n","5501/5501 [==============================] - 4s 660us/sample - loss: 0.3670 - acc: 0.3900 - val_loss: 0.3667 - val_acc: 0.3901\n","Epoch 532/1500\n","5501/5501 [==============================] - 4s 658us/sample - loss: 0.3670 - acc: 0.3900 - val_loss: 0.3667 - val_acc: 0.3901\n","Epoch 533/1500\n","5501/5501 [==============================] - 4s 650us/sample - loss: 0.3669 - acc: 0.3900 - val_loss: 0.3667 - val_acc: 0.3901\n","Epoch 534/1500\n","5501/5501 [==============================] - 4s 653us/sample - loss: 0.3670 - acc: 0.3900 - val_loss: 0.3667 - val_acc: 0.3901\n","Epoch 535/1500\n","5501/5501 [==============================] - 4s 648us/sample - loss: 0.3670 - acc: 0.3900 - val_loss: 0.3667 - val_acc: 0.3901\n","Epoch 536/1500\n","5501/5501 [==============================] - 4s 658us/sample - loss: 0.3670 - acc: 0.3900 - val_loss: 0.3667 - val_acc: 0.3901\n","Epoch 537/1500\n","5501/5501 [==============================] - 4s 645us/sample - loss: 0.3670 - acc: 0.3900 - val_loss: 0.3669 - val_acc: 0.3900\n","Epoch 538/1500\n","5501/5501 [==============================] - 4s 650us/sample - loss: 0.3672 - acc: 0.3900 - val_loss: 0.3669 - val_acc: 0.3901\n","Epoch 539/1500\n","5501/5501 [==============================] - 4s 648us/sample - loss: 0.3671 - acc: 0.3900 - val_loss: 0.3668 - val_acc: 0.3901\n","Epoch 540/1500\n","5501/5501 [==============================] - 4s 649us/sample - loss: 0.3672 - acc: 0.3900 - val_loss: 0.3670 - val_acc: 0.3900\n","Epoch 541/1500\n","5501/5501 [==============================] - 4s 651us/sample - loss: 0.3673 - acc: 0.3900 - val_loss: 0.3671 - val_acc: 0.3900\n","Epoch 542/1500\n","5501/5501 [==============================] - 4s 654us/sample - loss: 0.3673 - acc: 0.3900 - val_loss: 0.3670 - val_acc: 0.3900\n","Epoch 543/1500\n","5501/5501 [==============================] - 4s 651us/sample - loss: 0.3673 - acc: 0.3900 - val_loss: 0.3670 - val_acc: 0.3900\n","Epoch 544/1500\n","5501/5501 [==============================] - 4s 649us/sample - loss: 0.3674 - acc: 0.3900 - val_loss: 0.3673 - val_acc: 0.3900\n","Epoch 545/1500\n","5501/5501 [==============================] - 4s 655us/sample - loss: 0.3674 - acc: 0.3900 - val_loss: 0.3672 - val_acc: 0.3900\n","Epoch 546/1500\n","5501/5501 [==============================] - 4s 653us/sample - loss: 0.3676 - acc: 0.3900 - val_loss: 0.3675 - val_acc: 0.3900\n","Epoch 547/1500\n","5501/5501 [==============================] - 4s 645us/sample - loss: 0.3676 - acc: 0.3900 - val_loss: 0.3672 - val_acc: 0.3900\n","Epoch 548/1500\n","5501/5501 [==============================] - 4s 652us/sample - loss: 0.3675 - acc: 0.3900 - val_loss: 0.3673 - val_acc: 0.3900\n","Epoch 549/1500\n","5501/5501 [==============================] - 4s 656us/sample - loss: 0.3674 - acc: 0.3900 - val_loss: 0.3670 - val_acc: 0.3900\n","Epoch 550/1500\n","5501/5501 [==============================] - 4s 647us/sample - loss: 0.3673 - acc: 0.3900 - val_loss: 0.3669 - val_acc: 0.3900\n","Epoch 551/1500\n","5501/5501 [==============================] - 4s 655us/sample - loss: 0.3672 - acc: 0.3900 - val_loss: 0.3669 - val_acc: 0.3900\n","Epoch 552/1500\n","5501/5501 [==============================] - 4s 651us/sample - loss: 0.3671 - acc: 0.3900 - val_loss: 0.3668 - val_acc: 0.3901\n","Epoch 553/1500\n","5501/5501 [==============================] - 4s 663us/sample - loss: 0.3672 - acc: 0.3900 - val_loss: 0.3671 - val_acc: 0.3900\n","Epoch 554/1500\n","5501/5501 [==============================] - 4s 650us/sample - loss: 0.3675 - acc: 0.3900 - val_loss: 0.3677 - val_acc: 0.3900\n","Epoch 555/1500\n","5501/5501 [==============================] - 4s 644us/sample - loss: 0.3678 - acc: 0.3900 - val_loss: 0.3673 - val_acc: 0.3900\n","Epoch 556/1500\n","5501/5501 [==============================] - 4s 654us/sample - loss: 0.3673 - acc: 0.3900 - val_loss: 0.3673 - val_acc: 0.3900\n","Epoch 557/1500\n","5501/5501 [==============================] - 4s 666us/sample - loss: 0.3673 - acc: 0.3900 - val_loss: 0.3669 - val_acc: 0.3900\n","Epoch 558/1500\n","5501/5501 [==============================] - 4s 667us/sample - loss: 0.3672 - acc: 0.3900 - val_loss: 0.3672 - val_acc: 0.3900\n","Epoch 559/1500\n","5501/5501 [==============================] - 4s 658us/sample - loss: 0.3674 - acc: 0.3900 - val_loss: 0.3671 - val_acc: 0.3900\n","Epoch 560/1500\n","5501/5501 [==============================] - 4s 652us/sample - loss: 0.3672 - acc: 0.3900 - val_loss: 0.3669 - val_acc: 0.3900\n","Epoch 561/1500\n","5501/5501 [==============================] - 4s 652us/sample - loss: 0.3672 - acc: 0.3900 - val_loss: 0.3670 - val_acc: 0.3900\n","Epoch 562/1500\n","5501/5501 [==============================] - 4s 658us/sample - loss: 0.3672 - acc: 0.3900 - val_loss: 0.3669 - val_acc: 0.3901\n","Epoch 563/1500\n","5501/5501 [==============================] - 4s 654us/sample - loss: 0.3674 - acc: 0.3900 - val_loss: 0.3673 - val_acc: 0.3900\n","Epoch 564/1500\n","5501/5501 [==============================] - 4s 654us/sample - loss: 0.3675 - acc: 0.3900 - val_loss: 0.3673 - val_acc: 0.3900\n","Epoch 565/1500\n","5501/5501 [==============================] - 4s 652us/sample - loss: 0.3677 - acc: 0.3900 - val_loss: 0.3675 - val_acc: 0.3900\n","Epoch 566/1500\n","5501/5501 [==============================] - 4s 654us/sample - loss: 0.3678 - acc: 0.3900 - val_loss: 0.3681 - val_acc: 0.3899\n","Epoch 567/1500\n","5501/5501 [==============================] - 4s 651us/sample - loss: 0.3676 - acc: 0.3900 - val_loss: 0.3671 - val_acc: 0.3900\n","Epoch 568/1500\n","5501/5501 [==============================] - 4s 655us/sample - loss: 0.3673 - acc: 0.3900 - val_loss: 0.3670 - val_acc: 0.3900\n","Epoch 569/1500\n","5501/5501 [==============================] - 4s 659us/sample - loss: 0.3672 - acc: 0.3900 - val_loss: 0.3670 - val_acc: 0.3900\n","Epoch 570/1500\n","5501/5501 [==============================] - 4s 652us/sample - loss: 0.3673 - acc: 0.3900 - val_loss: 0.3671 - val_acc: 0.3900\n","Epoch 571/1500\n","5501/5501 [==============================] - 4s 652us/sample - loss: 0.3674 - acc: 0.3900 - val_loss: 0.3672 - val_acc: 0.3900\n","Epoch 572/1500\n","5501/5501 [==============================] - 4s 651us/sample - loss: 0.3672 - acc: 0.3900 - val_loss: 0.3669 - val_acc: 0.3901\n","Epoch 573/1500\n","5501/5501 [==============================] - 4s 658us/sample - loss: 0.3672 - acc: 0.3900 - val_loss: 0.3670 - val_acc: 0.3900\n","Epoch 574/1500\n","5501/5501 [==============================] - 4s 649us/sample - loss: 0.3673 - acc: 0.3900 - val_loss: 0.3670 - val_acc: 0.3900\n","Epoch 575/1500\n","5501/5501 [==============================] - 4s 652us/sample - loss: 0.3671 - acc: 0.3900 - val_loss: 0.3668 - val_acc: 0.3901\n","Epoch 576/1500\n","5501/5501 [==============================] - 4s 649us/sample - loss: 0.3671 - acc: 0.3900 - val_loss: 0.3669 - val_acc: 0.3901\n","Epoch 577/1500\n","5501/5501 [==============================] - 4s 652us/sample - loss: 0.3671 - acc: 0.3900 - val_loss: 0.3669 - val_acc: 0.3900\n","Epoch 578/1500\n","5501/5501 [==============================] - 4s 657us/sample - loss: 0.3672 - acc: 0.3900 - val_loss: 0.3670 - val_acc: 0.3900\n","Epoch 579/1500\n","5501/5501 [==============================] - 4s 653us/sample - loss: 0.3674 - acc: 0.3900 - val_loss: 0.3673 - val_acc: 0.3900\n","Epoch 580/1500\n","5501/5501 [==============================] - 4s 658us/sample - loss: 0.3674 - acc: 0.3900 - val_loss: 0.3671 - val_acc: 0.3900\n","Epoch 581/1500\n","5501/5501 [==============================] - 4s 654us/sample - loss: 0.3673 - acc: 0.3900 - val_loss: 0.3674 - val_acc: 0.3900\n","Epoch 582/1500\n","5501/5501 [==============================] - 4s 653us/sample - loss: 0.3679 - acc: 0.3900 - val_loss: 0.3675 - val_acc: 0.3900\n","Epoch 583/1500\n","5501/5501 [==============================] - 4s 652us/sample - loss: 0.3677 - acc: 0.3900 - val_loss: 0.3674 - val_acc: 0.3900\n","Epoch 584/1500\n","5501/5501 [==============================] - 4s 658us/sample - loss: 0.3676 - acc: 0.3900 - val_loss: 0.3673 - val_acc: 0.3900\n","Epoch 585/1500\n","5501/5501 [==============================] - 4s 650us/sample - loss: 0.3675 - acc: 0.3900 - val_loss: 0.3671 - val_acc: 0.3900\n","Epoch 586/1500\n","5501/5501 [==============================] - 4s 659us/sample - loss: 0.3672 - acc: 0.3900 - val_loss: 0.3668 - val_acc: 0.3901\n","Epoch 587/1500\n","5501/5501 [==============================] - 4s 647us/sample - loss: 0.3671 - acc: 0.3900 - val_loss: 0.3668 - val_acc: 0.3901\n","Epoch 588/1500\n","5501/5501 [==============================] - 4s 648us/sample - loss: 0.3670 - acc: 0.3900 - val_loss: 0.3667 - val_acc: 0.3901\n","Epoch 589/1500\n","5501/5501 [==============================] - 4s 653us/sample - loss: 0.3669 - acc: 0.3900 - val_loss: 0.3668 - val_acc: 0.3901\n","Epoch 590/1500\n","5501/5501 [==============================] - 4s 653us/sample - loss: 0.3671 - acc: 0.3900 - val_loss: 0.3668 - val_acc: 0.3901\n","Epoch 591/1500\n","5501/5501 [==============================] - 4s 649us/sample - loss: 0.3671 - acc: 0.3900 - val_loss: 0.3670 - val_acc: 0.3900\n","Epoch 592/1500\n","5501/5501 [==============================] - 4s 655us/sample - loss: 0.3671 - acc: 0.3900 - val_loss: 0.3670 - val_acc: 0.3900\n","Epoch 593/1500\n","5501/5501 [==============================] - 4s 650us/sample - loss: 0.3674 - acc: 0.3900 - val_loss: 0.3678 - val_acc: 0.3900\n","Epoch 594/1500\n","5501/5501 [==============================] - 4s 655us/sample - loss: 0.3684 - acc: 0.3899 - val_loss: 0.3683 - val_acc: 0.3899\n","Epoch 595/1500\n","5501/5501 [==============================] - 4s 653us/sample - loss: 0.3780 - acc: 0.3890 - val_loss: 0.3870 - val_acc: 0.3881\n","Epoch 596/1500\n","5501/5501 [==============================] - 4s 652us/sample - loss: 0.3815 - acc: 0.3886 - val_loss: 0.3710 - val_acc: 0.3897\n","Epoch 597/1500\n","5501/5501 [==============================] - 4s 649us/sample - loss: 0.3691 - acc: 0.3898 - val_loss: 0.3679 - val_acc: 0.3900\n","Epoch 598/1500\n","5501/5501 [==============================] - 4s 654us/sample - loss: 0.3677 - acc: 0.3900 - val_loss: 0.3672 - val_acc: 0.3900\n","Epoch 599/1500\n","5501/5501 [==============================] - 4s 657us/sample - loss: 0.3673 - acc: 0.3900 - val_loss: 0.3670 - val_acc: 0.3900\n","Epoch 600/1500\n","5501/5501 [==============================] - 4s 651us/sample - loss: 0.3672 - acc: 0.3900 - val_loss: 0.3669 - val_acc: 0.3901\n","Epoch 601/1500\n","5501/5501 [==============================] - 4s 653us/sample - loss: 0.3671 - acc: 0.3900 - val_loss: 0.3668 - val_acc: 0.3901\n","Epoch 602/1500\n","5501/5501 [==============================] - 4s 654us/sample - loss: 0.3670 - acc: 0.3900 - val_loss: 0.3668 - val_acc: 0.3901\n","Epoch 603/1500\n","5501/5501 [==============================] - 4s 650us/sample - loss: 0.3670 - acc: 0.3900 - val_loss: 0.3667 - val_acc: 0.3901\n","Epoch 604/1500\n","5501/5501 [==============================] - 4s 657us/sample - loss: 0.3670 - acc: 0.3900 - val_loss: 0.3667 - val_acc: 0.3901\n","Epoch 605/1500\n","5501/5501 [==============================] - 4s 658us/sample - loss: 0.3669 - acc: 0.3900 - val_loss: 0.3667 - val_acc: 0.3901\n","Epoch 606/1500\n","5501/5501 [==============================] - 4s 653us/sample - loss: 0.3669 - acc: 0.3900 - val_loss: 0.3667 - val_acc: 0.3901\n","Epoch 607/1500\n","5501/5501 [==============================] - 4s 658us/sample - loss: 0.3669 - acc: 0.3900 - val_loss: 0.3667 - val_acc: 0.3901\n","Epoch 608/1500\n","5501/5501 [==============================] - 4s 655us/sample - loss: 0.3669 - acc: 0.3900 - val_loss: 0.3667 - val_acc: 0.3901\n","Epoch 609/1500\n","5501/5501 [==============================] - 4s 655us/sample - loss: 0.3669 - acc: 0.3900 - val_loss: 0.3667 - val_acc: 0.3901\n","Epoch 610/1500\n","5501/5501 [==============================] - 4s 654us/sample - loss: 0.3670 - acc: 0.3900 - val_loss: 0.3667 - val_acc: 0.3901\n","Epoch 611/1500\n","5501/5501 [==============================] - 4s 650us/sample - loss: 0.3670 - acc: 0.3900 - val_loss: 0.3667 - val_acc: 0.3901\n","Epoch 612/1500\n","5501/5501 [==============================] - 4s 653us/sample - loss: 0.3670 - acc: 0.3900 - val_loss: 0.3667 - val_acc: 0.3901\n","Epoch 613/1500\n","5501/5501 [==============================] - 4s 658us/sample - loss: 0.3670 - acc: 0.3900 - val_loss: 0.3668 - val_acc: 0.3901\n","Epoch 614/1500\n","5501/5501 [==============================] - 4s 655us/sample - loss: 0.3671 - acc: 0.3900 - val_loss: 0.3669 - val_acc: 0.3901\n","Epoch 615/1500\n","5501/5501 [==============================] - 4s 654us/sample - loss: 0.3672 - acc: 0.3900 - val_loss: 0.3669 - val_acc: 0.3900\n","Epoch 616/1500\n","5501/5501 [==============================] - 4s 668us/sample - loss: 0.3672 - acc: 0.3900 - val_loss: 0.3670 - val_acc: 0.3900\n","Epoch 617/1500\n","5501/5501 [==============================] - 4s 657us/sample - loss: 0.3671 - acc: 0.3900 - val_loss: 0.3670 - val_acc: 0.3900\n","Epoch 618/1500\n","5501/5501 [==============================] - 4s 655us/sample - loss: 0.3672 - acc: 0.3900 - val_loss: 0.3668 - val_acc: 0.3901\n","Epoch 619/1500\n","5501/5501 [==============================] - 4s 645us/sample - loss: 0.3672 - acc: 0.3900 - val_loss: 0.3669 - val_acc: 0.3901\n","Epoch 620/1500\n","5501/5501 [==============================] - 4s 649us/sample - loss: 0.3671 - acc: 0.3900 - val_loss: 0.3668 - val_acc: 0.3901\n","Epoch 621/1500\n","5501/5501 [==============================] - 4s 652us/sample - loss: 0.3671 - acc: 0.3900 - val_loss: 0.3670 - val_acc: 0.3900\n","Epoch 622/1500\n","5501/5501 [==============================] - 4s 646us/sample - loss: 0.3672 - acc: 0.3900 - val_loss: 0.3669 - val_acc: 0.3900\n","Epoch 623/1500\n","5501/5501 [==============================] - 4s 654us/sample - loss: 0.3672 - acc: 0.3900 - val_loss: 0.3670 - val_acc: 0.3900\n","Epoch 624/1500\n","5501/5501 [==============================] - 4s 657us/sample - loss: 0.3672 - acc: 0.3900 - val_loss: 0.3668 - val_acc: 0.3901\n","Epoch 625/1500\n","5501/5501 [==============================] - 4s 653us/sample - loss: 0.3672 - acc: 0.3900 - val_loss: 0.3670 - val_acc: 0.3900\n","Epoch 626/1500\n","5501/5501 [==============================] - 4s 653us/sample - loss: 0.3674 - acc: 0.3900 - val_loss: 0.3673 - val_acc: 0.3900\n","Epoch 627/1500\n","5501/5501 [==============================] - 4s 646us/sample - loss: 0.3674 - acc: 0.3900 - val_loss: 0.3671 - val_acc: 0.3900\n","Epoch 628/1500\n","5501/5501 [==============================] - 4s 652us/sample - loss: 0.3671 - acc: 0.3900 - val_loss: 0.3668 - val_acc: 0.3901\n","Epoch 629/1500\n","5501/5501 [==============================] - 4s 657us/sample - loss: 0.3672 - acc: 0.3900 - val_loss: 0.3673 - val_acc: 0.3900\n","Epoch 630/1500\n","5501/5501 [==============================] - 4s 653us/sample - loss: 0.3674 - acc: 0.3900 - val_loss: 0.3670 - val_acc: 0.3900\n","Epoch 631/1500\n","5501/5501 [==============================] - 4s 646us/sample - loss: 0.3671 - acc: 0.3900 - val_loss: 0.3669 - val_acc: 0.3901\n","Epoch 632/1500\n","5501/5501 [==============================] - 4s 653us/sample - loss: 0.3670 - acc: 0.3900 - val_loss: 0.3668 - val_acc: 0.3901\n","Epoch 633/1500\n","5501/5501 [==============================] - 4s 655us/sample - loss: 0.3671 - acc: 0.3900 - val_loss: 0.3671 - val_acc: 0.3900\n","Epoch 634/1500\n","5501/5501 [==============================] - 4s 649us/sample - loss: 0.3675 - acc: 0.3900 - val_loss: 0.3671 - val_acc: 0.3900\n","Epoch 635/1500\n","5501/5501 [==============================] - 4s 647us/sample - loss: 0.3672 - acc: 0.3900 - val_loss: 0.3668 - val_acc: 0.3901\n","Epoch 636/1500\n","5501/5501 [==============================] - 4s 656us/sample - loss: 0.3671 - acc: 0.3900 - val_loss: 0.3668 - val_acc: 0.3901\n","Epoch 637/1500\n","5501/5501 [==============================] - 4s 648us/sample - loss: 0.3671 - acc: 0.3900 - val_loss: 0.3671 - val_acc: 0.3900\n","Epoch 638/1500\n","5501/5501 [==============================] - 4s 651us/sample - loss: 0.3671 - acc: 0.3900 - val_loss: 0.3670 - val_acc: 0.3900\n","Epoch 639/1500\n","5501/5501 [==============================] - 4s 652us/sample - loss: 0.3670 - acc: 0.3900 - val_loss: 0.3669 - val_acc: 0.3900\n","Epoch 640/1500\n","5501/5501 [==============================] - 4s 649us/sample - loss: 0.3672 - acc: 0.3900 - val_loss: 0.3669 - val_acc: 0.3900\n","Epoch 641/1500\n","5501/5501 [==============================] - 4s 650us/sample - loss: 0.3675 - acc: 0.3900 - val_loss: 0.3678 - val_acc: 0.3900\n","Epoch 642/1500\n","5501/5501 [==============================] - 4s 662us/sample - loss: 0.3684 - acc: 0.3899 - val_loss: 0.3678 - val_acc: 0.3900\n","Epoch 643/1500\n","5501/5501 [==============================] - 4s 663us/sample - loss: 0.3700 - acc: 0.3897 - val_loss: 0.3757 - val_acc: 0.3891\n","Epoch 644/1500\n","5501/5501 [==============================] - 4s 664us/sample - loss: 0.3813 - acc: 0.3887 - val_loss: 0.3710 - val_acc: 0.3897\n","Epoch 645/1500\n","5501/5501 [==============================] - 4s 662us/sample - loss: 0.3691 - acc: 0.3898 - val_loss: 0.3676 - val_acc: 0.3900\n","Epoch 646/1500\n","5501/5501 [==============================] - 4s 654us/sample - loss: 0.3675 - acc: 0.3900 - val_loss: 0.3671 - val_acc: 0.3900\n","Epoch 647/1500\n","5501/5501 [==============================] - 4s 649us/sample - loss: 0.3672 - acc: 0.3900 - val_loss: 0.3669 - val_acc: 0.3901\n","Epoch 648/1500\n","5501/5501 [==============================] - 4s 654us/sample - loss: 0.3670 - acc: 0.3900 - val_loss: 0.3667 - val_acc: 0.3901\n","Epoch 649/1500\n","5501/5501 [==============================] - 4s 655us/sample - loss: 0.3669 - acc: 0.3900 - val_loss: 0.3667 - val_acc: 0.3901\n","Epoch 650/1500\n","5501/5501 [==============================] - 4s 652us/sample - loss: 0.3669 - acc: 0.3900 - val_loss: 0.3666 - val_acc: 0.3901\n","Epoch 651/1500\n","5501/5501 [==============================] - 4s 650us/sample - loss: 0.3669 - acc: 0.3900 - val_loss: 0.3666 - val_acc: 0.3901\n","Epoch 652/1500\n","5501/5501 [==============================] - 4s 652us/sample - loss: 0.3668 - acc: 0.3900 - val_loss: 0.3667 - val_acc: 0.3901\n","Epoch 653/1500\n","5501/5501 [==============================] - 4s 655us/sample - loss: 0.3669 - acc: 0.3900 - val_loss: 0.3667 - val_acc: 0.3901\n","Epoch 654/1500\n","5501/5501 [==============================] - 4s 648us/sample - loss: 0.3669 - acc: 0.3900 - val_loss: 0.3667 - val_acc: 0.3901\n","Epoch 655/1500\n","5501/5501 [==============================] - 4s 649us/sample - loss: 0.3668 - acc: 0.3900 - val_loss: 0.3666 - val_acc: 0.3901\n","Epoch 656/1500\n","5501/5501 [==============================] - 4s 649us/sample - loss: 0.3668 - acc: 0.3900 - val_loss: 0.3667 - val_acc: 0.3901\n","Epoch 657/1500\n","5501/5501 [==============================] - 4s 646us/sample - loss: 0.3669 - acc: 0.3900 - val_loss: 0.3667 - val_acc: 0.3901\n","Epoch 658/1500\n","5501/5501 [==============================] - 4s 650us/sample - loss: 0.3669 - acc: 0.3900 - val_loss: 0.3666 - val_acc: 0.3901\n","Epoch 659/1500\n","5501/5501 [==============================] - 4s 651us/sample - loss: 0.3669 - acc: 0.3900 - val_loss: 0.3667 - val_acc: 0.3901\n","Epoch 660/1500\n","5501/5501 [==============================] - 4s 649us/sample - loss: 0.3670 - acc: 0.3900 - val_loss: 0.3667 - val_acc: 0.3901\n","Epoch 661/1500\n","5501/5501 [==============================] - 4s 654us/sample - loss: 0.3670 - acc: 0.3900 - val_loss: 0.3668 - val_acc: 0.3901\n","Epoch 662/1500\n","5501/5501 [==============================] - 4s 656us/sample - loss: 0.3670 - acc: 0.3900 - val_loss: 0.3668 - val_acc: 0.3901\n","Epoch 663/1500\n","5501/5501 [==============================] - 4s 655us/sample - loss: 0.3671 - acc: 0.3900 - val_loss: 0.3669 - val_acc: 0.3900\n","Epoch 664/1500\n","5501/5501 [==============================] - 4s 652us/sample - loss: 0.3671 - acc: 0.3900 - val_loss: 0.3667 - val_acc: 0.3901\n","Epoch 665/1500\n","5501/5501 [==============================] - 4s 655us/sample - loss: 0.3669 - acc: 0.3900 - val_loss: 0.3668 - val_acc: 0.3901\n","Epoch 666/1500\n","5501/5501 [==============================] - 4s 653us/sample - loss: 0.3670 - acc: 0.3900 - val_loss: 0.3668 - val_acc: 0.3901\n","Epoch 667/1500\n","5501/5501 [==============================] - 4s 650us/sample - loss: 0.3670 - acc: 0.3900 - val_loss: 0.3667 - val_acc: 0.3901\n","Epoch 668/1500\n","5501/5501 [==============================] - 4s 658us/sample - loss: 0.3671 - acc: 0.3900 - val_loss: 0.3669 - val_acc: 0.3901\n","Epoch 669/1500\n","5501/5501 [==============================] - 4s 655us/sample - loss: 0.3671 - acc: 0.3900 - val_loss: 0.3670 - val_acc: 0.3900\n","Epoch 670/1500\n","5501/5501 [==============================] - 4s 656us/sample - loss: 0.3674 - acc: 0.3900 - val_loss: 0.3674 - val_acc: 0.3900\n","Epoch 671/1500\n","5501/5501 [==============================] - 4s 657us/sample - loss: 0.3674 - acc: 0.3900 - val_loss: 0.3671 - val_acc: 0.3900\n","Epoch 672/1500\n","5501/5501 [==============================] - 4s 648us/sample - loss: 0.3673 - acc: 0.3900 - val_loss: 0.3670 - val_acc: 0.3900\n","Epoch 673/1500\n","5501/5501 [==============================] - 4s 662us/sample - loss: 0.3671 - acc: 0.3900 - val_loss: 0.3668 - val_acc: 0.3901\n","Epoch 674/1500\n","5501/5501 [==============================] - 4s 658us/sample - loss: 0.3670 - acc: 0.3900 - val_loss: 0.3668 - val_acc: 0.3901\n","Epoch 675/1500\n","5501/5501 [==============================] - 4s 656us/sample - loss: 0.3670 - acc: 0.3900 - val_loss: 0.3668 - val_acc: 0.3901\n","Epoch 676/1500\n","5501/5501 [==============================] - 4s 658us/sample - loss: 0.3672 - acc: 0.3900 - val_loss: 0.3669 - val_acc: 0.3900\n","Epoch 677/1500\n","5501/5501 [==============================] - 4s 657us/sample - loss: 0.3670 - acc: 0.3900 - val_loss: 0.3667 - val_acc: 0.3901\n","Epoch 678/1500\n","5501/5501 [==============================] - 4s 651us/sample - loss: 0.3670 - acc: 0.3900 - val_loss: 0.3667 - val_acc: 0.3901\n","Epoch 679/1500\n","5501/5501 [==============================] - 4s 655us/sample - loss: 0.3670 - acc: 0.3900 - val_loss: 0.3669 - val_acc: 0.3900\n","Epoch 680/1500\n","5501/5501 [==============================] - 4s 654us/sample - loss: 0.3671 - acc: 0.3900 - val_loss: 0.3669 - val_acc: 0.3900\n","Epoch 681/1500\n","5501/5501 [==============================] - 4s 656us/sample - loss: 0.3672 - acc: 0.3900 - val_loss: 0.3671 - val_acc: 0.3900\n","Epoch 682/1500\n","5501/5501 [==============================] - 4s 657us/sample - loss: 0.3674 - acc: 0.3900 - val_loss: 0.3672 - val_acc: 0.3900\n","Epoch 683/1500\n","5501/5501 [==============================] - 4s 660us/sample - loss: 0.3676 - acc: 0.3900 - val_loss: 0.3675 - val_acc: 0.3900\n","Epoch 684/1500\n","5501/5501 [==============================] - 4s 655us/sample - loss: 0.3676 - acc: 0.3900 - val_loss: 0.3671 - val_acc: 0.3900\n","Epoch 685/1500\n","5501/5501 [==============================] - 4s 652us/sample - loss: 0.3671 - acc: 0.3900 - val_loss: 0.3667 - val_acc: 0.3901\n","Epoch 686/1500\n","5501/5501 [==============================] - 4s 658us/sample - loss: 0.3670 - acc: 0.3900 - val_loss: 0.3667 - val_acc: 0.3901\n","Epoch 687/1500\n","5501/5501 [==============================] - 4s 651us/sample - loss: 0.3669 - acc: 0.3900 - val_loss: 0.3667 - val_acc: 0.3901\n","Epoch 688/1500\n","5501/5501 [==============================] - 4s 655us/sample - loss: 0.3671 - acc: 0.3900 - val_loss: 0.3669 - val_acc: 0.3900\n","Epoch 689/1500\n","5501/5501 [==============================] - 4s 659us/sample - loss: 0.3672 - acc: 0.3900 - val_loss: 0.3670 - val_acc: 0.3900\n","Epoch 690/1500\n","5501/5501 [==============================] - 4s 652us/sample - loss: 0.3673 - acc: 0.3900 - val_loss: 0.3669 - val_acc: 0.3900\n","Epoch 691/1500\n","5501/5501 [==============================] - 4s 660us/sample - loss: 0.3670 - acc: 0.3900 - val_loss: 0.3667 - val_acc: 0.3901\n","Epoch 692/1500\n","5501/5501 [==============================] - 4s 658us/sample - loss: 0.3669 - acc: 0.3900 - val_loss: 0.3666 - val_acc: 0.3901\n","Epoch 693/1500\n","5501/5501 [==============================] - 4s 655us/sample - loss: 0.3670 - acc: 0.3900 - val_loss: 0.3668 - val_acc: 0.3901\n","Epoch 694/1500\n","5501/5501 [==============================] - 4s 654us/sample - loss: 0.3673 - acc: 0.3900 - val_loss: 0.3671 - val_acc: 0.3900\n","Epoch 695/1500\n","5501/5501 [==============================] - 4s 660us/sample - loss: 0.3672 - acc: 0.3900 - val_loss: 0.3674 - val_acc: 0.3900\n","Epoch 696/1500\n","5501/5501 [==============================] - 4s 652us/sample - loss: 0.3673 - acc: 0.3900 - val_loss: 0.3671 - val_acc: 0.3900\n","Epoch 697/1500\n","5501/5501 [==============================] - 4s 661us/sample - loss: 0.3671 - acc: 0.3900 - val_loss: 0.3668 - val_acc: 0.3901\n","Epoch 698/1500\n","5501/5501 [==============================] - 4s 656us/sample - loss: 0.3672 - acc: 0.3900 - val_loss: 0.3670 - val_acc: 0.3900\n","Epoch 699/1500\n","5501/5501 [==============================] - 4s 655us/sample - loss: 0.3671 - acc: 0.3900 - val_loss: 0.3668 - val_acc: 0.3901\n","Epoch 700/1500\n","5501/5501 [==============================] - 4s 657us/sample - loss: 0.3669 - acc: 0.3900 - val_loss: 0.3667 - val_acc: 0.3901\n","Epoch 701/1500\n","5501/5501 [==============================] - 4s 670us/sample - loss: 0.3669 - acc: 0.3900 - val_loss: 0.3666 - val_acc: 0.3901\n","Epoch 702/1500\n","5501/5501 [==============================] - 4s 661us/sample - loss: 0.3671 - acc: 0.3900 - val_loss: 0.3670 - val_acc: 0.3900\n","Epoch 703/1500\n","5501/5501 [==============================] - 4s 656us/sample - loss: 0.3672 - acc: 0.3900 - val_loss: 0.3668 - val_acc: 0.3901\n","Epoch 704/1500\n","5501/5501 [==============================] - 4s 658us/sample - loss: 0.3671 - acc: 0.3900 - val_loss: 0.3671 - val_acc: 0.3900\n","Epoch 705/1500\n","5501/5501 [==============================] - 4s 653us/sample - loss: 0.3673 - acc: 0.3900 - val_loss: 0.3668 - val_acc: 0.3901\n","Epoch 706/1500\n","5501/5501 [==============================] - 4s 657us/sample - loss: 0.3671 - acc: 0.3900 - val_loss: 0.3668 - val_acc: 0.3901\n","Epoch 707/1500\n","5501/5501 [==============================] - 4s 654us/sample - loss: 0.3670 - acc: 0.3900 - val_loss: 0.3668 - val_acc: 0.3901\n","Epoch 708/1500\n","5501/5501 [==============================] - 4s 655us/sample - loss: 0.3669 - acc: 0.3900 - val_loss: 0.3667 - val_acc: 0.3901\n","Epoch 709/1500\n","5501/5501 [==============================] - 4s 657us/sample - loss: 0.3670 - acc: 0.3900 - val_loss: 0.3670 - val_acc: 0.3900\n","Epoch 710/1500\n","5501/5501 [==============================] - 4s 652us/sample - loss: 0.3671 - acc: 0.3900 - val_loss: 0.3669 - val_acc: 0.3901\n","Epoch 711/1500\n","5501/5501 [==============================] - 4s 653us/sample - loss: 0.3670 - acc: 0.3900 - val_loss: 0.3668 - val_acc: 0.3901\n","Epoch 712/1500\n","5501/5501 [==============================] - 4s 659us/sample - loss: 0.3672 - acc: 0.3900 - val_loss: 0.3669 - val_acc: 0.3900\n","Epoch 713/1500\n","5501/5501 [==============================] - 4s 651us/sample - loss: 0.3673 - acc: 0.3900 - val_loss: 0.3669 - val_acc: 0.3900\n","Epoch 714/1500\n","5501/5501 [==============================] - 4s 658us/sample - loss: 0.3671 - acc: 0.3900 - val_loss: 0.3669 - val_acc: 0.3900\n","Epoch 715/1500\n","5501/5501 [==============================] - 4s 655us/sample - loss: 0.3670 - acc: 0.3900 - val_loss: 0.3667 - val_acc: 0.3901\n","Epoch 716/1500\n","5501/5501 [==============================] - 4s 658us/sample - loss: 0.3670 - acc: 0.3900 - val_loss: 0.3668 - val_acc: 0.3901\n","Epoch 717/1500\n","5501/5501 [==============================] - 4s 656us/sample - loss: 0.3671 - acc: 0.3900 - val_loss: 0.3671 - val_acc: 0.3900\n","Epoch 718/1500\n","5501/5501 [==============================] - 4s 652us/sample - loss: 0.3675 - acc: 0.3900 - val_loss: 0.3670 - val_acc: 0.3900\n","Epoch 719/1500\n","5501/5501 [==============================] - 4s 660us/sample - loss: 0.3671 - acc: 0.3900 - val_loss: 0.3668 - val_acc: 0.3901\n","Epoch 720/1500\n","5501/5501 [==============================] - 4s 653us/sample - loss: 0.3670 - acc: 0.3900 - val_loss: 0.3669 - val_acc: 0.3901\n","Epoch 721/1500\n","5501/5501 [==============================] - 4s 654us/sample - loss: 0.3671 - acc: 0.3900 - val_loss: 0.3667 - val_acc: 0.3901\n","Epoch 722/1500\n","5501/5501 [==============================] - 4s 654us/sample - loss: 0.3669 - acc: 0.3900 - val_loss: 0.3667 - val_acc: 0.3901\n","Epoch 723/1500\n","5501/5501 [==============================] - 4s 656us/sample - loss: 0.3669 - acc: 0.3900 - val_loss: 0.3667 - val_acc: 0.3901\n","Epoch 724/1500\n","5501/5501 [==============================] - 4s 657us/sample - loss: 0.3670 - acc: 0.3900 - val_loss: 0.3667 - val_acc: 0.3901\n","Epoch 725/1500\n","5501/5501 [==============================] - 4s 665us/sample - loss: 0.3670 - acc: 0.3900 - val_loss: 0.3668 - val_acc: 0.3901\n","Epoch 726/1500\n","5501/5501 [==============================] - 4s 655us/sample - loss: 0.3684 - acc: 0.3899 - val_loss: 0.3752 - val_acc: 0.3894\n","Epoch 727/1500\n","5501/5501 [==============================] - 4s 655us/sample - loss: 0.3925 - acc: 0.3875 - val_loss: 0.3819 - val_acc: 0.3888\n","Epoch 728/1500\n","5501/5501 [==============================] - 4s 659us/sample - loss: 0.3735 - acc: 0.3894 - val_loss: 0.3692 - val_acc: 0.3899\n","Epoch 729/1500\n","5501/5501 [==============================] - 4s 667us/sample - loss: 0.3684 - acc: 0.3899 - val_loss: 0.3675 - val_acc: 0.3900\n","Epoch 730/1500\n","5501/5501 [==============================] - 4s 670us/sample - loss: 0.3675 - acc: 0.3900 - val_loss: 0.3671 - val_acc: 0.3900\n","Epoch 731/1500\n","5501/5501 [==============================] - 4s 655us/sample - loss: 0.3672 - acc: 0.3900 - val_loss: 0.3669 - val_acc: 0.3901\n","Epoch 732/1500\n","5501/5501 [==============================] - 4s 655us/sample - loss: 0.3670 - acc: 0.3900 - val_loss: 0.3667 - val_acc: 0.3901\n","Epoch 733/1500\n","5501/5501 [==============================] - 4s 661us/sample - loss: 0.3670 - acc: 0.3900 - val_loss: 0.3667 - val_acc: 0.3901\n","Epoch 734/1500\n","5501/5501 [==============================] - 4s 659us/sample - loss: 0.3669 - acc: 0.3900 - val_loss: 0.3666 - val_acc: 0.3901\n","Epoch 735/1500\n","5501/5501 [==============================] - 4s 655us/sample - loss: 0.3669 - acc: 0.3900 - val_loss: 0.3666 - val_acc: 0.3901\n","Epoch 736/1500\n","5501/5501 [==============================] - 4s 655us/sample - loss: 0.3668 - acc: 0.3900 - val_loss: 0.3666 - val_acc: 0.3901\n","Epoch 737/1500\n","5501/5501 [==============================] - 4s 654us/sample - loss: 0.3668 - acc: 0.3900 - val_loss: 0.3665 - val_acc: 0.3901\n","Epoch 738/1500\n","5501/5501 [==============================] - 4s 653us/sample - loss: 0.3668 - acc: 0.3901 - val_loss: 0.3666 - val_acc: 0.3901\n","Epoch 739/1500\n","5501/5501 [==============================] - 4s 656us/sample - loss: 0.3668 - acc: 0.3901 - val_loss: 0.3665 - val_acc: 0.3901\n","Epoch 740/1500\n","5501/5501 [==============================] - 4s 657us/sample - loss: 0.3668 - acc: 0.3901 - val_loss: 0.3666 - val_acc: 0.3901\n","Epoch 741/1500\n","5501/5501 [==============================] - 4s 652us/sample - loss: 0.3668 - acc: 0.3900 - val_loss: 0.3666 - val_acc: 0.3901\n","Epoch 742/1500\n","5501/5501 [==============================] - 4s 654us/sample - loss: 0.3668 - acc: 0.3900 - val_loss: 0.3666 - val_acc: 0.3901\n","Epoch 743/1500\n","5501/5501 [==============================] - 4s 651us/sample - loss: 0.3668 - acc: 0.3900 - val_loss: 0.3665 - val_acc: 0.3901\n","Epoch 744/1500\n","5501/5501 [==============================] - 4s 658us/sample - loss: 0.3668 - acc: 0.3900 - val_loss: 0.3666 - val_acc: 0.3901\n","Epoch 745/1500\n","5501/5501 [==============================] - 4s 657us/sample - loss: 0.3668 - acc: 0.3900 - val_loss: 0.3666 - val_acc: 0.3901\n","Epoch 746/1500\n","5501/5501 [==============================] - 4s 653us/sample - loss: 0.3668 - acc: 0.3900 - val_loss: 0.3666 - val_acc: 0.3901\n","Epoch 747/1500\n","5501/5501 [==============================] - 4s 655us/sample - loss: 0.3668 - acc: 0.3900 - val_loss: 0.3665 - val_acc: 0.3901\n","Epoch 748/1500\n","5501/5501 [==============================] - 4s 655us/sample - loss: 0.3668 - acc: 0.3900 - val_loss: 0.3665 - val_acc: 0.3901\n","Epoch 749/1500\n","5501/5501 [==============================] - 4s 651us/sample - loss: 0.3668 - acc: 0.3900 - val_loss: 0.3666 - val_acc: 0.3901\n","Epoch 750/1500\n","5501/5501 [==============================] - 4s 659us/sample - loss: 0.3668 - acc: 0.3900 - val_loss: 0.3666 - val_acc: 0.3901\n","Epoch 751/1500\n","5501/5501 [==============================] - 4s 652us/sample - loss: 0.3669 - acc: 0.3900 - val_loss: 0.3668 - val_acc: 0.3901\n","Epoch 752/1500\n","5501/5501 [==============================] - 4s 651us/sample - loss: 0.3672 - acc: 0.3900 - val_loss: 0.3673 - val_acc: 0.3900\n","Epoch 753/1500\n","5501/5501 [==============================] - 4s 663us/sample - loss: 0.3674 - acc: 0.3900 - val_loss: 0.3671 - val_acc: 0.3900\n","Epoch 754/1500\n","5501/5501 [==============================] - 4s 645us/sample - loss: 0.3672 - acc: 0.3900 - val_loss: 0.3668 - val_acc: 0.3901\n","Epoch 755/1500\n","5501/5501 [==============================] - 4s 648us/sample - loss: 0.3669 - acc: 0.3900 - val_loss: 0.3666 - val_acc: 0.3901\n","Epoch 756/1500\n","5501/5501 [==============================] - 4s 657us/sample - loss: 0.3669 - acc: 0.3900 - val_loss: 0.3667 - val_acc: 0.3901\n","Epoch 757/1500\n","5501/5501 [==============================] - 4s 655us/sample - loss: 0.3669 - acc: 0.3900 - val_loss: 0.3666 - val_acc: 0.3901\n","Epoch 758/1500\n","5501/5501 [==============================] - 4s 659us/sample - loss: 0.3669 - acc: 0.3900 - val_loss: 0.3667 - val_acc: 0.3901\n","Epoch 759/1500\n","5501/5501 [==============================] - 4s 650us/sample - loss: 0.3670 - acc: 0.3900 - val_loss: 0.3669 - val_acc: 0.3900\n","Epoch 760/1500\n","5501/5501 [==============================] - 4s 653us/sample - loss: 0.3671 - acc: 0.3900 - val_loss: 0.3670 - val_acc: 0.3900\n","Epoch 761/1500\n","5501/5501 [==============================] - 4s 657us/sample - loss: 0.3671 - acc: 0.3900 - val_loss: 0.3668 - val_acc: 0.3901\n","Epoch 762/1500\n","5501/5501 [==============================] - 4s 662us/sample - loss: 0.3671 - acc: 0.3900 - val_loss: 0.3668 - val_acc: 0.3901\n","Epoch 763/1500\n","5501/5501 [==============================] - 4s 657us/sample - loss: 0.3670 - acc: 0.3900 - val_loss: 0.3667 - val_acc: 0.3901\n","Epoch 764/1500\n","5501/5501 [==============================] - 4s 661us/sample - loss: 0.3668 - acc: 0.3900 - val_loss: 0.3666 - val_acc: 0.3901\n","Epoch 765/1500\n","5501/5501 [==============================] - 4s 653us/sample - loss: 0.3669 - acc: 0.3900 - val_loss: 0.3669 - val_acc: 0.3900\n","Epoch 766/1500\n","5501/5501 [==============================] - 4s 651us/sample - loss: 0.3670 - acc: 0.3900 - val_loss: 0.3668 - val_acc: 0.3901\n","Epoch 767/1500\n","5501/5501 [==============================] - 4s 655us/sample - loss: 0.3670 - acc: 0.3900 - val_loss: 0.3667 - val_acc: 0.3901\n","Epoch 768/1500\n","5501/5501 [==============================] - 4s 657us/sample - loss: 0.3668 - acc: 0.3900 - val_loss: 0.3665 - val_acc: 0.3901\n","Epoch 769/1500\n","5501/5501 [==============================] - 4s 657us/sample - loss: 0.3668 - acc: 0.3900 - val_loss: 0.3669 - val_acc: 0.3900\n","Epoch 770/1500\n","5501/5501 [==============================] - 4s 660us/sample - loss: 0.3672 - acc: 0.3900 - val_loss: 0.3670 - val_acc: 0.3900\n","Epoch 771/1500\n","5501/5501 [==============================] - 4s 656us/sample - loss: 0.3672 - acc: 0.3900 - val_loss: 0.3669 - val_acc: 0.3900\n","Epoch 772/1500\n","5501/5501 [==============================] - 4s 651us/sample - loss: 0.3671 - acc: 0.3900 - val_loss: 0.3670 - val_acc: 0.3900\n","Epoch 773/1500\n","5501/5501 [==============================] - 4s 654us/sample - loss: 0.3673 - acc: 0.3900 - val_loss: 0.3670 - val_acc: 0.3900\n","Epoch 774/1500\n","5501/5501 [==============================] - 4s 656us/sample - loss: 0.3672 - acc: 0.3900 - val_loss: 0.3669 - val_acc: 0.3900\n","Epoch 775/1500\n","5501/5501 [==============================] - 4s 655us/sample - loss: 0.3671 - acc: 0.3900 - val_loss: 0.3670 - val_acc: 0.3900\n","Epoch 776/1500\n","5501/5501 [==============================] - 4s 652us/sample - loss: 0.3774 - acc: 0.3890 - val_loss: 0.3988 - val_acc: 0.3867\n","Epoch 777/1500\n","5501/5501 [==============================] - 4s 655us/sample - loss: 0.3815 - acc: 0.3887 - val_loss: 0.3708 - val_acc: 0.3897\n","Epoch 778/1500\n","5501/5501 [==============================] - 4s 654us/sample - loss: 0.3689 - acc: 0.3899 - val_loss: 0.3676 - val_acc: 0.3900\n","Epoch 779/1500\n","5501/5501 [==============================] - 4s 656us/sample - loss: 0.3675 - acc: 0.3900 - val_loss: 0.3670 - val_acc: 0.3900\n","Epoch 780/1500\n","5501/5501 [==============================] - 4s 650us/sample - loss: 0.3671 - acc: 0.3900 - val_loss: 0.3668 - val_acc: 0.3901\n","Epoch 781/1500\n","5501/5501 [==============================] - 4s 653us/sample - loss: 0.3670 - acc: 0.3900 - val_loss: 0.3667 - val_acc: 0.3901\n","Epoch 782/1500\n","5501/5501 [==============================] - 4s 649us/sample - loss: 0.3669 - acc: 0.3900 - val_loss: 0.3667 - val_acc: 0.3901\n","Epoch 783/1500\n","5501/5501 [==============================] - 4s 649us/sample - loss: 0.3669 - acc: 0.3900 - val_loss: 0.3666 - val_acc: 0.3901\n","Epoch 784/1500\n","5501/5501 [==============================] - 4s 649us/sample - loss: 0.3668 - acc: 0.3901 - val_loss: 0.3665 - val_acc: 0.3901\n","Epoch 785/1500\n","5501/5501 [==============================] - 4s 666us/sample - loss: 0.3668 - acc: 0.3901 - val_loss: 0.3665 - val_acc: 0.3901\n","Epoch 786/1500\n","5501/5501 [==============================] - 4s 667us/sample - loss: 0.3667 - acc: 0.3901 - val_loss: 0.3665 - val_acc: 0.3901\n","Epoch 787/1500\n","5501/5501 [==============================] - 4s 651us/sample - loss: 0.3667 - acc: 0.3901 - val_loss: 0.3665 - val_acc: 0.3901\n","Epoch 788/1500\n","5501/5501 [==============================] - 4s 648us/sample - loss: 0.3667 - acc: 0.3901 - val_loss: 0.3665 - val_acc: 0.3901\n","Epoch 789/1500\n","5501/5501 [==============================] - 4s 656us/sample - loss: 0.3667 - acc: 0.3901 - val_loss: 0.3665 - val_acc: 0.3901\n","Epoch 790/1500\n","5501/5501 [==============================] - 4s 650us/sample - loss: 0.3667 - acc: 0.3901 - val_loss: 0.3665 - val_acc: 0.3901\n","Epoch 791/1500\n","5501/5501 [==============================] - 4s 656us/sample - loss: 0.3667 - acc: 0.3901 - val_loss: 0.3665 - val_acc: 0.3901\n","Epoch 792/1500\n","5501/5501 [==============================] - 4s 660us/sample - loss: 0.3667 - acc: 0.3901 - val_loss: 0.3665 - val_acc: 0.3901\n","Epoch 793/1500\n","5501/5501 [==============================] - 4s 652us/sample - loss: 0.3668 - acc: 0.3900 - val_loss: 0.3665 - val_acc: 0.3901\n","Epoch 794/1500\n","5501/5501 [==============================] - 4s 654us/sample - loss: 0.3668 - acc: 0.3900 - val_loss: 0.3666 - val_acc: 0.3901\n","Epoch 795/1500\n","5501/5501 [==============================] - 4s 657us/sample - loss: 0.3668 - acc: 0.3900 - val_loss: 0.3666 - val_acc: 0.3901\n","Epoch 796/1500\n","5501/5501 [==============================] - 4s 650us/sample - loss: 0.3668 - acc: 0.3900 - val_loss: 0.3666 - val_acc: 0.3901\n","Epoch 797/1500\n","5501/5501 [==============================] - 4s 649us/sample - loss: 0.3669 - acc: 0.3900 - val_loss: 0.3667 - val_acc: 0.3901\n","Epoch 798/1500\n","5501/5501 [==============================] - 4s 649us/sample - loss: 0.3669 - acc: 0.3900 - val_loss: 0.3666 - val_acc: 0.3901\n","Epoch 799/1500\n","5501/5501 [==============================] - 4s 656us/sample - loss: 0.3669 - acc: 0.3900 - val_loss: 0.3666 - val_acc: 0.3901\n","Epoch 800/1500\n","5501/5501 [==============================] - 4s 651us/sample - loss: 0.3669 - acc: 0.3900 - val_loss: 0.3668 - val_acc: 0.3901\n","Epoch 801/1500\n","5501/5501 [==============================] - 4s 654us/sample - loss: 0.3669 - acc: 0.3900 - val_loss: 0.3667 - val_acc: 0.3901\n","Epoch 802/1500\n","5501/5501 [==============================] - 4s 653us/sample - loss: 0.3669 - acc: 0.3900 - val_loss: 0.3667 - val_acc: 0.3901\n","Epoch 803/1500\n","5501/5501 [==============================] - 4s 656us/sample - loss: 0.3669 - acc: 0.3900 - val_loss: 0.3667 - val_acc: 0.3901\n","Epoch 804/1500\n","5501/5501 [==============================] - 4s 651us/sample - loss: 0.3669 - acc: 0.3900 - val_loss: 0.3668 - val_acc: 0.3900\n","Epoch 805/1500\n","5501/5501 [==============================] - 4s 654us/sample - loss: 0.3670 - acc: 0.3900 - val_loss: 0.3669 - val_acc: 0.3900\n","Epoch 806/1500\n","5501/5501 [==============================] - 4s 651us/sample - loss: 0.3672 - acc: 0.3900 - val_loss: 0.3671 - val_acc: 0.3900\n","Epoch 807/1500\n","5501/5501 [==============================] - 4s 658us/sample - loss: 0.3671 - acc: 0.3900 - val_loss: 0.3667 - val_acc: 0.3901\n","Epoch 808/1500\n","5501/5501 [==============================] - 4s 654us/sample - loss: 0.3669 - acc: 0.3900 - val_loss: 0.3669 - val_acc: 0.3900\n","Epoch 809/1500\n","5501/5501 [==============================] - 4s 653us/sample - loss: 0.3671 - acc: 0.3900 - val_loss: 0.3669 - val_acc: 0.3900\n","Epoch 810/1500\n","5501/5501 [==============================] - 4s 653us/sample - loss: 0.3670 - acc: 0.3900 - val_loss: 0.3668 - val_acc: 0.3901\n","Epoch 811/1500\n","5501/5501 [==============================] - 4s 649us/sample - loss: 0.3669 - acc: 0.3900 - val_loss: 0.3667 - val_acc: 0.3901\n","Epoch 812/1500\n","5501/5501 [==============================] - 4s 652us/sample - loss: 0.3669 - acc: 0.3900 - val_loss: 0.3667 - val_acc: 0.3901\n","Epoch 813/1500\n","5501/5501 [==============================] - 4s 647us/sample - loss: 0.3669 - acc: 0.3900 - val_loss: 0.3666 - val_acc: 0.3901\n","Epoch 814/1500\n","5501/5501 [==============================] - 4s 652us/sample - loss: 0.3669 - acc: 0.3900 - val_loss: 0.3669 - val_acc: 0.3901\n","Epoch 815/1500\n","5501/5501 [==============================] - 4s 677us/sample - loss: 0.3671 - acc: 0.3900 - val_loss: 0.3670 - val_acc: 0.3900\n","Epoch 816/1500\n","5501/5501 [==============================] - 4s 662us/sample - loss: 0.3671 - acc: 0.3900 - val_loss: 0.3671 - val_acc: 0.3900\n","Epoch 817/1500\n","5501/5501 [==============================] - 4s 657us/sample - loss: 0.3674 - acc: 0.3900 - val_loss: 0.3681 - val_acc: 0.3899\n","Epoch 818/1500\n","5501/5501 [==============================] - 4s 652us/sample - loss: 0.3688 - acc: 0.3899 - val_loss: 0.3680 - val_acc: 0.3899\n","Epoch 819/1500\n","5501/5501 [==============================] - 4s 650us/sample - loss: 0.3679 - acc: 0.3900 - val_loss: 0.3671 - val_acc: 0.3900\n","Epoch 820/1500\n","5501/5501 [==============================] - 4s 655us/sample - loss: 0.3670 - acc: 0.3900 - val_loss: 0.3667 - val_acc: 0.3901\n","Epoch 821/1500\n","5501/5501 [==============================] - 4s 655us/sample - loss: 0.3668 - acc: 0.3900 - val_loss: 0.3666 - val_acc: 0.3901\n","Epoch 822/1500\n","5501/5501 [==============================] - 4s 651us/sample - loss: 0.3668 - acc: 0.3900 - val_loss: 0.3667 - val_acc: 0.3901\n","Epoch 823/1500\n","5501/5501 [==============================] - 4s 652us/sample - loss: 0.3668 - acc: 0.3900 - val_loss: 0.3666 - val_acc: 0.3901\n","Epoch 824/1500\n","5501/5501 [==============================] - 4s 659us/sample - loss: 0.3668 - acc: 0.3900 - val_loss: 0.3665 - val_acc: 0.3901\n","Epoch 825/1500\n","5501/5501 [==============================] - 4s 649us/sample - loss: 0.3668 - acc: 0.3900 - val_loss: 0.3666 - val_acc: 0.3901\n","Epoch 826/1500\n","5501/5501 [==============================] - 4s 647us/sample - loss: 0.3668 - acc: 0.3900 - val_loss: 0.3667 - val_acc: 0.3901\n","Epoch 827/1500\n","5501/5501 [==============================] - 4s 653us/sample - loss: 0.3670 - acc: 0.3900 - val_loss: 0.3670 - val_acc: 0.3900\n","Epoch 828/1500\n","5501/5501 [==============================] - 4s 651us/sample - loss: 0.3671 - acc: 0.3900 - val_loss: 0.3669 - val_acc: 0.3900\n","Epoch 829/1500\n","5501/5501 [==============================] - 4s 652us/sample - loss: 0.3671 - acc: 0.3900 - val_loss: 0.3670 - val_acc: 0.3900\n","Epoch 830/1500\n","5501/5501 [==============================] - 4s 653us/sample - loss: 0.3672 - acc: 0.3900 - val_loss: 0.3668 - val_acc: 0.3901\n","Epoch 831/1500\n","5501/5501 [==============================] - 4s 650us/sample - loss: 0.3671 - acc: 0.3900 - val_loss: 0.3668 - val_acc: 0.3901\n","Epoch 832/1500\n","5501/5501 [==============================] - 4s 649us/sample - loss: 0.3669 - acc: 0.3900 - val_loss: 0.3667 - val_acc: 0.3901\n","Epoch 833/1500\n","5501/5501 [==============================] - 4s 654us/sample - loss: 0.3669 - acc: 0.3900 - val_loss: 0.3666 - val_acc: 0.3901\n","Epoch 834/1500\n","5501/5501 [==============================] - 4s 650us/sample - loss: 0.3669 - acc: 0.3900 - val_loss: 0.3666 - val_acc: 0.3901\n","Epoch 835/1500\n","5501/5501 [==============================] - 4s 657us/sample - loss: 0.3669 - acc: 0.3900 - val_loss: 0.3666 - val_acc: 0.3901\n","Epoch 836/1500\n","5501/5501 [==============================] - 4s 658us/sample - loss: 0.3669 - acc: 0.3900 - val_loss: 0.3667 - val_acc: 0.3901\n","Epoch 837/1500\n","5501/5501 [==============================] - 4s 655us/sample - loss: 0.3670 - acc: 0.3900 - val_loss: 0.3667 - val_acc: 0.3901\n","Epoch 838/1500\n","5501/5501 [==============================] - 4s 651us/sample - loss: 0.3668 - acc: 0.3900 - val_loss: 0.3666 - val_acc: 0.3901\n","Epoch 839/1500\n","5501/5501 [==============================] - 4s 654us/sample - loss: 0.3668 - acc: 0.3900 - val_loss: 0.3666 - val_acc: 0.3901\n","Epoch 840/1500\n","5501/5501 [==============================] - 4s 653us/sample - loss: 0.3670 - acc: 0.3900 - val_loss: 0.3668 - val_acc: 0.3901\n","Epoch 841/1500\n","5501/5501 [==============================] - 4s 653us/sample - loss: 0.3671 - acc: 0.3900 - val_loss: 0.3677 - val_acc: 0.3900\n","Epoch 842/1500\n","5501/5501 [==============================] - 4s 656us/sample - loss: 0.3687 - acc: 0.3899 - val_loss: 0.3679 - val_acc: 0.3900\n","Epoch 843/1500\n","5501/5501 [==============================] - 4s 651us/sample - loss: 0.3679 - acc: 0.3899 - val_loss: 0.3669 - val_acc: 0.3900\n","Epoch 844/1500\n","5501/5501 [==============================] - 4s 653us/sample - loss: 0.3670 - acc: 0.3900 - val_loss: 0.3667 - val_acc: 0.3901\n","Epoch 845/1500\n","5501/5501 [==============================] - 4s 655us/sample - loss: 0.3668 - acc: 0.3900 - val_loss: 0.3665 - val_acc: 0.3901\n","Epoch 846/1500\n","5501/5501 [==============================] - 4s 653us/sample - loss: 0.3667 - acc: 0.3901 - val_loss: 0.3664 - val_acc: 0.3901\n","Epoch 847/1500\n","5501/5501 [==============================] - 4s 653us/sample - loss: 0.3666 - acc: 0.3901 - val_loss: 0.3664 - val_acc: 0.3901\n","Epoch 848/1500\n","5501/5501 [==============================] - 4s 662us/sample - loss: 0.3666 - acc: 0.3901 - val_loss: 0.3664 - val_acc: 0.3901\n","Epoch 849/1500\n","5501/5501 [==============================] - 4s 654us/sample - loss: 0.3667 - acc: 0.3901 - val_loss: 0.3665 - val_acc: 0.3901\n","Epoch 850/1500\n","5501/5501 [==============================] - 4s 650us/sample - loss: 0.3667 - acc: 0.3900 - val_loss: 0.3665 - val_acc: 0.3901\n","Epoch 851/1500\n","5501/5501 [==============================] - 4s 652us/sample - loss: 0.3667 - acc: 0.3901 - val_loss: 0.3665 - val_acc: 0.3901\n","Epoch 852/1500\n","5501/5501 [==============================] - 4s 660us/sample - loss: 0.3668 - acc: 0.3900 - val_loss: 0.3666 - val_acc: 0.3901\n","Epoch 853/1500\n","5501/5501 [==============================] - 4s 652us/sample - loss: 0.3669 - acc: 0.3900 - val_loss: 0.3667 - val_acc: 0.3901\n","Epoch 854/1500\n","5501/5501 [==============================] - 4s 651us/sample - loss: 0.3670 - acc: 0.3900 - val_loss: 0.3669 - val_acc: 0.3900\n","Epoch 855/1500\n","5501/5501 [==============================] - 4s 657us/sample - loss: 0.3672 - acc: 0.3900 - val_loss: 0.3670 - val_acc: 0.3900\n","Epoch 856/1500\n","5501/5501 [==============================] - 4s 658us/sample - loss: 0.3672 - acc: 0.3900 - val_loss: 0.3670 - val_acc: 0.3900\n","Epoch 857/1500\n","5501/5501 [==============================] - 4s 652us/sample - loss: 0.3672 - acc: 0.3900 - val_loss: 0.3669 - val_acc: 0.3900\n","Epoch 858/1500\n","5501/5501 [==============================] - 4s 656us/sample - loss: 0.3669 - acc: 0.3900 - val_loss: 0.3665 - val_acc: 0.3901\n","Epoch 859/1500\n","5501/5501 [==============================] - 4s 653us/sample - loss: 0.3667 - acc: 0.3901 - val_loss: 0.3665 - val_acc: 0.3901\n","Epoch 860/1500\n","5501/5501 [==============================] - 4s 655us/sample - loss: 0.3668 - acc: 0.3900 - val_loss: 0.3666 - val_acc: 0.3901\n","Epoch 861/1500\n","5501/5501 [==============================] - 4s 654us/sample - loss: 0.3669 - acc: 0.3900 - val_loss: 0.3667 - val_acc: 0.3901\n","Epoch 862/1500\n","5501/5501 [==============================] - 4s 652us/sample - loss: 0.3669 - acc: 0.3900 - val_loss: 0.3666 - val_acc: 0.3901\n","Epoch 863/1500\n","5501/5501 [==============================] - 4s 650us/sample - loss: 0.3671 - acc: 0.3900 - val_loss: 0.3668 - val_acc: 0.3900\n","Epoch 864/1500\n","5501/5501 [==============================] - 4s 656us/sample - loss: 0.3669 - acc: 0.3900 - val_loss: 0.3666 - val_acc: 0.3901\n","Epoch 865/1500\n","5501/5501 [==============================] - 4s 663us/sample - loss: 0.3669 - acc: 0.3900 - val_loss: 0.3667 - val_acc: 0.3901\n","Epoch 866/1500\n","5501/5501 [==============================] - 4s 657us/sample - loss: 0.3670 - acc: 0.3900 - val_loss: 0.3670 - val_acc: 0.3900\n","Epoch 867/1500\n","5501/5501 [==============================] - 4s 650us/sample - loss: 0.3672 - acc: 0.3900 - val_loss: 0.3668 - val_acc: 0.3901\n","Epoch 868/1500\n","5501/5501 [==============================] - 4s 654us/sample - loss: 0.3670 - acc: 0.3900 - val_loss: 0.3667 - val_acc: 0.3901\n","Epoch 869/1500\n","5501/5501 [==============================] - 4s 652us/sample - loss: 0.3668 - acc: 0.3900 - val_loss: 0.3665 - val_acc: 0.3901\n","Epoch 870/1500\n","5501/5501 [==============================] - 4s 665us/sample - loss: 0.3667 - acc: 0.3901 - val_loss: 0.3665 - val_acc: 0.3901\n","Epoch 871/1500\n","5501/5501 [==============================] - 4s 660us/sample - loss: 0.3668 - acc: 0.3900 - val_loss: 0.3665 - val_acc: 0.3901\n","Epoch 872/1500\n","5501/5501 [==============================] - 4s 656us/sample - loss: 0.3668 - acc: 0.3900 - val_loss: 0.3666 - val_acc: 0.3901\n","Epoch 873/1500\n","5501/5501 [==============================] - 4s 651us/sample - loss: 0.3669 - acc: 0.3900 - val_loss: 0.3666 - val_acc: 0.3901\n","Epoch 874/1500\n","5501/5501 [==============================] - 4s 651us/sample - loss: 0.3668 - acc: 0.3900 - val_loss: 0.3667 - val_acc: 0.3901\n","Epoch 875/1500\n","5501/5501 [==============================] - 4s 654us/sample - loss: 0.3668 - acc: 0.3900 - val_loss: 0.3667 - val_acc: 0.3901\n","Epoch 876/1500\n","5501/5501 [==============================] - 4s 653us/sample - loss: 0.3671 - acc: 0.3900 - val_loss: 0.3675 - val_acc: 0.3900\n","Epoch 877/1500\n","5501/5501 [==============================] - 4s 657us/sample - loss: 0.3684 - acc: 0.3899 - val_loss: 0.3721 - val_acc: 0.3896\n","Epoch 878/1500\n","5501/5501 [==============================] - 4s 651us/sample - loss: 0.3908 - acc: 0.3875 - val_loss: 0.3749 - val_acc: 0.3894\n","Epoch 879/1500\n","5501/5501 [==============================] - 4s 647us/sample - loss: 0.3708 - acc: 0.3897 - val_loss: 0.3682 - val_acc: 0.3900\n","Epoch 880/1500\n","5501/5501 [==============================] - 4s 654us/sample - loss: 0.3679 - acc: 0.3900 - val_loss: 0.3672 - val_acc: 0.3900\n","Epoch 881/1500\n","5501/5501 [==============================] - 4s 654us/sample - loss: 0.3673 - acc: 0.3900 - val_loss: 0.3669 - val_acc: 0.3900\n","Epoch 882/1500\n","5501/5501 [==============================] - 4s 646us/sample - loss: 0.3671 - acc: 0.3900 - val_loss: 0.3668 - val_acc: 0.3901\n","Epoch 883/1500\n","5501/5501 [==============================] - 4s 652us/sample - loss: 0.3669 - acc: 0.3900 - val_loss: 0.3667 - val_acc: 0.3901\n","Epoch 884/1500\n","5501/5501 [==============================] - 4s 656us/sample - loss: 0.3668 - acc: 0.3900 - val_loss: 0.3666 - val_acc: 0.3901\n","Epoch 885/1500\n","5501/5501 [==============================] - 4s 651us/sample - loss: 0.3668 - acc: 0.3901 - val_loss: 0.3665 - val_acc: 0.3901\n","Epoch 886/1500\n","5501/5501 [==============================] - 4s 656us/sample - loss: 0.3667 - acc: 0.3901 - val_loss: 0.3665 - val_acc: 0.3901\n","Epoch 887/1500\n","5501/5501 [==============================] - 4s 649us/sample - loss: 0.3667 - acc: 0.3901 - val_loss: 0.3665 - val_acc: 0.3901\n","Epoch 888/1500\n","5501/5501 [==============================] - 4s 652us/sample - loss: 0.3667 - acc: 0.3901 - val_loss: 0.3665 - val_acc: 0.3901\n","Epoch 889/1500\n","5501/5501 [==============================] - 4s 649us/sample - loss: 0.3667 - acc: 0.3901 - val_loss: 0.3665 - val_acc: 0.3901\n","Epoch 890/1500\n","5501/5501 [==============================] - 4s 649us/sample - loss: 0.3667 - acc: 0.3901 - val_loss: 0.3664 - val_acc: 0.3901\n","Epoch 891/1500\n","5501/5501 [==============================] - 4s 657us/sample - loss: 0.3667 - acc: 0.3901 - val_loss: 0.3665 - val_acc: 0.3901\n","Epoch 892/1500\n","5501/5501 [==============================] - 4s 655us/sample - loss: 0.3667 - acc: 0.3901 - val_loss: 0.3665 - val_acc: 0.3901\n","Epoch 893/1500\n","5501/5501 [==============================] - 4s 651us/sample - loss: 0.3667 - acc: 0.3901 - val_loss: 0.3665 - val_acc: 0.3901\n","Epoch 894/1500\n","5501/5501 [==============================] - 4s 653us/sample - loss: 0.3667 - acc: 0.3901 - val_loss: 0.3665 - val_acc: 0.3901\n","Epoch 895/1500\n","5501/5501 [==============================] - 4s 649us/sample - loss: 0.3667 - acc: 0.3901 - val_loss: 0.3665 - val_acc: 0.3901\n","Epoch 896/1500\n","5501/5501 [==============================] - 4s 651us/sample - loss: 0.3667 - acc: 0.3901 - val_loss: 0.3665 - val_acc: 0.3901\n","Epoch 897/1500\n","5501/5501 [==============================] - 4s 653us/sample - loss: 0.3667 - acc: 0.3901 - val_loss: 0.3665 - val_acc: 0.3901\n","Epoch 898/1500\n","5501/5501 [==============================] - 4s 651us/sample - loss: 0.3668 - acc: 0.3900 - val_loss: 0.3665 - val_acc: 0.3901\n","Epoch 899/1500\n","5501/5501 [==============================] - 4s 657us/sample - loss: 0.3668 - acc: 0.3900 - val_loss: 0.3665 - val_acc: 0.3901\n","Epoch 900/1500\n","5501/5501 [==============================] - 4s 653us/sample - loss: 0.3668 - acc: 0.3900 - val_loss: 0.3667 - val_acc: 0.3901\n","Epoch 901/1500\n","5501/5501 [==============================] - 4s 676us/sample - loss: 0.3669 - acc: 0.3900 - val_loss: 0.3667 - val_acc: 0.3901\n","Epoch 902/1500\n","5501/5501 [==============================] - 4s 666us/sample - loss: 0.3669 - acc: 0.3900 - val_loss: 0.3666 - val_acc: 0.3901\n","Epoch 903/1500\n","5501/5501 [==============================] - 4s 658us/sample - loss: 0.3668 - acc: 0.3900 - val_loss: 0.3665 - val_acc: 0.3901\n","Epoch 904/1500\n","5501/5501 [==============================] - 4s 654us/sample - loss: 0.3668 - acc: 0.3900 - val_loss: 0.3665 - val_acc: 0.3901\n","Epoch 905/1500\n","5501/5501 [==============================] - 4s 656us/sample - loss: 0.3668 - acc: 0.3900 - val_loss: 0.3667 - val_acc: 0.3901\n","Epoch 906/1500\n","5501/5501 [==============================] - 4s 655us/sample - loss: 0.3669 - acc: 0.3900 - val_loss: 0.3667 - val_acc: 0.3901\n","Epoch 907/1500\n","5501/5501 [==============================] - 4s 654us/sample - loss: 0.3669 - acc: 0.3900 - val_loss: 0.3667 - val_acc: 0.3901\n","Epoch 908/1500\n","5501/5501 [==============================] - 4s 654us/sample - loss: 0.3670 - acc: 0.3900 - val_loss: 0.3668 - val_acc: 0.3901\n","Epoch 909/1500\n","5501/5501 [==============================] - 4s 644us/sample - loss: 0.3669 - acc: 0.3900 - val_loss: 0.3665 - val_acc: 0.3901\n","Epoch 910/1500\n","5501/5501 [==============================] - 4s 652us/sample - loss: 0.3668 - acc: 0.3900 - val_loss: 0.3665 - val_acc: 0.3901\n","Epoch 911/1500\n","5501/5501 [==============================] - 4s 655us/sample - loss: 0.3668 - acc: 0.3900 - val_loss: 0.3667 - val_acc: 0.3901\n","Epoch 912/1500\n","5501/5501 [==============================] - 4s 651us/sample - loss: 0.3671 - acc: 0.3900 - val_loss: 0.3671 - val_acc: 0.3900\n","Epoch 913/1500\n","5501/5501 [==============================] - 4s 653us/sample - loss: 0.3672 - acc: 0.3900 - val_loss: 0.3669 - val_acc: 0.3900\n","Epoch 914/1500\n","5501/5501 [==============================] - 4s 654us/sample - loss: 0.3670 - acc: 0.3900 - val_loss: 0.3669 - val_acc: 0.3900\n","Epoch 915/1500\n","5501/5501 [==============================] - 4s 646us/sample - loss: 0.3669 - acc: 0.3900 - val_loss: 0.3666 - val_acc: 0.3901\n","Epoch 916/1500\n","5501/5501 [==============================] - 4s 644us/sample - loss: 0.3668 - acc: 0.3900 - val_loss: 0.3666 - val_acc: 0.3901\n","Epoch 917/1500\n","5501/5501 [==============================] - 4s 650us/sample - loss: 0.3668 - acc: 0.3900 - val_loss: 0.3666 - val_acc: 0.3901\n","Epoch 918/1500\n","5501/5501 [==============================] - 4s 652us/sample - loss: 0.3669 - acc: 0.3900 - val_loss: 0.3667 - val_acc: 0.3901\n","Epoch 919/1500\n","5501/5501 [==============================] - 4s 655us/sample - loss: 0.3668 - acc: 0.3900 - val_loss: 0.3666 - val_acc: 0.3901\n","Epoch 920/1500\n","5501/5501 [==============================] - 4s 659us/sample - loss: 0.3669 - acc: 0.3900 - val_loss: 0.3666 - val_acc: 0.3901\n","Epoch 921/1500\n","5501/5501 [==============================] - 4s 653us/sample - loss: 0.3669 - acc: 0.3900 - val_loss: 0.3668 - val_acc: 0.3901\n","Epoch 922/1500\n","5501/5501 [==============================] - 4s 652us/sample - loss: 0.3673 - acc: 0.3900 - val_loss: 0.3683 - val_acc: 0.3899\n","Epoch 923/1500\n","5501/5501 [==============================] - 4s 651us/sample - loss: 0.3684 - acc: 0.3899 - val_loss: 0.3673 - val_acc: 0.3900\n","Epoch 924/1500\n","5501/5501 [==============================] - 4s 656us/sample - loss: 0.3673 - acc: 0.3900 - val_loss: 0.3668 - val_acc: 0.3901\n","Epoch 925/1500\n","5501/5501 [==============================] - 4s 655us/sample - loss: 0.3669 - acc: 0.3900 - val_loss: 0.3666 - val_acc: 0.3901\n","Epoch 926/1500\n","5501/5501 [==============================] - 4s 656us/sample - loss: 0.3667 - acc: 0.3900 - val_loss: 0.3664 - val_acc: 0.3901\n","Epoch 927/1500\n","5501/5501 [==============================] - 4s 650us/sample - loss: 0.3666 - acc: 0.3901 - val_loss: 0.3664 - val_acc: 0.3901\n","Epoch 928/1500\n","5501/5501 [==============================] - 4s 658us/sample - loss: 0.3666 - acc: 0.3901 - val_loss: 0.3664 - val_acc: 0.3901\n","Epoch 929/1500\n","5501/5501 [==============================] - 4s 654us/sample - loss: 0.3667 - acc: 0.3901 - val_loss: 0.3665 - val_acc: 0.3901\n","Epoch 930/1500\n","5501/5501 [==============================] - 4s 651us/sample - loss: 0.3668 - acc: 0.3900 - val_loss: 0.3667 - val_acc: 0.3901\n","Epoch 931/1500\n","5501/5501 [==============================] - 4s 649us/sample - loss: 0.3669 - acc: 0.3900 - val_loss: 0.3666 - val_acc: 0.3901\n","Epoch 932/1500\n","5501/5501 [==============================] - 4s 653us/sample - loss: 0.3669 - acc: 0.3900 - val_loss: 0.3669 - val_acc: 0.3900\n","Epoch 933/1500\n","5501/5501 [==============================] - 4s 655us/sample - loss: 0.3672 - acc: 0.3900 - val_loss: 0.3670 - val_acc: 0.3900\n","Epoch 934/1500\n","5501/5501 [==============================] - 4s 651us/sample - loss: 0.3670 - acc: 0.3900 - val_loss: 0.3666 - val_acc: 0.3901\n","Epoch 935/1500\n","5501/5501 [==============================] - 4s 655us/sample - loss: 0.3669 - acc: 0.3900 - val_loss: 0.3666 - val_acc: 0.3901\n","Epoch 936/1500\n","5501/5501 [==============================] - 4s 648us/sample - loss: 0.3669 - acc: 0.3900 - val_loss: 0.3670 - val_acc: 0.3900\n","Epoch 937/1500\n","5501/5501 [==============================] - 4s 655us/sample - loss: 0.3670 - acc: 0.3900 - val_loss: 0.3666 - val_acc: 0.3901\n","Epoch 938/1500\n","5501/5501 [==============================] - 4s 651us/sample - loss: 0.3668 - acc: 0.3900 - val_loss: 0.3665 - val_acc: 0.3901\n","Epoch 939/1500\n","5501/5501 [==============================] - 4s 643us/sample - loss: 0.3667 - acc: 0.3900 - val_loss: 0.3665 - val_acc: 0.3901\n","Epoch 940/1500\n","5501/5501 [==============================] - 4s 643us/sample - loss: 0.3668 - acc: 0.3900 - val_loss: 0.3666 - val_acc: 0.3901\n","Epoch 941/1500\n","5501/5501 [==============================] - 4s 651us/sample - loss: 0.3668 - acc: 0.3900 - val_loss: 0.3666 - val_acc: 0.3901\n","Epoch 942/1500\n","5501/5501 [==============================] - 4s 647us/sample - loss: 0.3668 - acc: 0.3900 - val_loss: 0.3667 - val_acc: 0.3901\n","Epoch 943/1500\n","5501/5501 [==============================] - 4s 653us/sample - loss: 0.3668 - acc: 0.3900 - val_loss: 0.3666 - val_acc: 0.3901\n","Epoch 944/1500\n","5501/5501 [==============================] - 4s 646us/sample - loss: 0.3669 - acc: 0.3900 - val_loss: 0.3668 - val_acc: 0.3901\n","Epoch 945/1500\n","5501/5501 [==============================] - 4s 649us/sample - loss: 0.3669 - acc: 0.3900 - val_loss: 0.3666 - val_acc: 0.3901\n","Epoch 946/1500\n","5501/5501 [==============================] - 4s 651us/sample - loss: 0.3668 - acc: 0.3900 - val_loss: 0.3666 - val_acc: 0.3901\n","Epoch 947/1500\n","5501/5501 [==============================] - 4s 653us/sample - loss: 0.3668 - acc: 0.3900 - val_loss: 0.3667 - val_acc: 0.3901\n","Epoch 948/1500\n","5501/5501 [==============================] - 4s 650us/sample - loss: 0.3669 - acc: 0.3900 - val_loss: 0.3666 - val_acc: 0.3901\n","Epoch 949/1500\n","5501/5501 [==============================] - 4s 649us/sample - loss: 0.3670 - acc: 0.3900 - val_loss: 0.3667 - val_acc: 0.3901\n","Epoch 950/1500\n","5501/5501 [==============================] - 4s 647us/sample - loss: 0.3670 - acc: 0.3900 - val_loss: 0.3668 - val_acc: 0.3900\n","Epoch 951/1500\n","5501/5501 [==============================] - 4s 649us/sample - loss: 0.3670 - acc: 0.3900 - val_loss: 0.3667 - val_acc: 0.3901\n","Epoch 952/1500\n","5501/5501 [==============================] - 4s 651us/sample - loss: 0.3669 - acc: 0.3900 - val_loss: 0.3667 - val_acc: 0.3901\n","Epoch 953/1500\n","5501/5501 [==============================] - 4s 656us/sample - loss: 0.3668 - acc: 0.3900 - val_loss: 0.3666 - val_acc: 0.3901\n","Epoch 954/1500\n","5501/5501 [==============================] - 4s 653us/sample - loss: 0.3670 - acc: 0.3900 - val_loss: 0.3668 - val_acc: 0.3901\n","Epoch 955/1500\n","5501/5501 [==============================] - 4s 668us/sample - loss: 0.3670 - acc: 0.3900 - val_loss: 0.3668 - val_acc: 0.3901\n","Epoch 956/1500\n","5501/5501 [==============================] - 4s 653us/sample - loss: 0.3670 - acc: 0.3900 - val_loss: 0.3669 - val_acc: 0.3900\n","Epoch 957/1500\n","5501/5501 [==============================] - 4s 651us/sample - loss: 0.3672 - acc: 0.3900 - val_loss: 0.3667 - val_acc: 0.3901\n","Epoch 958/1500\n","5501/5501 [==============================] - 4s 654us/sample - loss: 0.3671 - acc: 0.3900 - val_loss: 0.3676 - val_acc: 0.3900\n","Epoch 959/1500\n","5501/5501 [==============================] - 4s 654us/sample - loss: 0.3761 - acc: 0.3892 - val_loss: 0.3926 - val_acc: 0.3873\n","Epoch 960/1500\n","5501/5501 [==============================] - 4s 652us/sample - loss: 0.3848 - acc: 0.3883 - val_loss: 0.3713 - val_acc: 0.3897\n","Epoch 961/1500\n","5501/5501 [==============================] - 4s 652us/sample - loss: 0.3692 - acc: 0.3899 - val_loss: 0.3677 - val_acc: 0.3900\n","Epoch 962/1500\n","5501/5501 [==============================] - 4s 657us/sample - loss: 0.3675 - acc: 0.3900 - val_loss: 0.3670 - val_acc: 0.3900\n","Epoch 963/1500\n","5501/5501 [==============================] - 4s 656us/sample - loss: 0.3671 - acc: 0.3900 - val_loss: 0.3667 - val_acc: 0.3901\n","Epoch 964/1500\n","5501/5501 [==============================] - 4s 653us/sample - loss: 0.3669 - acc: 0.3900 - val_loss: 0.3666 - val_acc: 0.3901\n","Epoch 965/1500\n","5501/5501 [==============================] - 4s 655us/sample - loss: 0.3668 - acc: 0.3901 - val_loss: 0.3665 - val_acc: 0.3901\n","Epoch 966/1500\n","5501/5501 [==============================] - 4s 661us/sample - loss: 0.3667 - acc: 0.3901 - val_loss: 0.3665 - val_acc: 0.3901\n","Epoch 967/1500\n","5501/5501 [==============================] - 4s 650us/sample - loss: 0.3667 - acc: 0.3901 - val_loss: 0.3664 - val_acc: 0.3901\n","Epoch 968/1500\n","5501/5501 [==============================] - 4s 657us/sample - loss: 0.3666 - acc: 0.3901 - val_loss: 0.3664 - val_acc: 0.3901\n","Epoch 969/1500\n","5501/5501 [==============================] - 4s 657us/sample - loss: 0.3666 - acc: 0.3901 - val_loss: 0.3664 - val_acc: 0.3901\n","Epoch 970/1500\n","5501/5501 [==============================] - 4s 653us/sample - loss: 0.3666 - acc: 0.3901 - val_loss: 0.3664 - val_acc: 0.3901\n","Epoch 971/1500\n","5501/5501 [==============================] - 4s 652us/sample - loss: 0.3666 - acc: 0.3901 - val_loss: 0.3664 - val_acc: 0.3901\n","Epoch 972/1500\n","5501/5501 [==============================] - 4s 655us/sample - loss: 0.3666 - acc: 0.3901 - val_loss: 0.3663 - val_acc: 0.3901\n","Epoch 973/1500\n","5501/5501 [==============================] - 4s 653us/sample - loss: 0.3666 - acc: 0.3901 - val_loss: 0.3663 - val_acc: 0.3901\n","Epoch 974/1500\n","5501/5501 [==============================] - 4s 652us/sample - loss: 0.3666 - acc: 0.3901 - val_loss: 0.3664 - val_acc: 0.3901\n","Epoch 975/1500\n","5501/5501 [==============================] - 4s 650us/sample - loss: 0.3666 - acc: 0.3901 - val_loss: 0.3664 - val_acc: 0.3901\n","Epoch 976/1500\n","5501/5501 [==============================] - 4s 651us/sample - loss: 0.3666 - acc: 0.3901 - val_loss: 0.3663 - val_acc: 0.3901\n","Epoch 977/1500\n","5501/5501 [==============================] - 4s 654us/sample - loss: 0.3666 - acc: 0.3901 - val_loss: 0.3663 - val_acc: 0.3901\n","Epoch 978/1500\n","5501/5501 [==============================] - 4s 653us/sample - loss: 0.3666 - acc: 0.3901 - val_loss: 0.3663 - val_acc: 0.3901\n","Epoch 979/1500\n","5501/5501 [==============================] - 4s 652us/sample - loss: 0.3666 - acc: 0.3901 - val_loss: 0.3664 - val_acc: 0.3901\n","Epoch 980/1500\n","5501/5501 [==============================] - 4s 663us/sample - loss: 0.3666 - acc: 0.3901 - val_loss: 0.3664 - val_acc: 0.3901\n","Epoch 981/1500\n","5501/5501 [==============================] - 4s 657us/sample - loss: 0.3667 - acc: 0.3901 - val_loss: 0.3665 - val_acc: 0.3901\n","Epoch 982/1500\n","5501/5501 [==============================] - 4s 661us/sample - loss: 0.3667 - acc: 0.3900 - val_loss: 0.3665 - val_acc: 0.3901\n","Epoch 983/1500\n","5501/5501 [==============================] - 4s 664us/sample - loss: 0.3667 - acc: 0.3901 - val_loss: 0.3664 - val_acc: 0.3901\n","Epoch 984/1500\n","5501/5501 [==============================] - 4s 661us/sample - loss: 0.3666 - acc: 0.3901 - val_loss: 0.3665 - val_acc: 0.3901\n","Epoch 985/1500\n","5501/5501 [==============================] - 4s 661us/sample - loss: 0.3667 - acc: 0.3900 - val_loss: 0.3665 - val_acc: 0.3901\n","Epoch 986/1500\n","5501/5501 [==============================] - 4s 661us/sample - loss: 0.3667 - acc: 0.3901 - val_loss: 0.3665 - val_acc: 0.3901\n","Epoch 987/1500\n","5501/5501 [==============================] - 4s 661us/sample - loss: 0.3667 - acc: 0.3901 - val_loss: 0.3665 - val_acc: 0.3901\n","Epoch 988/1500\n","5501/5501 [==============================] - 4s 665us/sample - loss: 0.3667 - acc: 0.3901 - val_loss: 0.3664 - val_acc: 0.3901\n","Epoch 989/1500\n","5501/5501 [==============================] - 4s 664us/sample - loss: 0.3667 - acc: 0.3901 - val_loss: 0.3664 - val_acc: 0.3901\n","Epoch 990/1500\n","5501/5501 [==============================] - 4s 654us/sample - loss: 0.3666 - acc: 0.3901 - val_loss: 0.3665 - val_acc: 0.3901\n","Epoch 991/1500\n","5501/5501 [==============================] - 4s 653us/sample - loss: 0.3667 - acc: 0.3901 - val_loss: 0.3664 - val_acc: 0.3901\n","Epoch 992/1500\n","5501/5501 [==============================] - 4s 651us/sample - loss: 0.3667 - acc: 0.3901 - val_loss: 0.3665 - val_acc: 0.3901\n","Epoch 993/1500\n","5501/5501 [==============================] - 4s 649us/sample - loss: 0.3668 - acc: 0.3900 - val_loss: 0.3666 - val_acc: 0.3901\n","Epoch 994/1500\n","5440/5501 [============================>.] - ETA: 0s - loss: 0.3668 - acc: 0.3901"],"name":"stdout"}]},{"cell_type":"markdown","metadata":{"id":"9PaRkKPuQVsK","colab_type":"text"},"source":["Get final informations about memory of system"]},{"cell_type":"code","metadata":{"id":"3j_9je77QVLK","colab_type":"code","colab":{}},"source":["!lscpu |grep 'Model name'\n","!lscpu | grep 'Socket(s):'\n","!lscpu | grep 'Core(s) per socket:'\n","!lscpu | grep 'Thread(s) per core'\n","!lscpu | grep \"L3 cache\"\n","!lscpu | grep \"MHz\"\n","!cat /proc/meminfo | grep 'MemAvailable'\n","!df -h / | awk '{print $4}'\n","\n","!df -h\n","!cat /proc/cpuinfo\n","!cat /proc/meminfo"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"vCjfH8vpQcJV","colab_type":"code","colab":{}},"source":["from psutil import *\n","\n","cpu_count()\n","cpu_stats()\n","virtual_memory()"],"execution_count":0,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"6GWfPtKoPSAt","colab_type":"text"},"source":["Get a cropped size of original image and decoded image to compare"]},{"cell_type":"code","metadata":{"id":"S3w8XNHtFULF","colab_type":"code","colab":{}},"source":["# original = cv2.imread(\"./results_png/original__17_7606334.png\")\n","# decoded = cv2.imread(\"./results_png/decoded__17_7606334.png\")\n","\n","# scale_percent = 220\n","\n","# # Recorte da imagem original e a da imagem decodificada\n","# cropped_original = original[10:128, 10:128]\n","# cropped_decoded = decoded[10:128, 10:128]\n","\n","# cropped_original_width = int(cropped_original.shape[1] * scale_percent / 100)\n","# cropped_original_height = int(cropped_original.shape[0] * scale_percent / 100)\n","# cropped_original_dim = (cropped_original_width, cropped_original_height)\n","\n","# # resize image\n","# cropped_original_resized = cv2.resize(cropped_original, cropped_original_dim, interpolation = cv2.INTER_AREA) \n","\n","# cropped_decoded_width = int(cropped_decoded.shape[1] * scale_percent / 100)\n","# cropped_decoded_height = int(cropped_decoded.shape[0] * scale_percent / 100)\n","# cropped_decoded_dim = (cropped_decoded_width, cropped_decoded_height)\n","\n","# # resize image\n","# cropped_decoded_resized = cv2.resize(cropped_decoded, cropped_decoded_dim, interpolation = cv2.INTER_AREA) \n","\n","# # Original\n","# cv2_imshow(original)\n","# cv2_imshow(decoded)\n","\n","# # Cropped\n","# cv2_imshow(cropped_original)\n","# cv2_imshow(cropped_decoded)\n","\n","# # Resized\n","# cv2_imshow(cropped_original_resized)\n","# cv2_imshow(cropped_decoded_resized)\n"],"execution_count":0,"outputs":[]},{"cell_type":"markdown","metadata":{"colab_type":"text","id":"646a45RKjA26"},"source":["Load model"]},{"cell_type":"code","metadata":{"colab_type":"code","id":"00OeNqb9jAiy","colab":{}},"source":["# model_decoder_save = load_model('./models_h5/decoder__72_9347018.h5')\n","# model_decoder_save.compile(loss='binary_crossentropy', optimizer='adam', metrics=['accuracy'])\n","\n","# img_encoded = np.load('./data_npy/_72_9347018.npy')\n","# img_decoded = model_decoder_save.predict(img_encoded)\n","\n","# with open(\"./shapes_sizes_json/original__72_9347018.json\", \"r\") as read_file:\n","#     data = json.load(read_file)\n","\n","# test_encoder_result = img_decoded.reshape(data['rows'], data['columns'], data['channels'])\n","# plt.imshow(test_encoder_result)"],"execution_count":0,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"9BA6rEYJlgWM","colab_type":"text"},"source":["Generate a file to save informations about memory"]},{"cell_type":"code","metadata":{"id":"YSLDPPp8lgF5","colab_type":"code","colab":{}},"source":["# %%writefile deep_autoencoder.py\n","\n","# # Numpy Matplot cv2\n","# import numpy as np\n","# import matplotlib.pyplot as plt\n","# import matplotlib.image as mpimg\n","# from google.colab.patches import cv2_imshow\n","# import cv2\n","\n","# # Tensorflow and Keras\n","# from tensorflow.keras.preprocessing.image import ImageDataGenerator\n","# from tensorflow.keras.layers import Dense, Input, Dropout\n","# from tensorflow.keras.models import Model, Sequential, load_model, model_from_yaml, model_from_json\n","# from tensorflow.keras.applications.inception_v3 import preprocess_input\n","# from tensorflow.keras.callbacks import *\n","\n","# # OS libs\n","# import os\n","# import json\n","# import time\n","# import datetime\n","\n","# data_png = './data_png'\n","# data_npy = './data_npy/'\n","# results_png = './results_png/'\n","# metrics_png = './metrics_png/'\n","# models_h5 = './models_h5/'\n","# models_yml = './models_yml/'\n","# shapes_sizes_json = './shapes_sizes_json/'\n","\n","# def plot_metrics_history_subplot(history, name):\n","#     fig, (ax1, ax2) = plt.subplots(1, 2)\n","\n","#     # Plot training & validation accuracy values\n","#     ax1.plot(history.history['acc'])\n","#     ax1.plot(history.history['val_acc'])\n","#     ax1.set_title('Model accuracy')\n","#     ax1.legend(['Train', 'Test'], loc='upper right')\n","\n","#     # Plot training & validation loss values\n","#     ax2.plot(history.history['loss'])\n","#     ax2.plot(history.history['val_loss'])\n","#     ax2.set_title('Model loss')\n","#     ax2.legend(['Train', 'Test'], loc='upper right')\n","\n","#     fig.savefig(metrics_png + 'history_subplot_' + name)\n","\n","# def plot_metrics_history(history, name):    \n","#     fig = plt.figure()\n","    \n","#     # Plot training & validation accuracy values\n","#     plt.plot(history.history['acc'])\n","#     plt.plot(history.history['val_acc'])\n","#     plt.title('Model accuracy')\n","#     plt.ylabel('Accuracy')\n","#     plt.xlabel('Epoch')\n","#     plt.legend(['Train', 'Test'], loc='upper right')\n","#     plt.show()\n","#     fig.savefig(metrics_png + 'history_acc_' + name)\n","\n","#     fig = plt.figure()\n","\n","#     # Plot training & validation loss values\n","#     plt.plot(history.history['loss'])\n","#     plt.plot(history.history['val_loss'])\n","#     plt.title('Model loss')\n","#     plt.ylabel('Loss')\n","#     plt.xlabel('Epoch')\n","#     plt.legend(['Train', 'Test'], loc='upper right')\n","#     plt.show()\n","#     fig.savefig(metrics_png + 'history_loss_' + name)\n","\n","# def plot_metrics_evaluate_all(model, name):\n","#     fig = plt.figure()\n","\n","#     loss = model[0]\n","#     accuracy = model[1]\n","\n","#     plt.plot([0, 100], [0, loss * 100])\n","#     plt.plot([0, 100], [0, accuracy * 100])\n","#     plt.title('Loss: %.2f%% | Accuracy: %.2f%%' % ( loss * 100,  accuracy * 100 ))\n","#     plt.legend(['Loss', 'Accuracy'], loc='upper right')\n","#     plt.show()\n","    \n","#     fig.savefig(metrics_png + 'evaluate_loss_accuracy' + name)\n","\n","# def plot_metrics_evaluate(model, name):\n","#     fig, (ax1, ax2) = plt.subplots(1, 2)\n","#     loss = model[0]\n","#     accuracy = model[1]\n","\n","#     ax1.plot([0, 100], [0, loss * 100])\n","#     ax1.set_title('Loss: %.2f%%' % ( loss * 100 ))\n","#     ax1.legend(['Loss'], loc='upper right')\n","\n","#     ax2.plot([0, 100], [0, accuracy * 100])\n","#     ax2.set_title('Accuracy: %.2f%%' % ( accuracy * 100 ))\n","#     ax2.legend(['Accuracy'], loc='upper right')\n","    \n","#     fig.savefig(metrics_png + 'evaluate_acc_' + name)\n","\n","# def plot_all(images):\n","#     fig = plt.figure(figsize=(32, 32))\n","#     number_rows = int(len(images)/3) + 1\n","    \n","#     for index in range(len(images)):\n","#         a = fig.add_subplot(number_rows, 3, index+1)\n","#         plt.imshow(images[index])\n","#         plt.title(f'{index}:{images[index].shape}')\n","#         a.axis('off')\n","    \n","#     fig.savefig(results_png + 'compare_all_images.png')\n","#     plt.show()\n","\n","# def save_image(name, image):        \n","#     mpimg.imsave(results_png + name, image)\n","\n","# def save_npy(name, image): \n","#     name = name[:-4]\n","#     np.save(data_npy + name + '.npy', image)\n","\n","# def save_json(name, shape, size): \n","#     name = name[:-4]\n","\n","#     data = {\n","#         \"rows\": shape[0],\n","#         \"columns\": shape[1],\n","#         \"channels\": shape[2],\n","#         \"size\": size,\n","#         \"shape\": shape\n","#     }\n","\n","#     with open(shapes_sizes_json + 'original_' + name + '.json', 'w') as outfile:\n","#         json.dump(data, outfile)\n","\n","\n","# class TimingCallback(Callback):\n","#   def __init__(self):\n","#     self.times = []\n","#   def on_epoch_begin(self, epoch, logs={}):\n","#     self.start_time = time.time()\n","#   def on_epoch_end(self, epoch, logs={}):\n","#     self.times.append(time.time() - self.start_time)\n","\n","# time_callback = TimingCallback()\n","\n","# class SimpleAutoencoder(object):\n","\n","#     def __init__(self, input_dim, encoded_dim):    \n","#         input_layer = Input(shape=(input_dim,))\n","#         hidden_input = Input(shape=(encoded_dim,))\n","#         hidden_layer = Dense(encoded_dim, activation='relu')(input_layer)\n","#         output_layer = Dense(input_dim, activation='sigmoid')(hidden_layer)\n","\n","#         self.autoencoder = Model(input_layer, output_layer)\n","#         self.encoder = Model(input_layer, hidden_layer)\n","#         tmp_decoder_layer = self.autoencoder.layers[-1]\n","#         self.decoder = Model(hidden_input, tmp_decoder_layer(hidden_input))\n","\n","#         self.autoencoder.compile(optimizer='adam', loss='binary_crossentropy', metrics = ['accuracy'])\n","\n","#     def train(self, input_train, input_test, batch_size, epochs):    \n","#         self.autoencoder.fit(input_train, \n","#                                     input_train,\n","#                                     epochs=epochs,\n","#                                     batch_size=batch_size,\n","#                                     shuffle=True,\n","#                                     validation_data=(\n","#                                             input_test, \n","#                                             input_test),\n","#                                     callbacks=[time_callback])\n","        \n","#     def get_encoded_image(self, image):\n","#         encoded_image = self.encoder.predict(image)\n","#         return encoded_image\n","    \n","#     def get_decoded_image(self, encoded_imgs):\n","#         decoded_image = self.decoder.predict(encoded_imgs)\n","#         return decoded_image\n","\n","#     def get_evaluate_model(self, train, test):\n","#         return self.autoencoder.evaluate(train, test)\n","\n","#     def get_history_model(self):\n","#         return self.autoencoder.history\n","    \n","#     def save_model(self, name):\n","#         name = name[:-4]\n","#         self.autoencoder.save(models_h5 + 'autoencoder_' + name + '.h5')\n","#         self.encoder.save(models_h5 + 'encoder_' + name + '.h5')\n","#         self.decoder.save(models_h5 + 'decoder_' + name + '.h5')\n","\n","#     def save_model_to_yml(self, name):\n","#         name = name[:-4]\n","#         model_yaml = self.autoencoder.to_yaml()\n","#         with open(models_yml + 'autoencoder_' + name + '.yaml', 'w') as yaml_file:\n","#             yaml_file.write(model_yaml)\n","            \n","# def main():\n","#     images = []\n","#     historic = []\n","#     results = []\n","    \n","#     for img in os.listdir(data_png):\n","#         try:\n","#             # Normalização das imagens   \n","#             img_train = mpimg.imread((os.path.join(data_png, img)))  \n","#             max_train_value = float(img_train.max())\n","#             train = img_train.astype('float32') / max_train_value\n","#             train = train.reshape((len(train), np.prod(train.shape[1:])))\n","            \n","#             img_test = mpimg.imread((os.path.join(data_png, img)))\n","#             max_test_value = float(img_test.max())\n","#             test = img_test.astype('float32') / max_test_value\n","#             test = test.reshape((len(test), np.prod(test.shape[1:])))\n","\n","#             # Envio da imagem para a classe DeepAutoencoder\n","#             autoencoder = SimpleAutoencoder(train.shape[1], 64)\n","#             autoencoder.train(train, test, 64, 1500)\n","            \n","#             encoded_img = autoencoder.get_encoded_image(test)\n","#             decoded_img = autoencoder.get_decoded_image(encoded_img)\n","\n","#             autoencoder_history = autoencoder.get_history_model()\n","#             autoencoder_evaluate = autoencoder.get_evaluate_model(train, test)\n","            \n","#             autoencoder.save_model(img)\n","#             autoencoder.save_model_to_yml(img)\n","            \n","#             plot_metrics_history(autoencoder_history, 'autoencoder' + img)\n","#             plot_metrics_history_subplot(autoencoder_history, 'autoencoder' + img)\n","#             plot_metrics_evaluate(autoencoder_evaluate, 'autoencoder' + img)\n","#             plot_metrics_evaluate_all(autoencoder_evaluate, 'autoencoder' + img)\n","\n","#             # Dimensões da imagem original\n","#             image_shape = img_test.shape\n","#             size_image = img_test.size\n","\n","#             # Redimensionamento das imagens obtidas\n","#             original_result = test.reshape(image_shape[0], image_shape[1], image_shape[2])\n","#             decoded_img_result = decoded_img.reshape(image_shape[0], image_shape[1], image_shape[2])      \n","\n","#             images.append(original_result)\n","#             images.append(encoded_img)\n","#             images.append(decoded_img_result)\n","\n","#             save_image('original_' + img, original_result)\n","#             save_image('encoded_' + img, encoded_img)\n","#             save_image('decoded_' + img, decoded_img_result)\n","            \n","#             save_npy(img, encoded_img)\n","#             save_json(img, image_shape, size_image)\n","            \n","#             #Print average of the time for each layer\n","#             results.append(np.average(time_callback.times))\n","#             seconds = np.average(time_callback.times)\n","#             result_time = str(datetime.timedelta(seconds=seconds))\n","#             print(\"Medium time:\", result_time)  \n","\n","#         except Exception as e:\n","#             print(e)\n","#             pass\n","\n","#     plot_all(images)\n","#     return"],"execution_count":0,"outputs":[]}]}