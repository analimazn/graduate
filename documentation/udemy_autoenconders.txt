Curso Udemy - Deep Learning A - Z:

Neurônio artificial:
- Entradas
- Soma
- Função de ativação

Multiplica as entradas pelos pesos e depois soma.

Função de Ativação: Step Function (função Degrau)
- Maior que zero = 1
- Menor que zero = 0

Operador XOR: Não é linearmente separável

Função de ativação: Sigmoid (função Sigmoide)
- Se X for alto o valor será aproximadamente 1
- Se X for pequeno o valor será aproximadamente 0
- Não retorna valores negativos

Gradiente: Calcular o menor custo/peso
- Usa derivada para calcular o quanto ajustar dos pesos

Autoencoder:
- Superfitting e Underfitting
- Não supervisionado
- Self supervised learning: Aprende supervisionando a si mesmo (Esquerda para a direita)
 
Tipos de autoencoder:
- Sparse Autoencoder:
	- Menor quantidade de camadas de entrada do que camadas ocultas
	- Um dos mais populares
	- Usa uma técnica de regularização para prevenir overfitting
	- Não usa todos os neurônios da camada oculta (valores pequenos)

- Denoising autoencoder
	- Mesma quantidade de camadas de entrada e de camadas ocultas
	- Modifica os valores da camada de entrada, alterando alguns neurônios para o valor zero
	- Quando os pesos são atualizados, a camada de saída é comparada com os valores originais para obter o valor do erro
	
- Contractive autoencoder
	- Menor quantidade de camadas de entrada do que camadas ocultas
	- Adiciona uma função de penalidade quando os pesos são atualizados

- Deep autoencoder:
	- Maior quantidade de camadas de entrada do que camadas ocultas, as camadas vão reduzindo gradativamente
	- Input: Encoding DBN
	- Compressed: Feature vector
	- Output: Decoding DBN


- Convolutional autoencoder
	- Maior quantidade de camadas de entrada do que camadas ocultas, as camadas vão reduzindo gradativamente
	- Camadas de convolução reduzindo a camada gradativamente
	- Decodifica até chegar ao tamanho original







